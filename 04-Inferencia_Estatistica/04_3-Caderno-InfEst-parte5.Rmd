---
title: "04_3-Caderno-InfEst-parte5"
author: "Helena R. S. D'Espindula"
output:
  html_document: 
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
      number_sections: true
  pdf_document:
date: "2024-04-26"
---

```{r setup, echo=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = TRUE, error = TRUE)
library(ggplot2)
library(glmnet)
library(Matrix)
library(bookdown)
library(numDeriv)
library(pracma)
library(lpSolve)
library(quadprog)
library(mvtnorm)
#library(optimize)
#library(optimx)
```
\usepackage{amsmath}

- At√© agora resolvemos problemas lineares assim:
$$
(X^TX)^{-1} X^TX \hat{\beta} = (X^TX)^{-1}X^Ty
$$
- Fun√ß√£o linear
$$
y = \beta_0 + \beta_1 x_1 + \beta_p x_p +erro
$$
- Aqui tem um exp ent√£o n√£o d√° pra resolver assim:
$$
y = \frac{exp (\beta_0 + \beta_1 x_1 )}{coisas}
$$


# M√©todos Num√©ricos

## Sistemas de equa√ß√µes n√£o-lineares

### Equa√ß√µes n√£o-lineares
- Equa√ß√µes precisam ser resolvidas frequentemente em todas as √°reas da ci√™ncia.
- Equa√ß√£o de uma vari√°vel:$f(x) = 0$.
- A solu√ß√£o ou raiz √© um valor num√©rico de $x$ que satisfaz a equa√ß√£o.‚àí1.0 ‚àí0.5 0.0 0.5 1.0
- Solu√ß√£o de uma equa√ß√£o do tipo $f(x) = 0$ √© o ponto onde $f(x)$ cruza ou toca o eixo $x$.

### Solu√ß√£o de equa√ß√µes n√£o lineares
- Em muitas situa√ß√µes √© imposs√≠vel determinar a raiz analiticamente.
- Exemplo trivial $3x + 8 = 0 \rigtharrow x = -\frac{8}{3}$
- Exemplo n√£o-trivial $8 ‚àí 4.5(x ‚àí sin(x)) = 0 ‚Üí x = ?$
- Solu√ß√£o num√©rica de $f(x) = 0$ √© um valor de $x$ que satisfaz √† equa√ß√£o de forma aproximada.
- M√©todos num√©ricos para resolver equa√ß√µes s√£o divididos em dois grupos:
  1. M√©todos de confinamento;
  2. M√©todos abertos

### M√©todos de confinamento
- Identifica-se um intervalo que possui a solu√ß√£o.
- Usando um esquema num√©rico, o tamanho do intervalo √© reduzido sucessivamente at√© uma precis√£o desejada

### M√©todos abertos
- Assume-se uma estimativa inicial.
- Tentativa inicial deve ser pr√≥xima a solu√ß√£o.
- Usando um esquema num√©rico a solu√ß√£o √© melhorada.
- O processo para quando a precis√£o desejada √© atingida.


### Erros em solu√ß√µes num√©ricas
- Crit√©rio para determinar se uma solu√ß√£o √© suficientemente precisa.
- Seja $x_{ts}$ a solu√ß√£o verdadeira e $x_{ns}$ uma solu√ß√£o num√©rica.
- Quatro medidas podem ser consideradas para avaliar o erro:
1. Erro real $x_{ts} - x_{ns}$.

2. Toler√¢ncia em $f(x)$
$$
|f(x_{ts}) - f(x_{ns})| = |0 - e| = |e|
$$

3. Toler√¢ncia no tamanho do intervalo de busca:
$$
|\frac{b-a}{2}|
$$
4. Erro relativo estimado:
$$
|\frac{x^n_{ns}-x^{n-1}_{ns}}{x^{n-1}_{ns}}|
$$

  - Tolerancia que o prof usa normalmente:
$$
1e^{-4}
$$


## M√©todos de confinamento

### M√©todo da bisse√ß√£o
- M√©todo de confinamento.
- Sabe-se que dentro de um intervalo  $[a,b], f(x)$ √© cont√≠nua e possui uma solu√ß√£o.
- Neste caso $f(x)$ tem sinais opostos nos pontos finais do intervalo.

### Algoritmo: m√©todo da bisse√ß√£o
- Encontre $[a,b]$, tal que $f(a) f(b) < 0$.
- Calcule a primeira estimativa $x^{(1)}_{ns}$ usando $x^{(1)}_{ns} = \frac{a+b}{2}$
- Determine se a solu√ß√£o exata est√° entre $a$ e $x^{(1)}_{ns}$ ou entre $x^{(1)}_{ns}$ e $b$. Isso √© feito verificando o sinal do produto $f(a)f(x^{(1)}_{ns}) $
  1. Se $f(a) f(x^{(1)}_{ns}) < 0$, a solu√ß√£o est√° entre $a$ e $x^{(1)}_{ns}$
  2. Se  $f(a) f(x^{(1)}_{ns}) > 0$, a solu√ß√£o est√° entre $x^{(1)}_{ns}$ $b$.

- Selecione o subintervalo que cont√©m a solu√ß√£o e volte ao passo 2.
- Repita os passos 2 a 4 at√© que a toler√¢ncia especificada seja satisfeita

### Implementa√ß√£o R: m√©todo da bisse√ß√£o

```{r}
bissecao <- function(fx,
                     a,
                     b,
                     tol = 1e-04,
                     max_iter = 100) {
  fa <-
    fx(a)
  fb <- fx(b)
  if (fa * fb > 0)
    stop("Solu√ß√£o n√£o est√° no intervalo")
  solucao <- c()
  sol <- (a + b) / 2
  solucao[1] <- sol
  
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for (i in 1:max_iter) {
    ## max_inter para n√£o ir at√© infinito se n√£o atingir a tolerancia
    test <- fx(a) * fx(sol)
    if (test < 0) {
      solucao[i + 1] <- (a + sol) / 2
      b = sol
    }
    if (test > 0) {
      solucao[i + 1] <- (b + sol) / 2
      a = sol
    }
    if (abs((b - a) / 2) < tol)
      break
    sol = solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <-
    list("Tentativas" = solucao,
         "Limites" = limites,
         "Raiz" = solucao[i + 1])
  return(out)
}
```


### Exemplo
- Encontre as ra√≠zes de
$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] <= 3.84
$$

$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] - 3.84 <= 0
$$

√© uma parabola de boca para cima, tem duas raizes em zero


```{r}
ftheta <- function(theta) {
  ## Implementando a fun√ß√£o
  dd <-
    2 * length(y) * (log(theta.hat / theta) + mean(y) * (theta - theta.hat))
  return(dd - 3.84)
}
set.seed(123) ## Resolvendo numericamente
y <- rexp(20, rate = 1)
theta.hat <- 1 / mean(y)
Ic_min <- bissecao(fx = ftheta, a = 0, b = theta.hat)
Ic_max <- bissecao(fx = ftheta, a = theta.hat, b = 3)
c(Ic_min$Raiz, Ic_max$Raiz) ## Solu√ß√£o aproximada
```


### M√©todo regula falsi
- Sabe-se que dentro de um intervalo $[a,b], f(x)$ √© cont√≠nua e possui uma solu√ß√£o.

### Algoritmo: m√©todo regula falsi
- Escolha os pontos $a$ e $b$ entre os quais existe uma solu√ß√£o.
- Calcule a primeira estimativa: $x^{(i)} = \frac{a f(b) - f f(a)}{f(b)-f(a)}$
- Determine se a solu√ß√£o est√° entre ùëé e ùë•ùëñ, ou entre ùë•(ùëñ) e ùëè.
  1. Se $f(a)f(x(i)) < 0$, a solu√ß√£o est√° entre $a$ e $x(i)$.
  2. Se $f(a)f(x(i)) > 0$, a solu√ß√£o est√° entre $x(i)$ e $b$.
- Selecione o subintervalo que cont√©m a solu√ß√£o como o novo intervalo [ùëé,ùëè] e volte ao passo 2.
- Repita passos 2 a 4 at√© converg√™ncia


### Implementa√ß√£o R: m√©todo regula falsi

```{r}

regula_falsi <- function(fx,
                         a,
                         b,
                         tol = 1e-04,
                         max_iter = 100) {
  fa <-
    fx(a)
  fb <- fx(b)
  if (fa * fb > 0)
    stop("Solu√ß√£o n√£o est√° no intervalo")
  solucao <- c()
  sol <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
  solucao[1] <- sol
  limites <- matrix(NA, ncol = 2, nrow = max_iter)
  for (i in 1:max_iter) { 
    ## max_inter para n√£o ir at√© infinito se n√£o atingir a tolerancia
    test <- fx(a) * fx(sol)
    if (test < 0) {
      b = sol
      solucao[i + 1] <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
    }
    if (test > 0) {
      a = sol
      solucao[i + 1] <- sol <- (a * fx(b) - b * fx(a)) / (fx(b) - fx(a))
    }
    if (abs(solucao[i + 1] - solucao[i]) < tol)
      break
    sol = solucao[i + 1]
    limites[i, ] <- c(a, b)
  }
  out <-
    list("Tentativas" = solucao,
         "Limites" = limites,
         "Raiz" = sol)
  return(out)
}
```

### Aplica√ß√£o: regula-falsi
- Encontre as ra√≠zes de
$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] <= 3.84
$$

```{r}
## Resolvendo numericamente
Ic_min <- regula_falsi(fx = ftheta, a = 0.1, b = theta.hat)
Ic_max <- regula_falsi(fx = ftheta, a = theta.hat, b = 3)
## Solu√ß√£o aproximada
c(Ic_min$Raiz, Ic_max$Raiz)
```



$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] <= 3.84
$$
√© igual a:
$$ f(\theta) - 3,84 = 0 $$
$$ f(\theta = 0,1)$$
$$x^{(2)} = 0,1 - \alpha f(\theta = 0,1) = 0,9$$
$$x^{(3)} = 0,9 - \alpha f(\theta = 0,9) = 1,8$$
$$x^{(4)} = 1,8 - \alpha f(\theta = 1,8)$$



### Coment√°rios: m√©todos de confinamento

- Sempre convergem para uma resposta, desde que uma raiz esteja no intervalo.
- Podem falhar quando a fun√ß√£o √© tangente ao eixo $x$, n√£o cruzando em $f(x) = 0$.
- Converg√™ncia √© lenta em compara√ß√£o com outros m√©todos.
- S√£o dif√≠ceis de generalizar para sistemas de equa√ß√µes n√£o-lineares.


## M√©todos abertos

### M√©todo de Newton

- Fun√ß√£o deve ser cont√≠nua e diferenci√°vel.
- Fun√ß√£o deve possuir uma solu√ß√£o perto do ponto inicial

### Algoritmo: m√©todo de Newton
- Escolha um ponto $x_1$ como inicial.
- Para $i = 1,2, ...$ at√© que o erro seja menor que um valor especificado, calcule
$$
x^{(i+1)} = x^{(i)} - \frac{f(x^{(i)})}{f'(x^{(i)})}
$$

- Implementa√ß√£o computacional

```{r}
newton <- function(fx, f_prime, x1, tol = 1e-04, max_iter = 10) {
  solucao <- c()
  solucao[1] <- x1
  for(i in 1:max_iter) {
    solucao[i+1] = solucao[i] - fx(solucao[i])/f_prime(solucao[i])
    if( abs(solucao[i+1] - solucao[i]) < tol) break
  }
  return(solucao)
}
```

### Aplica√ß√£o: m√©todo de Newton
- Encontre as ra√≠zes de
$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] <= 3.84
$$

- Derivada
$$
D'(\theta) = 2n(y - 1/ \theta)
$$


```{r}
## Derivada da fun√ß√£o a ser resolvida
fprime <- function(theta){2*length(y)*(mean(y) - 1/theta)}
## Solu√ß√£o numerica
Ic_min <- newton(fx = ftheta, f_prime = fprime, x1 = 0.1)
Ic_max <- newton(fx = ftheta, f_prime = fprime, x1 = 2)
c(Ic_min[length(Ic_min)], Ic_max[length(Ic_max)])
```

### M√©todo gradiente descendente

Obs: na matematica √© mais comum procurar o minimo do que o m√°ximo.

- M√©todo do gradiente descendente em geral √© usado para otimizar uma fun√ß√£o.
- Suponha que desejamos minimizar $F(x)$ cuja derivada √© $f(x)$.
- Sabemos que um ponto critico ser√° obtido em $f(x) = 0$
- Note que $f(x)$ √© o gradiente de $F(x)$, assim aponta na dire√ß√£o de m√°ximo.
- Assim, podemos caminhar na dire√ß√£o contr√°ria seguindo o gradiente, i.e.
$$
x^{(i+1)} = x^{(i)} - \alpha f (x^{(i)})
$$
- $\alpha$ √© um par√¢metro de tuning usado para controlar o tamanho do passo.
- A escolha do $\alpha$ √© fundamental para atingir converg√™ncia.
- Busca em gride pode ser uma op√ß√£o razo√°vel.

Obs: $\alpha$ = parametro de tuning ou taxa de aprendizagem. Idealmente valor pequeno para ir em passos pequenos.

### Algoritmo: m√©todo gradiente descendente
- Escolha um ponto $x_1$ como inicial.
- Para $i - 1,2, ....$ at√© que o erro seja menor que um valor especificado, calcule:
$$
x^{(i+1)} = x^{(i)} - \alpha f (x^{(i)})
$$

- Implementa√ß√£o computacional

```{r}
grad_des <- function(fx,
                     x1,
                     alpha,
                     max_iter = 100,
                     tol = 1e-04) {
  sol <- c()
  sol[1] <- x1
  for (i in 1:max_iter) {
    sol[i + 1] <- sol[i] - alpha * fx(sol[i])
    if (abs(fx(sol[i + 1])) < tol)
      break
  }
  return(sol)
}
```

### Aplica√ß√£o: m√©todo gradiente descendente

- Encontre as ra√≠zes de
$$
D(\theta) = 2n[ log(\frac{\hat{\theta}}{\theta} + y_{linha} (\theta - \hat{\theta})] <= 3.84
$$


```{r}
## Solu√ß√£o numerica
Ic_min <- grad_des(fx = ftheta, alpha = -0.02, x1 = 0.1)
Ic_max <- grad_des(fx = ftheta, alpha = 0.01, x1 = 4)
c(Ic_min[length(Ic_min)], Ic_max[length(Ic_max)])
```



## Sistemas de equa√ß√µes n√£o-lineares

### Sistemas de equa√ß√µes

- Sistema com duas equa√ß√µes:
$$
f_1(x_1,x_2) = 0
$$

$$
f_2(x_1,x_2) = 0
$$

- A solu√ß√£o num√©rica consiste em encontrar $\hat{x_1}$ e $\hat{x_2}$ que satisfa√ßa o sistema de equa√ß√µes.

- A ideia √© facilmente estendida para um sistema com ùëõ equa√ß√µes
$$
f_1(x_1,x_n) = 0
$$
...
$$
f_n(x_1,x_n) = 0
$$

- Genericamente, tem-se
$$
f(x) = 0
$$

## M√©todo de Newton


### Algoritmo: m√©todo de Newton
- Escolha um vetor $x1$ como inicial.
- Para $i = 1,2 ....$ at√© que o erro seja menor que um valor especificado, calcule
$$
x^{(i+1)} = x^{(i)} - J(x^{(i)})^{-1} f(x^{(i)})
$$
onde

$$
$$

√© chamado Jacobiano de $f(x).

- Implementa√ß√£o computacional

```{r}
newton <- function(fx, jacobian, x1, tol = 1e-04, max_iter = 10) {
  solucao <- matrix(NA, ncol = length(x1), nrow = max_iter)
  solucao[1,] <- x1
  for(i in 1:max_iter) {
    J <- jacobian(solucao[i,])
    grad <- fx(solucao[i,])
    solucao[i+1,] = solucao[i,] - solve(J, grad)
    if( sum(abs(solucao[i+1,] - solucao[i,])) < tol) break
  }
  return(solucao)
}
```


### Aplica√ß√£o: m√©todo de Newton
- Resolva
ùëì1(ùë•1, ùë•2) = ùë•2 ‚àí 1
2 (expùë•1/2 + exp‚àíùë•/2) = 0
ùëì2(ùë•1, ùë•2) = 9ùë•2
1 + 25ùë•2
2 ‚àí 225 = 0.
- Precisamos obter o Jacobiano, assim tem-se
J(ùë•) = [‚àí 1
2 ( expùë•1/2
2 ‚àí exp‚àíùë•1/2
2 ) 1
18ùë•1 50ùë•

```{r}
## Sistema a ser resolvido
fx <- function(x) {
  c(x[2] - 0.5 * (exp(x[1] / 2) + exp(-x[1] / 2)),
    9 * x[1] ^ 2 + 25 * x[2] ^ 2 - 225)
}
## Jacobiano
Jacobian <- function(x) {
  jac <- matrix(NA, 2, 2)
  jac[1, 1] <- -0.5 * (exp(x[1] / 2) / 2 - exp(-x[1] / 2) / 2)
  jac[1, 2] <- 1
  jac[2, 1] <- 18 * x[1]
  jac[2, 2] <- 50 * x[2]
  return(jac)
}
```

```{r}
## Resolvendo
sol <- newton(fx = fx, jacobian = Jacobian, x1 = c(1,1))
tail(sol,4) ## Solu√ß√£o
```

```{r}
fx(sol[8,]) ## OK
```

### Coment√°rios: m√©todo de Newton
- M√©todo de Newton ir√° convergir tipicamente se tr√™s condi√ß√µes forem satisfeitas:
1. As fun√ß√µes ùëì1, ùëì2, ‚Ä¶ , ùëìùëõ e suas derivadas forem cont√≠nuas e limitadas na vizinhan√ßa da
solu√ß√£o.
2. O Jacobiano deve ser diferente de zero na vizinhan√ßa da solu√ß√£o.
3. A estimativa inicial de solu√ß√£o deve estar suficientemente pr√≥xima da solu√ß√£o exata.
- Derivadas parciais (elementos da matriz Jacobiana) devem ser determinados. Isso pode ser
feito analitica ou numericamente.
- Cada passo do algoritmo envolve a invers√£o de uma matriz.


### M√©todo gradiente descendente


- Escolha um vetor ùë•1 como inicial.
- Para ùëñ = 1,2, ‚Ä¶ at√© que o erro seja menor que um valor especificado, calcule
ùë•(ùëñ+1) = ùë•(ùëñ) ‚àí ùõºf(ùë•(ùëñ)).
- Implementa√ß√£o computacional


```{r}
grad_des <- function(fx,
                     x1,
                     alpha,
                     max_iter = 100,
                     tol = 1e-04) {
  solucao <- matrix(NA, ncol = length(x1), nrow = max_iter)
  solucao[1, ] <- x1
  for (i in 1:c(max_iter - 1)) {
    solucao[i + 1, ] <- solucao[i, ] - alpha * fx(solucao[i, ])
    #print(c(i, solucao[i+1,]))
    if (sum(abs(solucao[i + 1, ] - solucao[i, ])) <= tol)
      break
  }
  return(solucao)
}
```

### Aplica√ß√£o: m√©todo gradiente descendente
- Resolva
$$
$$

$$
$$

onde $y_i = (5.15; 6.40; 2.77; 5.72; 6.25; 3.45; 5.00; 6.86; 4.86; 3.72)$ e
$z_i = (0.28; 0.78; 0.40; 0.88; 0.94; 0.04; 0.52; 0.89; 0.55; 0.45).$

- Implementa√ß√£o computacional

```{r}
fx <- function(x) {
  y <- c(5.15, 6.40, 2.77, 5.72, 6.25, 3.45, 5.00, 6.86, 4.86, 3.72)
  z <- c(0.28, 0.78, 0.40, 0.88, 0.94, 0.04, 0.52, 0.89, 0.55, 0.45)
  term1 <- -2 * sum(y - x[1] - x[2] * z)
  term2 <- -2 * sum((y - x[1] - x[2] * z) * z)
  out <- c(term1, term2)
  return(out)
}
sol_grad <-
  grad_des(
    fx = fx,
    x1 = c(5, 0),
    alpha = 0.05,
    max_iter = 140
  )
fx(x = sol_grad[137, ])
```

### Coment√°rios: m√©todo gradiente descendente

- Vantagem: n√£o precisa calcular o Jacobiano!!
- Desvantagem: precisa de tuning.
- Em geral precisa de mais itera√ß√µes que o m√©todo de Newton.
- Cada itera√ß√£o √© mais barata computacionalmente.
- Uma varia√ß√£o do m√©todo √© conhecido como steepest descent.
- Avalia a mudan√ßa em ùëì(ùë•) para um gride de ùõº e da o passo usando o ùõº que torna ùêπ (ùë•)
maior/menor.
- O tamanho do passo pode ser adaptativo.
- Cuidado! Sup√µe que a fun√ß√£o subjacente est√° sendo minimizada!


## Diferencia√ß√£o num√©rica

- Derivada d√° uma medida da taxa na qual a vari√°vel $y$ muda devido a uma mudan√ßa na vari√°vel $x$.
- A fun√ß√£o a ser diferenciada pode ser dada por uma fun√ß√£o $f(x)$, ou apenas por um conjunto de pontos $(y_i, x_i)$.
- Quando devemos usar derivadas num√©ricas?
  1. $f'(x)$ √© dificil de obter analiticamente.
  2. $f'(x)$ √© caro para calcular computacionalmente.
  3. Quando a fun√ß√£o √© especificada apenas por um conjunto de pontos.
- Abordagens para a diferencia√ß√£o num√©rica
  1. Aproxima√ß√£o por diferen√ßas finitas.
  2. Aproximar a fun√ß√£o por uma outra fun√ß√£o de f√°cil deriva√ß√£o.
  3. Diferencia√ß√£o autom√°tica (fora do nosso escopo)

### Aproxima√ß√£o da derivada por diferen√ßas finitas
- Derivada $f'(x)$ de uma fun√ß√£o $f'(x)$ no ponto $x =a$ √© definida como:
$$
f'(a) = \lim_{x \to a}{\frac{f(x)-f(a)}{x-a}}
$$

- Derivada √© a inclina√ß√£o da reta tangente √† fun√ß√£o em $x=a$
- Escolhe-se um ponto $x$ pr√≥ximo a $a$ e calcula-se a inclina√ß√£o da reta que conecta os dois pontos.
- A precis√£o do c√°lculo aumenta quando $x$ aproxima de $a$
- Aproxima√ß√£o num√©rica: a fun√ß√£o ser√° avaliada em diferentes pontos pr√≥ximos a $a$ para aproximar $f'(a)$.

- F√≥rmulas para diferencia√ß√£o num√©rica:
1. Diferen√ßa progressiva: inclina√ß√£o da reta que conecta os pontos $(x_i,f(x_i))$ e $(x_{i+1},f(x_{i+1}))$ 
$$
f'(x_i) = \frac{f(x_{i+1}) - f(x_{i})}{x_{i+1} - x_i}
$$
2. Diferen√ßa regressiva: inclina√ß√£o da reta que conecta os pontos $(x_{i-1},f(x_{i-1}))$ e $(x_{i},f(x_{i}))$ 
$$
f'(x_i) = \frac{f(x_{i}) - f(x_{i-1})}{x_{i} - x_{i-1}}
$$
3. Diferen√ßa central: inclina√ß√£o da reta que conecta os pontos $(x_{i-1},f(x_{i-1}))$ e $(x_{i+1},f(x_{i+1}))$ 
$$
f'(x_i) = \frac{f(x_{i+1}) - f(x_{i-1})}{x_{i+1} - x_{i-1}}
$$

Obs: nessas formulas o 1 n√£o precisa ser litelmente 1, √© s√≥ um valor pequeno.


- Diferen√ßa progressiva
```{r}
dif_prog <- function(fx, x, h) {
df <- (fx(x + h) - fx(x))/( (x + h) - x)
return(df)
}
```

- Diferen√ßa regressiva
```{r}
dif_reg <- function(fx, x, h) {
df <- (fx(x) - fx(x - h))/( x - (x - h))
return(df)
}
```


- Diferen√ßa central
```{r}
dif_cen <- function(fx, x, h) {
df <- (fx(x + h) - fx(x - h))/( (x + h) - (x - h))
return(df)}
```


Exemplo: aproxima√ß√£o da derivada por diferen√ßas finitas
- Considere $f(x) = x^3$, assim $f'(x) = 3x^2$
```{r}
fx <- function(x) x^3
dif_prog(fx, x = 2, h = 0.001) ## Diferen√ßa progressiva
## [1] 12.006
dif_reg(fx, x = 2, h = 0.001) ## Diferen√ßa regressiva
## [1] 11.994
dif_cen(fx, x = 2, h = 0.001) ## Diferen√ßa central
## [1] 12
3*2^2 ## Exata
## [1] 12
```

## Diferen√ßas finitas usando expans√£o em S√©ries de Taylor

- As f√≥rmulas anteriores podem ser deduzidas usando expans√£o em s√©rie de Taylor.
- O n√∫mero de pontos para aproximar a derivada pode mudar.
- Vantagem da dedu√ß√£o por s√©rie de Taylor √© que ela fornece uma estimativa do erro de truncamento.


### Diferen√ßa finita progressiva com dois pontos
- Aproxima√ß√£o de Taylor para o ponto $x_{i+1}$ **+1**
$$
f(x_{i+1}) = f(x_i) + f'(x_i)h + \frac{f''(x_i)}{2!}h^2 +  \frac{f'''(x_i)}{3!}h^3 + ....
$$
onde $h = x_{i+1} - x_{i}$
- Fixando dois termos e deixando os outros termos como um **res√≠duo**, temos
$$
f(x_{i+1}) = f(x_i) + f'(x_i)h + \frac{f''(\xi)}{2!}h^2
$$
- Resolvendo para $f'(x_i)$, temos
$$
f(x_{i}) = \frac{f(x_{i+1}) + f'(x_i)}{h} - \frac{f''(\xi)}{2!}h^2
$$
- Erro de truncamento,
$$
- \frac{f''(\xi)}{2!}h^2 = O(h)
$$

### Diferen√ßa finita regressiva com dois pontos
- Aproxima√ß√£o de Taylor para o ponto $x_{i-1}$ **-1**
$$
f(x_{i-1}) = f(x_i) - f'(x_i)h + \frac{f''(x_i)}{2!}h^2 +  \frac{f'''(x_i)}{3!}h^3 + ....
$$
onde $h = x_{i} - x_{i-1}$
- Fixando dois termos e deixando os outros termos como um res√≠duo, temos
$$
f(x_{i-1}) = f(x_i) + f'(x_i)h + \frac{f''(\xi)}{2!}h^2
$$
- Resolvendo para ùëì‚Ä≤(ùë•ùëñ), temos
$$
f(x_{i}) = \frac{f(x_{i}) - f'(x_{i-1})}{h} - \frac{f''(\xi)}{2!}h^2
$$
- Erro de truncamento, ùëì‚Ä≥(ùúâ)
$$
\frac{f''(\xi)}{2!}h^2 = O(h)
$$



### Diferen√ßa finita central com dois pontos
- Aproxima√ß√£o de Taylor para o ponto $x_{i+1}$
$$
f(x_{i+1}) = f(x_i) + f'(x_i)h + \frac{f''(x_i)}{2!}h^2 +  \frac{f'''(x_i)}{3!}h^3 + ....
$$
onde $erro_1$ est√° entre $x_1$ e $x_{i-1}$.
- Aproxima√ß√£o de Taylor para o ponto ùë•ùëñ‚àí1
$$
f(x_{i-1}) = f(x_i) - f'(x_i)h + \frac{f''(x_i)}{2!}h^2 +  \frac{f'''(x_i)}{3!}h^3 + ....
$$
onde $erro_2$ est√° entre $x_{i-1}$ e $x_{i}$.

### Diferen√ßa finita central com dois pontos
- Subtraindo as equa√ß√µes, temos
$$
$$
- Resolvendo para ùëì‚Ä≤(ùë•ùëñ), temos
$$
$$

### Diferen√ßa finita progressiva com tr√™s pontos
- Aproxima ùëì‚Ä≤(ùë•ùëñ) avaliando a fun√ß√£o no ponto e nos dois pontos seguintes ùë•ùëñ+1 e ùë•ùëñ+2.
- Aproxima√ß√£o de Taylor em ùë•ùëñ+1 e ùë•ùëñ+2,
$$
$$

$$
$$
- Equa√ß√µes 1 e 2 s√£o combinadas de forma que os termos com derivada segunda
desapare√ßam.
- Multiplicando Eq. 1 por 4 e subtraindo Eq. 2, temos
$$
$$

Diferen√ßa finita com tr√™s pontos
- Resolvendo em ùëì‚Ä≤(ùë•ùëñ), temos
$$
$$
- Diferen√ßa finita regressiva com tr√™s pontos
$$
$$


## Derivadas de segunda ordem

### F√≥rmulas de diferen√ßas finitas para a segunda derivada
- Usando as mesmas ideias podemos aproximar a derivada segunda de uma fun√ß√£o qualquer
por diferen√ßas finitas.
- A deriva√ß√£o das f√≥rmulas s√£o id√™nticas, por√©m mais tediosas.
- F√≥rmula da diferen√ßa central com tr√™s pontos para a derivada segunda
$$
$$
- Diferen√ßa central com quatro pontos
$$
$$

### F√≥rmulas de diferen√ßas finitas para a segunda derivada
- Diferen√ßa progressiva com tr√™s pontos
$$
$$
- Diferen√ßa regressiva com tr√™s pontos
$$
$$
- Uma infinidade de f√≥rmulas de v√°rias ordens est√£o dispon√≠veis.
- F√≥rmulas de diferencia√ß√£o podem ser obtidas usando polin√¥mios de Lagrange


### Erros na diferencia√ß√£o num√©rica
- Em todas as f√≥rmulas o erro de truncamento √© fun√ß√£o de ‚Ñé.
- ‚Ñé √© o espa√ßamento entre os pontos, i.e. ‚Ñé = ùë•ùëñ+1 ‚àí ùë•ùëñ.
- Com ‚Ñé pequeno o erro de truncamento ser√° pequeno.
- Em geral usa-se a precis√£o da m√°quina, algo como 1ùëí‚àí16.
- O erro de arredondamento depende da precis√£o finita de cada computador.
- Mesmo que ‚Ñé possa ser t√£o pequeno quanto desejado o erro de arredondamento pode crescer quando se diminue ‚Ñé.


## Extrapola√ß√£o de Richardson


- Extrapola√ß√£o de Richardson √© usada para obter uma aproxima√ß√£o mais precisa da derivada
a partir de duas aproxima√ß√µes menos precisas.
- Considere o valor ùê∑ de uma derivada (desconhecida) calculada pela f√≥rmula
$$
$$
onde ùê∑(‚Ñé) aproxima ùê∑ e ùëò2 e ùëò4 s√£o termos de erro.
- O uso da mesma f√≥rmula, por√©m com espa√ßamento ‚Ñé/2 resulta
$$
$$


- A Eq. (4) pode ser rescrita (ap√≥s multiplicar por 4):
$$
$$
- Subtraindo (3) de (5) elimina os termos com ‚Ñé2 e fornece
$$
$$
- Resolvendo (6), temos
$$
$$

- O erro na Eq. (7) √© agora ùëÇ(‚Ñé4). O valor de ùê∑ √© aproximado por
$$
$$
- A partir de duas aproxima√ß√µes de ordem inferiores, obtemos uma aproxima√ß√£o de ùëÇ(‚Ñé4) mais precisa.
- Procedimento a partir de duas aproxima√ß√µes com erro ùëÇ(‚Ñé4) mostra que
$$
$$
- Aproxima√ß√£o ainda mais precisa.


### Exemplo: extrapola√ß√£o de Richardson
- Calcule a derivada de ùëì(ùë•) = 2ùë• ùë• no ponto ùë• = 2.
- Solu√ß√£o exata: $ $
- Solu√ß√£o num√©rica usando diferen√ßa central

```{r}
fx <- function(x) (2^x)/x
fpx <- function(x)(log(2)*(2^x))/
x - (2^x)/x^2
erro <- fpx(x = 2)/
dif_cen(fx = fx, x = 2, h = 0.2)
(erro-1)*100
## [1] 0.345544
```

- Extrapola√ß√£o de Richardson

```{r}
D2 <- dif_cen(fx = fx, x = 2, h = 0.2/2)
D <- dif_cen(fx = fx, x = 2, h = 0.2)
der <- (1/3)*( 4*D2 - D)
erro2 <- fpx(x = 2)/der
(erro2-1)*100
## [1] -0.001585268
```


```{r}
c("Exata" = fpx(x = 2), "Richardson" = der,
"Central" = dif_cen(fx = fx, x = 2, h = 0.2))
## Exata Richardson Central
## 0.3862944 0.3863005 0.3849641
```


## Derivadas parciais

- Para fun√ß√µes com muitas vari√°veis, a derivada parcial da fun√ß√£o em rela√ß√£o a uma das
vari√°veis representa a taxa de varia√ß√£o da fun√ß√£o em rela√ß√£o a essa vari√°vel, mantendo as
demais constantes.
- Assim, as f√≥rmulas de diferen√ßas finitas podem ser usadas no c√°lculo das derivadas parciais.
- As f√≥rmulas s√£o aplicadas em cada uma das vari√°veis, mantendo as outras fixas.
- A mesma ideia se aplica para derivadas de mais alta ordem


### Implementa√ß√£o: derivadas parciais
- Derive 
$$
f(\beta_0, \beta_1) = \sum^n_{i=1}{|y_i - (\beta_0 + \beta_1 x_i)|}
$$

- Para fazer vai calcular derivada de cada beta (o outro fica como contante):
$$
\frac{\partial( \beta_0, \beta_1) }{\partial \beta_0} = ....
$$

$$
\frac{\partial( \beta_0, \beta_1) }{\partial \beta_1} = ....
$$
- F√≥rmula dois pontos central
```{r}
dif_cen <- function(fx, pt, h, ...) {
  df <- (fx(pt + h, ...) - fx(pt - h, ...))/( (pt + h) - (pt - h))
  return(df)
}
```

- Fun√ß√£o a ser diferenciada
```{r}
fx <- function(par, y, x1) {sum ( abs( y - (par[1] + par[2]*x1)) )}
```

- Gradiente usando diferen√ßas finita.
```{r}
grad_fx <- function(fx, par, h, ...) {
  fbeta0 <-
    function(beta0, beta1, y, x)
      fx(par = c(beta0, beta1),
         y = y,
         x = x) #beta1 constante
  fbeta1 <-
    function(beta1, beta0, y, x)
      fx(par = c(beta0, beta1),
         y = y,
         x = x) #beta0 constante
  db0 <-
    dif_cen(
      fx = fbeta0,
      pt = par[1],
      h = h,
      beta1 = par[2],
      y = y,
      x = x
    )
  db1 <-
    dif_cen(
      fx = fbeta1,
      pt = par[2],
      h = h,
      beta0 = par[1],
      y = y,
      x = x
    )
  return(c(db0, db1))
}
```


Exemplo: derivadas parciais

- Simulando $y_i$'s e $x_i$'s.
```{r}
set.seed(123)
x <- runif(100)
y <- rnorm(100, mean = 2 + 3*x, sd = 1)
```

- Gradiente num√©rico
```{r}
grad_fx(fx = fx, par = c(2, 3), h = 0.001, y = y, x1 = x)
## [1] 6.000000 2.272805
```

- Gradiente anal√≠tico
```{r}
c(sum(((y - 2 - 3*x)/abs(y - 2 -3*x))*(-1)),
sum(((y - 2 - 3*x)/abs(y - 2 -3*x))*(-x)))
## abs = modulo
## [1] 6.000000 2.272805
```


## Uso de fun√ß√µes residentes do R para diferencia√ß√£o num√©rica

- Pacote numDeriv implementa derivadas por diferen√ßa finita.
- Gradiente
```{r}
require(numDeriv)
args(grad)
## function (func, x, method = "Richardson", side = NULL, method.args = list(),
## ...)
## NULL
```

- Hessiano
```{r}
args(hessian)
## function (func, x, method = "Richardson", method.args = list(),
## ...)
## NULL
```


- Aplica√ß√£o
```{r}
## Fun√ß√£o a ser diferenciada:
fx <- function(par, y, x1) {sum ( abs( y - (par[1] + par[2]*x1)) )}

## Calculando:
grad(func = fx, x = c(2, 3), y = y, x1 = x)
## [1] 6.000000 2.272805
```

```{r}
hessian(func = fx, x = c(2, 3), y = y, x1 = x)
## [,1] [,2]
## [1,] 58.91271 29.53710
## [2,] 29.53710 48.86648
```


## Integra√ß√£o num√©rica

- Integrais aparecem com frequ√™ncia em c√°lculo de probabilidades.
- A probabilidade de um evento √© a √°rea abaixo de uma curva.
- Em modelos complicados a integral pode n√£o ter solu√ß√£o anal√≠tica.
- Os m√©todos de integra√ß√£o num√©rica, podem ser dividos em tr√™s grupos:
  1. M√©todos baseados em soma finita.
  2. Aproximar a fun√ß√£o por uma outra de f√°cil integra√ß√£o.
  3. Estimar o valor da integral.

- Considere a distribui√ß√£o Gaussiana (ou Normal) com fun√ß√£o densidade probabilidade dada por
$$
f(x; \mu, \sigma^2 ) = \frac{1}{\sqrt{(2 \pi \sigma)}} exp (- \frac{1}{2 \sigma^2}(x - \mu)^2)
$$
- Gr√°fico da fun√ß√£o

Integra√ß√£o num√©rica
- O c√°lculo de uma probabilidade qualquer baseado nesta distribui√ß√£o √© dado pela seguinte
integral
$$
$$

## M√©todo Trapezoidal

- Usa uma fun√ß√£o linear para aproximar o integrando.
- O integrando pode ser aproximado por S√©rie de Taylor
$$
$$
- Integrando analiticamente essa aproxima√ß√£o, tem-se
$$
$$
- Simplificando, obtem-se
$$
$$

## M√©todo de Simpson 1/3

- Aproxima o integrando por um polin√¥mio de segunda ordem.
- Pontos finais ùë•1 = ùëé, ùë•3 = ùëè, e o ponto central, ùë•2 = (ùëé + ùëè)/2.
- O polin√¥mio pode ser escrito na forma:
ùëù(ùë•) = ùõº + ùõΩ(ùë• ‚àí ùë•1) + ùúÜ(ùë• ‚àí ùë•1)(ùë• ‚àí ùë•2) (8)
onde ùõº, ùõΩ e ùúÜ s√£o constantes desconhecidas.
- Impomos a condi√ß√£o que o polin√¥mio deve passar por todos os pontos, ùëù(ùë•1) = ùëì(ùë•1), ùëù(ùë•2) = ùëì(ùë•2) e ùëù(ùë•3) = ùëì(ùë•3).


- Isso resulta em:
$$
$$
- Substituindo em 8 e integrando ùëù(ùë•), obt√©m-se
$$
$$

- A integral √© facilmente calculada com apenas tr√™s avalia√ß√µes da fun√ß√£o.
```{r}
simpson <- function(integrando, a, b, ...){
h <- (b-a)/2
x2 <-(a+b)/2
integral <- (h/3)*(integrando(a,...) +
4*integrando(x2, ...) + integrando(b, ...))
return(integral)
}
```


- Exemplo: calcule ‚à´3
```{r}
fx <- function(x) x^2
simpson(integrando = fx, a = 2, b = 3)
## [1] 6.333333
```


- Solu√ß√£o exata:
$$
$$

## Quadratura Gaussiana


- Os m√©todos trapezoidal e Simpson s√£o muito simples.
- Aproximam o integrando por um polin√¥mio de f√°cil integra√ß√£o.
- Resolvem a integral aproximada.
- Os pontos s√£o igualmente espa√ßados.
- S√£o simples e intuitivos, por√©m de dif√≠cil generaliza√ß√£o.
- A Quadratura Gaussiana √© um dos m√©todos mais populares de integra√ß√£o num√©rica.
- Aplica√ß√µes: modelos mistos n√£o-lineares, an√°lise de dados longitudinais, medidas
repetidas, modelos lineares generalizados mistos, etc.


- Forma geral da quadratura de Gauss:

\begin{equation}
  \tag{9}
  \int_{a}^{b} f(x)dx === \sum^n_{i=1}{C_i f(x_i)}
\end{equation}

onde $C_i$ s√£o pesos e $x_i$ s√£o os pontos de Gauss em $[a, b]$.
- Exemplo 1: para ùëõ = 2 a Eq. 9 tem a forma:
$$
$$
- Exemplo 2: para ùëõ = 3 a Eq. 9 tem a forma:
$$
$$

- Coeficientes ùê∂ùëñ e a localiza√ß√£o dos pontos ùë•ùëñ depende dos valores de ùëõ, ùëé e ùëè.
- ùê∂ùëñ e ùë•ùëñ s√£o determinados de forma que o lado direito da Eq. 9 seja igual ao lado esquerdo
para fun√ß√µes ùëì(ùë•) especificadas.
- A especifica√ß√£o de ùëì(ùë•) vai depender do dom√≠nio de integra√ß√£o.
- Diferentes dom√≠nios levam a diferentes varia√ß√µes do m√©todo



- Dom√≠nios comuns:
1. Gauss-Legendre, Gauss-Jacobi e Gauss-Chebyshev
$$
$$
2. Gauss-Laguerre
$$
$$
3. Gauss-Hermite
$$
$$

No dom√≠nio [‚àí1,1] a forma da quadratura de Gauss √©
$$
$$
- ùê∂ùëñ e ùë•ùëñ s√£o determinados fazendo com que a Eq. 9 seja exata quando
ùëì(ùë•) = 1, ùë•, ùë•2, ùë•3 ‚Ä¶.
- O n√∫mero de casos depende do valor de ùëõ.
- Para ùëõ = 2, tem-se
$$
$$


## Quadratura de Gauss-Legendre

Quadratura de Gauss-Legendre
- As quatro constantes ùê∂1, ùê∂2, ùë•1 e ùë•2 s√£o determinadas fazendo Eq. 10 exata quando
aplicada aos quatro casos:
Caso 1 ùëì(ùë•) = 1 ‚à´1
‚àí1 1ùëëùë• = 2 = ùê∂1 + ùê∂2
Caso 2 ùëì(ùë•) = ùë• ‚à´1
‚àí1 ùë•ùëëùë• = 0 = ùê∂1ùë•1 + ùê∂2ùë•2
Caso 3 ùëì(ùë•) = ùë•2 ‚à´1
‚àí1 ùë•2ùëëùë• = 2
3 = ùê∂1ùë•2
1 + ùê∂2ùë•2
2
Caso 4 ùëì(ùë•) = ùë•3 ‚à´1
‚àí1 ùë•3ùëëùë• = 0 = ùê∂1ùë•3
1 + ùê∂2ùë•3
2
- Sistema n√£o-linear de quatro equa√ß√µes e quatro inc√≥gnitas.
- Podem existir m√∫ltiplas solu√ß√µes.
- Uma solu√ß√£o particular √© obtido por impor que ùë•1 = ‚àíùë•2.
- Pela equa√ß√£o 2, implica que ùê∂1 = ùê∂2 e a solu√ß√£o √©
$$
$$

Exemplo: quadratura de Gauss-Legendre
- Calcule ‚à´1
‚àí1 ùë•2ùëëùë•.
- Usando Gauss-Legendre com dois pontos, tem-se
$$
$$


- Quando ùëì(ùë•) √© uma fun√ß√£o do tipo ùëì(ùë•) = 1, ùëì(ùë•) = ùë•, ùëì(ùë•) = ùë•2 ou ùëì(ùë•) = ùë•3 ou
qualquer combina√ß√£o linear destas a aproxima√ß√£o √© exata.
- Caso contr√°rio o procedimento fornece uma aproxima√ß√£o.
- Exemplo: ùëì(ùë•) = ùëêùëúùë†(ùë•) valor exato √©
$$
$$
- Usando Quadratura de Gauss-Legendre com ùëõ = 2, tem-se
$$
$$


- O n√∫mero de pontos de integra√ß√£o controla a precis√£o da aproxima√ß√£o.
- Em R o pacote pracma fornece os pesos e pontos de integra√ß√£o.
- Exemplo
```{r}
require(pracma)
gaussLegendre(n = 2, a = -1, b = 1)
## $x
## [1] -0.5773503 0.5773503
##
## $w
## [1] 1 1
```

- Baseado nos pontos e pesos de integra√ß√£o √© f√°cil construir fun√ß√µes gen√©ricas para integra√ß√£o num√©rica


- Fun√ß√£o gen√©rica
```{r}
gauss_legendre <- function(integrando, n.pontos, a, b, ...){
pontos <- gaussLegendre(n.pontos, a = a, b = b)
integral <- sum(pontos$w*integrando(pontos$x,...))
return(integral)
}
```


- Exemplo: $ $

```{r}
## n = 2
gauss_legendre(integrando = cos, n.pontos = 2, a = -1, b = 1)
## [1] 1.675824
## n = 10
gauss_legendre(integrando = cos, n.pontos = 10, a = -1, b = 1)
## [1] 1.682942
```

## Quadratura de Gauss-Laguerre

- Gauss-Laguerre resolve integrais do tipo:
$$
$$
- Integral √© aproximada por uma soma ponderada.
$$
$$
- A fun√ß√£o √© avaliada nos pontos de Gauss e pesos de integra√ß√£o.
- Os pesos e pontos de integra√ß√£o s√£o obtidos de forma similar ao caso de Gauss-Legendre, por√©m baseado no polin√¥mio de Laguerre.

- Fun√ß√£o gen√©rica para integra√ß√£o de Gauss-Laguerre

```{r}
gauss_laguerre <- function(integrando, n.pontos, ...) {
  pontos <- gaussLaguerre(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, ...)
                  / exp(-pontos$x))
  return(integral)
}
```

- Exemplo: $ $

```{r}
fx <- function(x, lambda) lambda*exp(-lambda*x)
## n = 2
gauss_laguerre(integrando = fx, n.pontos = 2, lambda = 10)
## [1] 0.04381233
## n = 10
gauss_laguerre(integrando = fx, n.pontos = 10, lambda = 10)
## [1] 0.8981046
## n = 100
gauss_laguerre(integrando = fx, n.pontos = 100, lambda = 10)
## [1] 1
```


## Quadratura de Gauss-Hermite

- Gauss-Hermite resolve integrais do tipo:
$$
$$
- Integral √© aproximada por uma soma ponderada.
$$
$$
- A fun√ß√£o √© avaliada nos pontos de Gauss e pesos de integra√ß√£o.
- Os pesos e pontos de integra√ß√£o s√£o obtidos de forma similar ao caso de Gauss-Legendre, por√©m baseado no polin√¥mio de Hermite.

- Fun√ß√£o gen√©rica para integra√ß√£o de Gauss-Hermite

```{r}
gauss_hermite <- function(integrando, n.pontos, ...) {
  pontos <- gaussHermite(n.pontos)
  integral <- sum(pontos$w * integrando(pontos$x, ...)
                  / exp(-pontos$x ^ 2))
  return(integral)
}
```


Implementa√ß√£o: quadratura de Gauss-Hermite
- Exemplo: $ $
```{r}
## n = 2
gauss_hermite(integrando = dnorm, n.pontos = 2)
## [1] 0.9079431
## n = 10
gauss_hermite(integrando = dnorm, n.pontos = 10)
## [1] 0.9999876
## n = 100
gauss_hermite(integrando = dnorm, n.pontos = 100)
## [1] 1
```

Limita√ß√µes: quadratura de Gauss
- Quadratura de Gauss apresenta duas grandes limita√ß√µes:
1. Os pontos s√£o escolhidos ignorando a fun√ß√£o a ser integrada.
2. O n√∫mero de pontos necess√°rios para a integra√ß√£o cresce como uma pot√™ncia da dimens√£o da
integral.
3. 20 pontos em uma dimens√£o demanda 202 = 400 pontos em duas dimens√µes.
- Espalhar os pontos de forma inteligente diminui o n√∫mero de pontos necess√°rios.


Quadratura de Gauss-Hermite Adaptativa
- Os pontos de integra√ß√£o s√£o centrados e escalonados como se ùëì(ùë•)ùëí‚àíùë•2
fosse a
distribui√ß√£o Gaussiana.
- A m√©dia da aproxima√ß√£o Gaussiana ser√° a modaÃÇ ùë• de ùëôùëõ[ùëì(ùë•)ùëí‚àíùë•2
].
- A vari√¢ncia da aproxima√ß√£o Gaussiana ser√°
$$
$$
- Novos pontos de integra√ß√£o adaptados ser√£o dados por
$$
$$
com correspondentes pesos,
$$
$$

Silde 105

- Como antes, a integral √© aproximada por
$$
$$
- Problema: como encontrar a moda e o hessiano de 
$$
$$
- Analiticamente ou numericamente.
- Caso especial Gauss-Hermite Adaptativa com ùëõ = 1 ‚Üí Aproxima√ß√£o de Laplace

## Aproxima√ß√£o de Laplace

[[ARRUMAR]]

## Integra√ß√£o Monte Carlo

Integra√ß√£o Monte Carlo
- M√©todo simples e geral para resolver integrais.
- Objetivo: estimar o valor da integral de uma fun√ß√£o ùëì(ùë•) em algum dom√≠nio ùê∑ qualquer,
ou seja,
$$
$$
- Seja ùëù(ùë•) uma fdp cujo dom√≠nio coincide com ùê∑.
- Ent√£o, a integral em Eq. 11 √© equivalente a
$$
$$
- A integral corresponde a 
$$
$$

- Algoritmo: integra√ß√£o Monte Carlo
  1. Gere n√∫meros aleat√≥rios de ùëù(ùë•);
  2. Calcule ùëöùëñ = ùëì(ùë•ùëñ)/ùëù(ùë•ùëñ) para cada amostra,ùëñ = 1, ‚Ä¶ , ùëõ.
  3. Calcule a m√©dia ‚àëùëõ
$$
$$
- Implementa√ß√£o para fun√ß√µes com ùê∑ = ‚Ñú.
```{r}
monte.carlo <- function(funcao, n.pontos, ...) {
  pontos <- rnorm(n.pontos)
  norma <- dnorm(pontos)
  integral <- mean(funcao(pontos,...)/norma)
  return(integral)
}
```


- Exemplo: 
$$
$$

```{r}
## Integrando a Normal padr√£o
monte.carlo(funcao = dnorm, n.pontos = 1000)
## [1] 1
## Integrando distribui√ß√£o t com df = 30
monte.carlo(funcao = dt, n.pontos = 1000, df = 30)
## [1] 0.9982789
```
[[ARRUMAR]]

## Otimiza√ß√£o


### Motiva√ß√£o
- Otimiza√ß√£o usa um modelo matem√°tico rigoroso para determinar a solu√ß√£o mais eficiente
para um dado problema.
- Precisamos identificar um objetivo.
- Criar uma medida que mensure a performance. Ex. rendimento, tempo, custo, etc.
- Em geral, qualquer quantidade ou combina√ß√£o de quantidades representada por um
simples n√∫mero.
- Fun√ß√µes perda usuais.
- Perda quadr√°tica: Œ£ùëõ
ùëñ=1(ùë¶ùëñ ‚àí ùúá)2.
- Perda absoluta: Œ£ùëõ
ùëñ=1 |ùë¶ùëñ ‚àí ùúá|.
- Perda minimax: minimize ùëöùëéùë•(|ùë¶ùëñ ‚àí ùúá|).


Otimiza√ß√£o: fun√ß√µes perda
- Graficamente, tem-se
[[ARRUMAR]]
- Objetivo: encontrar o ponto de m√≠nimo da fun√ß√£o perda.


### Classifica√ß√£o dos problemas de otimiza√ß√£o
- Programa√ß√£o linear (LP)
  - Fun√ß√£o objetivo e as restri√ß√µes s√£o lineares.
  - min ùë• ùëê‚ä§ùë•, sujeito a ùê¥ùë• ‚â§ ùëè e ùë• ‚â• 0.
- Programa√ß√£o quadr√°tica (QP)
  - Fun√ß√£o objetivo √© quadr√°tica e as restri√ß√µes s√£o lineares.
  - min ùë•ùë•‚ä§ùëÑùë• + ùëê‚ä§ùë•, sujeito a ùê¥ùë• ‚â§ ùëè e ùë• ‚â• 0.
- Programa√ß√£o n√£o-linear (NLP): fun√ß√£o objetivo ou ao menos uma restri√ß√£o √© n√£o linear.
- Cada classe de problemas tem seus pr√≥prios m√©todos de solu√ß√£o.
- Em R temos pacotes espec√≠ficos para cada tipo de problema.
- Frequentemente, tamb√©m distinguimos se o problema tem ou n√£o restri√ß√µes.
  - Otimiza√ß√£o restrita refere-se a problemas com restri√ß√µes de igualdade ou desigualdades.

### Otimiza√ß√£o em R
- Pacotes populares para otimiza√ß√£o em R.
[[ARRUMAR]]
Tipo de problema Pacote Fun√ß√£o
Prop√≥sito geral (1 dim) Built in `optimize(...)`
Prop√≥sito geral (n dim) Built in `optim(...)`
Programa√ß√£o Linear lpSolve `lp(...)`
Programa√ß√£o quadr√°tica quadprog `solve.QP(...)`
Programa√ß√£o n√£o-linear optimize `optimize()`
optimx `optimx(...)`
- Existe uma infinidade de pacotes com os mais diversos algoritmos implementados em R.
- Todos est√£o listados no Task View - Optimization and Mathematical programming


### Otimiza√ß√£o em R
- A estrutura b√°sica de um otimizador √© sempre a mesma.
```{r eval=FALSE, include=TRUE}
optimizer(objective, constraints, bounds = NULL, types = NULL, maximum = FALSE)
```
- As fun√ß√µes em geral apresentam algum argumento que permite trocar o algoritmo de otimiza√ß√£o.
- Fun√ß√µes nativas do R:
- `optimize()` restrita a problemas unidimensionais.
- Baseado no esquema "Golden section search".
- `optim()` problemas n-dimensionais.
- Restrita a fun√ß√µes com argumentos cont√≠nuous.


### Otimizando fun√ß√µes perda: redu√ß√£o de dados
- Considere as fun√ß√µes perda:
- Perda quadr√°tica: Œ£ùëõùëñ=1(ùë¶ùëñ ‚àí ùúá)2.
(media)
- Perda absoluta: Œ£ùëõùëñ=1 |ùë¶ùëñ ‚àí ùúá|.
(mediana)
- Perda minimax: Minimize ùëöùëéùë•(|ùë¶ùëñ ‚àí ùúá|).
- Seja um conjunto de observa√ß√µes ùë¶ùëñ.
- Encontre o melhor resumo de um n√∫mero baseado em cada uma das fun√ß√µes perda
anteriores.


- Passo 1: implementar as fun√ß√µes objetivo.
  - Perda quadr√°tica
```{r}
perda_quad <- function(mu, dd) { sum((dd-mu)^2) }
```
  
  - Perda absoluta
```{r}
perda_abs <- function(mu, dd) { sum(abs(dd-mu)) }
```

  - Perda minimax
```{r}
perda_minimax <- function(mu, dd) { max(abs(dd-mu)) }
```
  
- Passo 2: obter o conjunto de observa√ß√µes.
```{r}
set.seed(123)
y <- rpois(100, lambda = 3)
## gerou 100 obs de uma poison

##plot(dados_reg_log$Anos, dados_reg_log$Renda, main = "Anos de Exp vs Renda")

##grafico <- ggplot(dados_reg_log,aes(x = Anos, y = Renda, colour = Premium)) + geom_point()
##grafico
```

- Passo 3: otimizando a fun√ß√£o perda.

```{r}
# Perda quadr√°tica
fit_quad <- optimize(f = perda_quad, interval = c(0, 20), dd = y)
# Perda absoluta
fit_abs <- optimize(f = perda_abs, interval = c(0, 20), dd = y)
# Perda minimax
fit_minimax <- optimize(f = perda_minimax, interval = c(0, 20), dd = y)
```

- Perda quadr√°tica
```{r}
fit_quad
## $minimum
## [1] 2.94

## $objective
## [1] 259.64
```

- Perda absoluta
```{r}
fit_abs
## $minimum
## [1] 2.999952

## $objective
## [1] 128.0007
```

- Perda minimax
```{r}
fit_minimax
## $minimum
## [1] 4.000013

## $objective
## [1] 4.000013
```
[[ARRUMAR]]


### Otimiza√ß√£o num√©rica
- Muito f√°cil usar o otimizador num√©rico.
- N√£o precisamos calcular nada.
- Solu√ß√£o para quem n√£o gosta de matem√°tica?
- Como isso √© poss√≠vel?
- O que voc√™s acham?
- Vamos investigar caso a caso.

### Programa√ß√£o linear
- Especifica√ß√£o matem√°tica
- Nota√ß√£o matricial.

- Nota√ß√£o mais compacta.
$$
$$


### Exemplo: programa√ß√£o linear
- Fun√ß√£o objetivo
- Objetivo: maximimizar o lucro total.
- Produtos A e B s√£o vendidos por R$ 25 e R$ 20.
- Restri√ß√£o de recursos
- Produto A precisa de 20 u.p e produto B precisa 12 u.p.
- Apenas 1800 u.p est√£o dispon√≠veis por dia.
- Restri√ß√£o de tempo
- Produtos A e B demoram 1/15 hrs para produzir.
- Um dia de trabalho tem 8 hrs.
- Formula√ß√£o do problema
- Denote $x_1$ e $x_2$ como n√∫mero de itens A e B produzidos.
- Fun√ß√£o objetivo: maximizar o total de vendas
$$
max_{x_1, x_2} 25x_1 + 20x_2
$$
- Sujeito a restri√ß√µes de recursos e tempo.
$$
20x_1 + 12x_2 \le 1800
$$
$$
\frac{1}{15}x_1 + \frac{1}{15}x_2 \le 8
$$

- Restri√ß√µes escritas de forma matricial.
$$
$$

### Exemplo: programa√ß√£o linear
- Solu√ß√£o for√ßa bruta !!
```{r}
x1 <- 0:140
x2 <- 0:140
grid <- expand.grid(x1,x2)
lucro <- function(x) 25*x[1] + 20*x[2]
```

- Restri√ß√£o de recursos.
```{r}
recurso <- function(x) {
out <- 20*x[1] + 12*x[2]
if(out > 1800) out = 0
return(out)
}
```

- Restri√ß√£o de tempo.
```{r}
tempo <- function(x) {
out <- (1/15)*x[1] + (1/15)*x[2]
if(out > 8) out = 0
return(out)
}
```


Exemplo: programa√ß√£o linear
- Graficamente, tem-se
  - Sem restri√ß√µes
  - Restri√ß√£o de recursos
  - Restri√ß√£o de tempo
- A ideia pode ser generalizada para ùëõ restri√ß√µes.
- Algoritmo Simplex.
- Pacote `lpSolve` em R.

### Fun√ß√£o lp(...) do pacote lpSolve.
- Sintaxe geral
```{r}
require(lpSolve)
# lp(direction = "min", objective.in, const.mat, const.dir, const.rhs)
```

### Para o nosso exemplo, tem-se
```{r}
require(lpSolve)
## Carregando pacotes exigidos: lpSolve
objective.in <- c(25, 20) # c's
const.mat <- matrix(c(20, 12, 1/15, 1/15), nrow=2, byrow=TRUE)
const.rhs <- c(1800, 8)
const.dir <- c("<=", "<=")
optimum <- lp(direction = "max", objective.in, const.mat,
              const.dir, const.rhs)
```
- Solu√ß√£o
```{r}
optimum$solution # Solu√ß√£o
## [1] 45 75
optimum$objval # Lucro
## [1] 2625
```

Obs: MMM = "Marketing Mix Model"

## Programa√ß√£o quadr√°tica

- Especifica√ß√£o matem√°tica
$$
$$
- Coeficientes quadr√°ticos D ‚Üí Dmat.
- Coeficientes lineares ùëë ‚Üí dvec.
- Matriz de constantes A ‚Üí Amat.
- Restri√ß√µes de igualdade ou desigualdade ùëè ‚Üí bvec.


Programa√ß√£o quadr√°tica: implementa√ß√£o
- Fun√ß√£o solve.QP(...) pacote quadprog.
- Argumento meq = n fixa as primeiras ùëõ restri√ß√µes como lineares.
```{r}
require(quadprog)
## Carregando pacotes exigidos: quadprog
args(solve.QP)
## function (Dmat, dvec, Amat, bvec, meq = 0, factorized = FALSE)
## NULL
```

- Popular na literatura de Machine Learning.
- Caso particular das m√°quinas de vetores de suporte.
- O problema de regress√£o √© resolvido por minimizar a perda quadr√°tica sob uma restri√ß√£o.
- Por exemplo, tem-se
min
ùõΩ
(ùë¶ ‚àí XùõΩ)‚ä§(ùë¶ ‚àí XùõΩ), sujeito a Œ£ùëì(ùõΩ) ‚â§ ùë†.
- A parte da regress√£o pode ser escrita como
min
ùõΩ
ùë¶‚ä§ùë¶ ‚àí 2ùë¶‚ä§XùõΩ + ùõΩ‚ä§X‚ä§XùõΩ.


- Neste caso, tem-se
D = X‚ä§X e ùëë = ùë¶‚ä§X.
```{r}
n <- 100
x1 <- runif(n)
x2 <- runif(n)
y <- 0 + x1 + x2 + rnorm(n)
X <- cbind( rep(1,n), x1, x2 )
# Regression
r <- lm(y ~ x1 + x2)
```

- Exemplo sem restri√ß√µes.
```{r}
# Optimization
library(quadprog)
# Sem restri√ß√£o apenas como exemplo
Amat = matrix(nr=3,nc=0)
b = numeric()
s <- solve.QP(t(X) %*% X, t(y) %*% X,
Amat = Amat, bvec = b, meq = 0)
# Comparison
coef(r)
## (Intercept) x1 x2
## -0.4138375 1.6987259 1.1433559
s$solution
## [1] -0.4138375 1.6987259 1.1433559
```



- Exemplo com restri√ß√µes (soma igual a 1);
```{r}
# Optimization
# Soma dos betas = 1
Amat <- matrix(c(1,1,1),ncol = 1, nrow = 3)
b = c(1)
s <- solve.QP(t(X) %*% X, t(y) %*% X,
Amat = Amat, bvec = b, meq = 1)
# Comparison
s$solution
## [1] 0.67483269 0.34432273 -0.01915542
sum(s$solution)
## [1] 1
```

- Exemplo com restri√ß√µes (soma ponderada).
```{r}
# Optimization
# Soma dos betas = 1
Amat <- matrix(c(0.4,0.3,0.2),
ncol = 1, nrow = 3)
b = c(1)
s <- solve.QP( t(X) %*% X, t(y) %*% X,
Amat = Amat, bvec = b, meq = 1)
# Comparison
s$solution
## [1] -1.014036 3.732834 1.428822
sum(s$solution*c(0.4,0.3,0.2))
## [1] 1
```


## Programa√ß√£o n√£o-linear

### M√©todos de programa√ß√£o n√£o-linear

- Os m√©todos s√£o em geral categorizados baseado na dimensionalidade
  1. Unidimensional: Golden Section search.
  2. Multidimensional.
- Caso multidimensional, tem-se pelo menos quatro tipos de algoritmos:
  1. N√£o baseados em gradiente: Nelder-Mead;(sem derivada)
  2. Baseados em gradiente: gradiente descendente e varia√ß√µes;(deriva√ß√£o 1a)
  3. Baseados em hessiano: Newton e quasi-Newton (BFGS); (mais de uma derivada)
  4. Algoritmos baseados em simula√ß√£o e ideias gen√©ticas: Simulating Annealing (SANN).
- A fun√ß√£o gen√©rica `optim()` em R fornece interface aos principais algoritmos de otimiza√ß√£o.
- Vamos discutir as principais ideias por tr√°s de cada tipo de algoritmo.
- Existe uma infinidade de varia√ß√µes e implementa√ß√µes.


## M√©todo Golden Section Search

### Programa√ß√£o n√£o-linear: problemas unidimensionais
- O Golden Section Search √© o mais popular e muito eficiente.
- Algoritmo
1. Defina a raz√£o de ouro $ \psi = \frac{\sqrt{5} - 1}{2} = 0,618 $
2. Escolha um intervalo $[a,b]$ que contenha a solu√ß√£o;
3. Avalie $f(x_1)$ onde $x_1 = a + (1 - \psi) (b-a)$ e compare com $f(x_2)$ onde $x_2 = a + \psi (b-a)$;
4. Se $f(x_1) < f(x_2)$ continue a procura em $[a, x_1]$ caso contr√°rio em $[x_2, b]$.
- Em R a fun√ß√£o optimize() implementa este m√©todo.
```{r}
args(optimize)
## function (f, interval, ..., lower = min(interval), upper = max(interval),
## maximum = FALSE, tol = .Machine$double.eps^0.25)
## NULL
```
- Na fun√ß√£o `optim()` esse m√©todo √© chamado de Brent.

### Exemplo: otimiza√ß√£o **unidimensional**
- Minize a fun√ß√£o ùëì(ùë•) = |ùë• ‚àí 2| + 2|ùë• ‚àí 1|.
- Implementando e otimizando.
```{r}
start_time <- Sys.time()
xx <- c()
fx <- function(x) {
  out <- abs(x-2) + 2*abs(x-1)
  xx <<- c(xx, x) 
  ## duplo assignment no global env. Valor vai para fora da fun√ß√£o. Usado para fazer o grafico.
  return(out)
}
out <- optimize(f = fx, interval = c(-3,3))
out
## $minimum
## [1] 1.000021
##
## $objective
## [1] 1.000021


end_time <- Sys.time()
time_taken <- end.time - start.time
time_taken
```

## M√©todo de Nelder-Mead (gradient free) - multidimencional

### M√©todo de Nelder-Mead (gradient free)
- Algoritmo de Nelder-Mead
1. Escolha um simplex com $n + 1$ pontos $p_1(x_1, y_1), ... p_{n+1} (x_{n+1}, y_{n+1})$, sendo $n$ o n√∫mero de par√¢metros.
2. Calcule $f(p_i)$ e ordene por tamanho $ f(p_1) \le f(p_n)$
3. Avalie se o melhor valor √© bom o suficiente, se for, pare.
4. Delete o ponto com maior/menor $f(p_i)$ do simplex.
5. Escolha um novo ponto pro simplex.
6. Volte ao passo 2.

### Algoritmo de Nelder-Mead: escolhendo o novo ponto
  - Ponto central do lado melhor (B):
$$
$$
  - Refletir o simplex para o lado BG.
$$
$$
- Se a fun√ß√£o em R √© menor que em W movemos na dire√ß√£o correta.
1. Op√ß√£o 1: fa√ßa W = R e repita.
2. Op√ß√£o 2: expandir usando o ponto ùê∏ = 2ùëÖ ‚àí ùëÄ e ùëä = ùê∏, repita.
- Se a fun√ß√£o em R e W s√£o iguais contraia W para pr√≥ximo a B, repita.
- A cada passo uma decis√£o l√≥gica precisa ser tomada.

## M√©todos baseado em gradiente

- Use o gradiente de ùëì(ùë•), ou seja, ùëì‚Ä≤(ùë•) para obter a dire√ß√£o de procura.
  1. ùëì‚Ä≤(ùë•) pode ser obtido analiticamente;
  2. ùëì‚Ä≤(ùë•) qualquer aproxima√ß√£o n√∫merica.
- A dire√ß√£o de procura ùë†ùëõ √© o negativo do gradiente no √∫ltimo ponto.
- Passos b√°sicos
  1. Calcule a dire√ß√£o de busca ‚àíùëì‚Ä≤(ùë•).
  2. Obtenha o pr√≥ximo passo ùë•(ùëõ+1) movendo com passo ùõºùëõ na dire√ß√£o de ‚àíùëì‚Ä≤(ùë•).
  3. Tamanho do passo ùõºùëõ pode ser fixo ou vari√°vel.
  4. Repita at√© $ f'(x_i) \thickapprox x$ seja satisfeito.

## M√©todos baseado em hessiano

- Algoritmo de Newton-Raphson.
- Maximizar/minimizar uma fun√ß√£o ùëì(ùë•) √© o mesmo que resolver a equa√ß√£o n√£o-linear
ùëì‚Ä≤(ùë•) = 0.
- Equa√ß√£o de itera√ß√£o
ùë•(ùëñ+1) = ùë•(ùëñ) ‚àí J(x(i))‚àí1ùëì‚Ä≤(ùë•(ùëñ)),
onde J √© a segunda derivada (hessiano) de ùëì(ùë•).
- J(x(i)) pode ser obtida analitica ou numericamente.
- J(x(i)) pode ser aproximada por uma fun√ß√£o mais simples de calcular.
- M√©todos Quasi-Newton (mais famoso BFGS).


M√©todos Quasi-Newton
- M√©todos quasi-Newton tentam imitar o m√©todo de Newton.
- A equa√ß√£o de itera√ß√£o √© dada por
ùë•(ùëñ+1) = ùë•(ùëñ) ‚àí ùõºùëñHùëñùëì‚Ä≤(ùë•(ùëñ)),
onde Hùëñ √© alguma aproxima√ß√£o para o inverso do Hessiano.
- ùõºùëñ √© o tamanho do passo.
- Denote ùõøùëñ = ùë•(ùëñ+1) ‚àí ùë•(ùëñ) e ùõæùëñ = ùëì‚Ä≤(ùë•(ùëñ+1)) ‚àí ùëì‚Ä≤(ùë•(ùëñ)).
- Para obter Hùëñ+1 o algoritmo imp√µe que
Hùëñ+1ùõæùëñ = ùõøùëñ.
- Algoritmo DFP
$$
$$

- Vers√£o melhorada do DFP devido a Broyden, Fletcher, Goldfarb e Shanno (BFGS).
- Aproxima o hessiano por
Hùëñ+1 = Hùëñ ‚àí
$$
$$
- Implementa√ß√µes modernas do BFGS usando wolfe line search para encontrar ùõºùëñ.
- Considere ùúì(ùõº) = ùëì(ùë•(ùëñ) ‚àí ùõºHùëñùëì‚Ä≤(ùë•(ùëñ))), encontre ùõºùëñ tal que
$$
$$
onde ùúá e ùúÇ s√£o constantes com 0 < ùúá ‚â§ ùúÇ < 1.

## M√©todos baseados em simula√ß√£o

- Algoritmo gen√©rico (maximiza√ß√£o):
  1. Gere uma solu√ß√£o aleat√≥ria (ùë•1);
  2. Calcule a fun√ß√£o objetivo no ponto simulado ùëì(ùë•1);
  3. Gere uma solu√ß√£o na vizinhan√ßa (ùë•2) do ponto em (1);
  4. Calcule a fun√ß√£o objetivo no novo ponto ùëì(ùë•2):
  - Se ùëì(ùë•2) > ùëì(ùë•1) mova para ùë•2.
  - Se ùëì(ùë•2) < ùëì(ùë•1) TALVEZ mova para ùë•2.
  5. Repita passos 3-4 at√© atingir algum crit√©rio de converg√™ncia ou n√∫mero m√°ximo de itera√ß√µes.

- Para decidir se um ponto ùë•2 quando ùëì(ùë•2) < ùëì(ùë•1) ser√° aceito, usa-se uma probabilidade
de aceita√ß√£o
ùëé = exp (ùëì(ùë•2) ‚àí ùëì(ùë•1))/ùëá ,
onde ùëá √© a temperatura}* (pense como um tuning).
- Se ùëì(ùë•2) > ùëì(ùë•1) ent√£o ùëé > 1, assim o ùë•2 ser√° aceito com probabilidade 1.
- Se ùëì(ùë•2) < ùëì(ùë•1) ent√£o 0 < ùëé < 1.
- Assim, ùë•2 ser√° aceito se ùëé > ùëà (0,1).
- Amostrador de Metropolis no contexto de MCMC (Markov Chain Monte Carlo).

## Escolhendo o melhor m√©todo

- M√©todo de Newton √© o mais eficiente (menos itera√ß√µes).
- Por√©m, cada itera√ß√£o pode ser cara computacionalmente.
- Cada itera√ß√£o envolve a solu√ß√£o de um sistema ùëù √ó ùëù.
- M√©todos quasi-Newton s√£o eficientes, principalmente se o gradiente for obtido
analiticamente.
- Quando a fun√ß√£o √© suave os m√©todos de Newton e quasi-Newton geralmente convergem.
- M√©todos baseados apenas em gradiente s√£o simples computacionalmente.
- Em geral precisam de tuning o que pode ser dificil na pr√°tica.
- M√©todo de Nelder-Mead √© simples e uma escolha razo√°vel.
- M√©todos baseados em simula√ß√£o s√£o ideal para fun√ß√µes com m√°ximos/minimos locais.
- Em geral s√£o caros computacionalmente e portanto lentos.

- Em R o pacote optimx() fornece fun√ß√µes para avaliar e comparar o desempenho de
m√©todos de otimiza√ß√£o.
- Exemplo: minimizando a Normal bivariada.
- Escrevendo a fun√ß√£o objetivo
```{r}
require(mvtnorm)
fx <- function(xx){-dmvnorm(xx)}
```


- Comparando os diversos algoritmos descritos.
```{r}
require(optimx)
## Carregando pacotes exigidos: optimx
res <- optimx(par = c(-1,1), fn = fx,
method = c("BFGS","Nelder-Mead","CG"))
res
## p1 p2 value fevals gevals
## BFGS -1.772901e-06 1.772901e-06 -0.1591549 13 11
## Nelder-Mead 1.134426e-04 -1.503306e-04 -0.1591549 55 NA
## CG -8.423349e-06 8.423349e-06 -0.1591549 97 49
## niter convcode kkt1 kkt2 xtime
## BFGS NA 0 TRUE TRUE 0.004
## Nelder-Mead NA 0 TRUE TRUE 0.002
## CG NA 0 TRUE TRUE 0.011
```



### Algumas recomenda√ß√µes
- Otimiza√ß√£o trata todos os par√¢metros da mesma forma.
- Cuidado com par√¢metros em escalas muito diferentes.
- Padronizar entradas pode ser uma op√ß√£o.
- Cuidado com par√¢metros restritos.
- Recomenda√ß√µes
- Torne todos os par√¢metros irrestritos.
- Fa√ßa sua fun√ß√£o a prova de erros.
- Entenda quais s√£o as regi√µes que o algoritmo pode falhar.
- Use o m√°ximo poss√≠vel de resultados analiticos.
- Estude o comportamento da sua fun√ß√£o.










