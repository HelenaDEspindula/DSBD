---
title: "Caderno_Inferencia_Estatistica"
output: pdf_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```
# Sumario

# Aula

## Subtitulo

### Silde

# InstrumentaÃ§Ã£o MatemÃ¡tica para EstatÃ­stica â€“ Prof Wagner Hugo Bonat â€“ 09/03/2024

- MatemÃ¡tica (5 partes)
-	Probabilidade (1 parte)
-	InferÃªncia (3 partes)

### TÃ³picos em matemÃ¡tica customizados para DS:

-	Fornecer base matemÃ¡tica para entender e criar tÃ©cnicas de anÃ¡lise de dados
-	VisÃ£o geral e intuitiva
-	Focar nos resultados e suas aplicaÃ§Ãµes 
-	NÃ£o ser exaustivo em cada tÃ³pico ou matematicamente (muito) rigoroso
-	Suporte computacional para compreender conceitos matemÃ¡ticos abstratos
-	Formar uma base sÃ³lida para entender tÃ©cnicas avanÃ§adas:
  -	Modelagem estatÃ­stica
  -	Machine learnig

### O curso nÃ£o Ã© de receitas, Ã© de fundamentos

- Os objetivos desta abordagem sÃ£o:
  -	Desmestificar o processo peos quais os algoritmos resolvem problemas
  -	Mostrar que apesar de existir um conjunto enrme de tÃ©cnicas, muitas delas sÃ£o pequenas melhorias em tÃ©cnicas jÃ¡ existentes
-	Promover um uso qualificado das ferramentas jÃ¡ disponÃ­veis

## Referencias:

-	Deep Learning, Ian Goodfellow and Yoshua Bengio and Aaro Courville, MIT Press, 2016.
-	Mathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo Faisal and Cheng Soon Ong, Cambridge, 2019
-	Livro do prof: MatemÃ¡tica para CiÃªncias de Dados

## O que precisamos saber?

-	CÃ¡lculo Diferencial e Integral
  -	FunÃ§Ãµes, limites e continuidade
  -	Derivadas
  -	Integrais
-	Ãlgebra Matricial
  -	Vetores e escalares
  -	Matrizes
  -	Sistemas de equaÃ§Ãµes lineares
  -	DecomposiÃ§Ãµes matriciais
-	MÃ©todos NumÃ©ricos
  -	Sistemas de equaÃ§Ãµes nÃ£o-lineares
  -	DiferenciaÃ§Ã£o e integraÃ§Ã£o numÃ©rica
  -	OtimizaÃ§Ã£o

## Exemplos motivacionais:

### Classificador binÃ¡rio
Ferramenta popular em modelagem estatÃ­stica e aprendizagem de maquina

Objetivo: classificar um individuo ou observaÃ§Ã£o em uma entre duas categorias

Exemplos:

-	Classificar um paciente como sadio ou doente
-	Classificar um cliente como bom ou mal pagador etc
	
## Diversos algoritmos disponÃ­veis:

-	Arvores de classificaÃ§Ã£o
-	MÃ¡quinas de vetores de suporte
-	Redes neurais
-	Gradient boost
-	RegressÃ£o logÃ­stica Ã© muito popular

## DescriÃ§Ã£o matemÃ¡tica:

- Suponha que temos um conjunto de dados $y_{i}$  para $i=1,â€¦,n$ .
-	Cada $y_{i}  \in [0,1]$ (Ã© zero ou 1) -> sim ou nÃ£o, saudÃ¡vel ou doente etc

Potenciais objetivos:

-	Descrever o relacionamento de $y_{i}$ com um conjunto de variÃ¡veis explanatÃ³rios $x_{ij}$  com $j=1,â€¦,p$
-	Classificar uma nova observaÃ§Ã£o como 0 ou 1

Exemplo - Conjunto de dados com 3 colunas:

- Renda anual do usuÃ¡rio
-	Anos de experiencia do usuÃ¡rio
-	Se Ã© premium ou nÃ£o

Objetivos:

-	Identificar como as covariÃ¡veis renda e anos influenciem a compra premium
-	Predizer se um novo usuÃ¡rio serÃ¡ ou nÃ£o premium
-	Orientar campanha de marketing


```{r}
dados_reg_log <- read.table("./Wagner/reg_log.txt", header = TRUE)

head(dados_reg_log,n =10)

```
```{r}
plot(dados_reg_log$Anos, dados_reg_log$Renda, main = "Anos de Exp vs Renda")
```
```{r}
library(ggplot2)
grafico <- ggplot(dados_reg_log,aes(x = Anos, y = Renda, colour = Premium)) + geom_point()

grafico
```




$i$	$y$	$=f($ 	$x_{i1} = renda$ $x_{i2} = anos)$

$y_{i} = f (x_{ij})$
$y_{i} = f(x_{ij})+erro$
$erro = y_{i}-f (x_{ij} )$


ConstruÃ§Ã£o do classificador:

-	Explicar o modelo que descreve a relaÃ§Ã£o entre $y_{i}$ e $x_{ij}$ (i linha-usuÃ¡rio, j coluna-covariÃ¡vel)

$y=f(renda,xp)$, ou seja,  y Ã© funÃ§Ã£o dependente de renda e xp

-	 Especificar funÃ§Ã£o perda (medida de erro)

$erro=g( y_{i},f(x_{ij}))$ funÃ§Ã£o g

```{r}
f_logit <- function(par, y, renda, anos){
  mu <- 1/(1+exp(-(par[1] + par[2]*renda + par[3]*anos)))
  SQ_logit <- sum((y - mu)^2)
  return(SQ_logit)
}


#f_logit()
```


-	CaracterÃ­sticas satisfaÃ§a duas equaÃ§Ãµes de distÃ¢ncia: 
$d(y,\mu)>0 | y= \mu$     e     $d(y,\mu)=0 | \mu=f(x_{ij})$

Otimizar a funÃ§Ã£o perda:

-	Qual algoritmo escolher?
-	Como implementÃ¡-la?
-	Analisar o modelo ajustando

## Kmeans

ClusterizaÃ§Ã£o usando kmeans

- Agrupar indivÃ­duos semelhantes
-	Individuos no mesmo grupo sejam mais parecidos do que indivÃ­duos em grupos diferentes
-	DistÃ¢ncia da media 



# Math part

## Linha reta

$$y_{i} = \beta_{0} + \beta_{1} * renda$$

## Sigmoide

$$y_{i} = \frac{1}{1 + exp^{ -(\beta_{0} + \beta_{1} * renda +  \beta_{2} * anos)}} $$

Combinando o modelo logistico com a funÃ§Ã£o perda


$$SQ_{logit}(\beta) = \sum_{i=1}^{n}(y_{1} - \frac{1}{1 + exp^{ -(\beta_{0} + \beta_{1} * renda +  \beta_{2} * anos)}})^2 $$

```{r}
# f_logit <- funcao(par, y, renda, anos) {
#   mu <- 1 / (1 + exp(-(par[1] + par[2] * renda + par[3] * anos)))
#   SQ_logit <- sum((y - mu) ^ 2)
#   return(SQ_logit)
# }
```


# CÃ¡lculo Diferencial e Integral

## Problemas convencionais em ciÃªncia de dados

- Problemas convencionais em ciÃªncia de dados
- PrevisÃ£o ou prediÃ§Ã£o â†’ O que vai acontecer?
- ClassificaÃ§Ã£o â†’ Qual o tipo de um determinado objeto?
- Agrupamento â†’ Qual a melhor forma de agregar objetos?
- PrescriÃ§Ã£o â†’ O que devo fazer?


- Como resolvÃª-los?
- Em geral usamos algum tipo de modelo.
- O que Ã© um modelo?
- RepresentaÃ§Ã£o simplificada da realidade.
- Qual o objetivo de um modelo?
- Representar como o cientista imagina ou supÃµe que a realidade estÃ¡ sendo gerada e refletida por meio dos dados.
- CaracterÃ­sticas de um bom modelo
- Deve representar os principais aspectos do fenÃ´meno sendo avaliado.
- Pode conter uma ou mais quantidades desconhecidas (parÃ¢metros).
- Deve permitir generalizaÃ§Ãµes.
- Deve fornecer um resumo rÃ¡pido e interpretÃ¡vel do fenÃ´meno em estudo.
- Deve ser matematicamente preciso e coerente.


## FunÃ§Ãµes

- DefiniÃ§Ã£o: uma funÃ§Ã£o escrita como $y = f(x)$ associa um nÃºmero $y$ a cada valor de $x$.
- $x$ Ã© chamada de variÃ¡vel independente.
- DomÃ­nio de $f(x)$ Ã© a faixa de valores que $x$ pode assumir.
- $y$ Ã© chamada de variÃ¡vel dependente.
- Imagem de $f(x)$ Ã© a faixa de valores que $y$ pode assumir.
- Resumindo temos,

$$ \frac{x \in Dominio}{Independente} \longrightarrow f(x) \longrightarrow \frac{x \in Imagem}{Dependente}$$


- O domÃ­nio e imagem de uma funÃ§Ã£o
sÃ£o intervalos.
- Tipos de intervalos:
  - Intervalo aberto nÃ£o contÃ©m as extremidades: NotaÃ§Ã£o (a,b).
  - Intervalo fechado contÃ©m as extremidades: NotaÃ§Ã£o [a,b].
- O que entra e o que sai de uma funÃ§Ã£o?
  - Naturais: $ {N} = \{0, 1, 2, 3...\} $ {N} = \{0,1,2,3, â€¦ \}$.
  - Inteiros: ${Z} = {â€¦ , -3, -2, -1, 0, 1,2,3, â€¦}$
  - Racionais ${Q} = {ab |a, b \in {Z}, b {!=} 0}$
  - Irracionais: Conjunto de nÃºmeros que nÃ£o sÃ£o racionais.
  - Reais: UniÃ£o de todos os nÃºmeros mencionados acima, notaÃ§Ã£o {R}.
- DistinÃ§Ã£o importante ${R}$ (double) e ${Z}$
(integer).


- Considere a funÃ§Ã£o y = x2.
- Em R temos
```{r}
minha_funcao <- function(x) {
  y <- x^2
  return(y)
}
```

- Avaliando a funÃ§Ã£o em alguns pontos.
```{r}
x_vec <- c(-5, -4, -3, -2, -1,
0, 1, 2, 3, 4, 5) #concatenaÃ§Ã£o
minha_funcao(x = x_vec) #automaticamente vetorizado
```


## FunÃ§Ãµes unidimensionais

- Uma funÃ§Ã£o y = f(x) Ã© dita ser de apenas uma variÃ¡vel (unidimensional). Ou seja, sÃ³ uma entrada
- Pode ser desenhada em um espaÃ§o bidimensional, o chamado {R}2. Gafico de x e y
- O espaÃ§o {R}2 Ã© formado por todas as duplas ordenadas de valores reais.
- A variÃ¡vel dependente y Ã© representada no eixo vertical.
- A variÃ¡vel dependente x Ã© representada no eixo horizontal.

```{r}

## Avaliando a funÃ§Ã£o
y <- minha_funcao(x = x_vec)
## GrÃ¡fico da funÃ§Ã£o
plot(y ~ x_vec, xlab = "x", type = "l",
ylab = expression(y = f(x)))
points(x_vec,y)

## ou com GGPLOT

ggplot(mapping = aes(x_vec,y))

```

## FunÃ§Ãµes parametrizadas

- DefiniÃ§Ã£o - parÃ¢metro Ã© uma quantidade conhecida que indexa ou parametriza uma determinada funÃ§Ã£o.
- Os parÃ¢metros mudam o comportamento da funÃ§Ã£o e descrevem quantidades/caracterÃ­sticas de interesse.
- NotaÃ§Ã£o: $y = f(x - \theta)$, onde $\theta$ denota o parÃ¢metro.
- O conjunto de valores que $\theta$ (theta minusculo) pode assumir Ã© chamado de espaÃ§o paramÃ©trico (theta maiusculo).
- NotaÃ§Ã£o $\theta \in \Theta $.
- Exemplo: $y = (x - \theta)^2$. Theta joga o grafico mais para direita ou esquerda
- Computacionalmente:

```{r}
fx <- function(x, theta) {
out <- (x - theta)^2
return(out)
}
```


```{r}
## Criar grafico
```

## FunÃ§Ãµes com vÃ¡rios parÃ¢metros

- Em geral uma funÃ§Ã£o pode ter vÃ¡rios parÃ¢metros.
- O ideal Ã© que cada parÃ¢metro controle um aspecto da funÃ§Ã£o.
- Exemplo: $y = f(x; \theta)$, onde $\theta$ Ã© um vetor de parÃ¢metros.
- FunÃ§Ã£o com dois parÃ¢metros:
$$ y = \frac{(x - \theta_{1})^2}{\theta_{2}}$$

```{r}
## Criar grafico
```



## Declividade

- A declividade mede a variaÃ§Ã£o Î” no valor de y dividido pela variaÃ§Ã£o no valor de x, ou seja, declividade Ã© $ \frac{\Delta y}{\Delta x}$ (quanto varia y quando mudamos x).
- A declividade do desenho de uma funÃ§Ã£o pode ser constante (A), positiva (B) ou negativa (C).


```{r}
## Criar grafico
```
Figura 4. Exemplos de declividade.

- O intercepto vertical Ã© o ponto no qual o grÃ¡fico cruza o eixo vertical e Ã© obtido quando
x = 0.
Prof




## FunÃ§Ãµes com duas ou mais variÃ¡veis independentes

FunÃ§Ãµes com duas ou mais variÃ¡veis independentes
- DefiniÃ§Ã£o - uma funÃ§Ã£o escrita como y = f(x) associa um nÃºmero y a cada vetor de entrada x. (x Ã© um vetor!)
- x = (x1, â€¦ , xğ‘)âŠ¤ denota um vetor linha transposto (vetor coluna).
- Exemplo: considere a funÃ§Ã£o de duas variÃ¡veis x1 e x2 definida por

$$ f(x1, x2) = âˆš(25 - x21- x22)$$
,avalie a funÃ§Ã£o nos pontos x = (0, 0)trasp, x = (3, 0)transpo= e desenhe seu grÃ¡fico.
- Avaliando nos pontos
y =
âˆš
25 - 02 - 02 = 5 e y =
âˆš
25 - 32 - 02 = 4.

Computacionalmente
- ImplementaÃ§Ã£o computacional
```{r}
fx1x2 <- function(x) {
y = sqrt(25 - x[1]^2 - x[2]^2)
return(y)
}
entrada1 <- c(0, 0)
entrada2 <- c(3, 0)
fx1x2(x = entrada1)
## [1] 5
fx1x2(x = entrada2)
## [1] 4
```

- Avaliando uma funÃ§Ã£o bidimensional.
```{r}

entrada <- matrix(c(entrada1, entrada2),
                  ncol = 2, nrow = 2,
                  byrow = TRUE)
entrada
## [,1] [,2]
## [1,] 0 0
## [2,] 3 0

saida <- c()
for(i in 1:2) {
  saida[i] <- fx1x2(entrada[i,])
}
saida
## [1] 5 4
```



- O grÃ¡fico da funÃ§Ã£o Ã© o conjunto das triplas ordenadas (y, x1, x2) que satisfazem a funÃ§Ã£o.


## Passo-a-passo para desenhar funÃ§Ãµes bidimensionais

- Neste caso estamos no espaÃ§o {R}3.
- (A) Montar uma grade de valores combinando valores para x1 com valores para x2.
- (B) Avaliar a funÃ§Ã£o em cada um dos pontos criados.
- (C) Representar o valor da funÃ§Ã£o no grÃ¡fico. Neste caso usando uma paleta de cores. (poderia ser uma topografia, seria uma hemi-esfera)

```{r}

```

Figura 5. Passo-a-passo para desenhar uma funÃ§Ã£o de duas variÃ¡veis independentes.

GrÃ¡ficos bidimensionais
- Em geral usamos uma grade mais precisa.

curva de nivel ou iso-linha

```{r}

```


Figura 6. IlustraÃ§Ã£o do grÃ¡fico de uma funÃ§Ã£o de duas variÃ¡veis de entrada.

## FunÃ§Ãµes multidimensionais

- DefiniÃ§Ã£o - uma funÃ§Ã£o escrita como y = f(x; \theta) associa um nÃºmero y a cada vetor de entrada x e \theta denota um vetor de parÃ¢metros conhecidos.
- Para funÃ§Ãµes com mais de duas variÃ¡veis de entrada nÃ£o temos uma forma simples de representaÃ§Ã£o grÃ¡fica.
- Em termos prÃ¡ticos as funÃ§Ãµes vÃ£o representar ou modelar situaÃ§Ãµes reais.
- Precisamos de funÃ§Ãµes flexÃ­veis para representar fenÃ´menos complexos.



FunÃ§Ãµes polinÃ´miais
- FunÃ§Ãµes polinÃ´miais sÃ£o funÃ§Ãµes do tipo $y = \beta_{0} + \beta_{1}x + \beta_{2} x^2 + â€¦ \beta_{p} x^p$.
- Exemplo: funÃ§Ãµes polinÃ´miais de grau atÃ© trÃªs.  
  - FunÃ§Ã£o linear: y = ğ›½0 + ğ›½1x.
  - FunÃ§Ã£o quadrÃ¡tica: y = ğ›½0 + ğ›½1x + ğ›½2x2.
  - FunÃ§Ã£o cÃºbica:y = ğ›½0 + ğ›½1x + ğ›½2x2 + ğ›½3x3.
- O grÃ¡fico de uma funÃ§Ã£o quadrÃ¡tica Ã© uma parÃ¡bola aberta para cima se ğ›½2 > 0 ou para baixo se ğ›½2 < 0.
- Graficamente:
```{r}

```


Figura 8. Exemplos de grÃ¡ficos de funÃ§Ãµes polinÃ´miais.

FunÃ§Ãµes do tipo potÃªncia
- FunÃ§Ãµes do tipo potÃªncia sÃ£o funÃ§Ãµes da forma
$$y = x^a$$
em que a Ã© um expoente constante.
- Por definiÃ§Ã£o, $x^0 = 1 $ e note que um
nÃºmero sem expoente estÃ¡ elevado a 1.
- Propriedades importantes:
$$


$$
1. xa(xğ‘) = xa+ğ‘;
2. (xa)ğ‘ = xağ‘;
3. (xğ‘§)a = xa(ğ‘§a);
4. (xğ‘§
)ğ‘ = xğ‘
ğ‘§ğ‘ ;
5. 1
xa = x-a;
6. xa
xğ‘ = xa-ğ‘;
7. âˆš
x = x1/2;
8. a âˆš
x = x1/a;
9. ğ‘ âˆš
xa = xa/ğ‘.


## FunÃ§Ãµes exponenciais

- FunÃ§Ãµes exponenciais sÃ£o funÃ§Ãµes do tipo y = ax onde a Ã© maior que zero e diferente
de 1 e x Ã© o expoente.
- FunÃ§Ãµes exponenciais naturais sÃ£o funÃ§Ãµes exponenciais que tem como base
ğ‘’ = limğ‘›â†’âˆ [1 + (1/ğ‘›)]ğ‘› = 2.718281828.
- Propriedades importantes:
$$
$$
1. ğ‘’0 = 1.
2. ğ‘’1 = ğ‘’ = 2.71828.
3. ğ‘’a(ğ‘’b) = ğ‘’a+b.
4. (ğ‘’a)b = ğ‘’ab.
5. ğ‘’a
ğ‘’b = ğ‘’a-b.

## FunÃ§Ãµes logarÃ­tmicas

- FunÃ§Ãµes logarÃ­tmicas ou logaritmo Ã© a potÃªncia Ã  qual uma dada base deve ser elevada
para se obter um particular nÃºmero.
- Logaritmos comuns utilizam a base 10 e sÃ£o escritos log10.
- Por exemplo, uma vez que 102 = 100, 2 Ã© o log de 100.
- Para qualquer funÃ§Ã£o exponencial y = ax, onde a Ã© a base e x o expoente, loga y = x x Ã©
a potÃªncia Ã  qual a deve ser elevado, para obter-se y.


## RelaÃ§Ãµes entre funÃ§Ãµes logarÃ­tmicas e exponenciais.
- Se log10 y = 2x, entÃ£o y = 102x.
- Se loga y = xğ‘§, entÃ£o y = axğ‘§.
- Se ln y = 5ğ‘¡, entÃ£o y = ğ‘’5ğ‘¡.
- Se y = a3x, entÃ£o loga y = 3x.
- Se y = 106x, entÃ£o log10 y = 6x.
- Se y = ğ‘’ğ‘¡+1, entÃ£o ln y = ğ‘¡ + 1.


## Outras funÃ§Ãµes de interesse
- SigmÃ³ide ou logÃ­stica: y = 1
1+ğ‘’-x .
- Tangente hiperbÃ³lica: y = ğ‘’x-ğ‘’-x
ğ‘’x+ğ‘’-x .
- Linear retificada (ReLU): y = max{0,x}. (maximo entre 0 e x?. Vale 0 atÃ© o 0 e depois "sobe")
- Leaky ReLU: y = max{ğ›¼x, x}, onde ğ›¼ Ã© uma parÃ¢metro conhecido.

##Desenho do grÃ¡fico das funÃ§Ãµes

```{r}

```

## Normal

$$ y= (x-0)^2/\theta$$

$$ exp{-(n - \theta_{1})^2/ \theta_{2}}$$
fazer grafico
 .....normal

## Limites e continuidade

Limite de uma funÃ§Ã£o
- DefiniÃ§Ã£o - se uma funÃ§Ã£o f(x) se aproxima de um nÃºmero ğ¿ conforme x tende a um
nÃºmero a vindo da direita ou da esquerda, dizemos que o limite de f(x) tende a ğ¿
quando x tende a a.
- NotaÃ§Ã£o
lim xâ†’a
f(x) = f(a) = ğ¿.
- O limite pode nÃ£o existir.
- Se o limite de uma funÃ§Ã£o existe ele Ã© Ãºnico.
- Considere o limite
lim
xâ†’1
(x + 1) = 2.



Exemplo
- Considere o limite
lim
xâ†’1
x2 - 1
x - 1
= ?

Ã© 2
- Computacionalmente
```{r}
fx <- function(x) {
out <- (x^2 - 1)/(x - 1)
return(out)
}
fx(x = 1)
## [1] NaN
```



```{r}
## Figura 11. Desenho do grÃ¡fico da funÃ§Ã£o
```

Exemplo
- Note que
$$
$$

- DefiniÃ§Ã£o intuitiva: o limite de uma funÃ§Ã£o Ã© o valor que achamos natural para ela em um determinado ponto.
- Essa funÃ§Ã£o nÃ£o Ã© continua (no ponto)



## Continuidade de uma funÃ§Ã£o
- DefiniÃ§Ã£o - dizemos que uma funÃ§Ã£o Ã© contÃ­nua em x = a se trÃªs condiÃ§Ãµes forem satisfeitas:
  - $f(a)$ existe,
  - $\lim_{x \to a} f(x)$ existe e
  - $\lim_{x \to a} f(x) = f(a)$.
- Continuidade significa que pequenas variaÃ§Ãµes na variÃ¡vel independente levam a pequenas variaÃ§Ãµes na variÃ¡vel dependente.(mudanÃ§as suaves, ou nÃ£o abruptas)
- Teorema do valor intermediÃ¡rio: se a funÃ§Ã£o f(x) Ã© contÃ­nua no intervalo fechado [a,b],
entÃ£o existe pelo menos um nÃºmero ğ‘ em [a,b] tal que f(ğ‘) = ğ‘€.
- ImplicaÃ§Ã£o: se f(x) Ã© contÃ­nua seu grÃ¡fico nÃ£o contÃ©m salto vertical.
- Em geral podemos pensar em funÃ§Ãµes contÃ­nuas como sendo funÃ§Ãµes suaves.

FunÃ§Ã£o nÃ£o contÃ­nua
- Considere a funÃ§Ã£o nÃ£o continua em 0.
$$
\lim_{x \to 0} \frac{|x|}{x} = \{-1   x < 0 e 1 x > 0
$$



```{r}
## Figura 12. FunÃ§Ã£o descontinua.
```

Propriedades de limites
Se limxâ†’ğ‘ f(x) = ğ¿1 e limxâ†’ğ‘ ğ‘”(x) = ğ¿2, entÃ£o
- limxâ†’ğ‘[f(x) + ğ‘”(x)] = limxâ†’ğ‘ f(x) + limxâ†’ğ‘ ğ‘”(x) = ğ¿1 + ğ¿2.
- limxâ†’ğ‘ ğ‘˜f(x) = ğ‘˜ limxâ†’ğ‘ f(x) = ğ‘˜ğ¿1.
- limxâ†’ğ‘ f(x)ğ‘”(x) = limxâ†’ğ‘ f(x) limxâ†’ğ‘ ğ‘”(x) = ğ¿1ğ¿2.
- limxâ†’ğ‘
f(x)
ğ‘”(x) = ğ¿1
ğ¿2
, desde que ğ¿2 {!=} 0.


## Derivadas

- DefiniÃ§Ã£o - derivada ordinÃ¡ria, derivada primeira, ou simplesmente, derivada de uma funÃ§Ã£o y = f(x) em um ponto x = a no domÃ­nio de f Ã© representada por $ ğ‘‘y/ğ‘‘x , yâ€², ğ‘‘f ğ‘‘x$ ou $fâ€²(a)$ Ã© o valor

$$
$$
ğ‘‘y
ğ‘‘x
|x=a = fâ€²(a) = lim
â„â†’0
f(a + â„) - f(a)
â„

$$
\lim_{h \to 0}  = \frac{f(a+h)-f(a)}h
$$

- InterpretaÃ§Ã£o da derivada
- Taxa de mudanÃ§a instÃ¢ntanea.
- No limite quando $x \longrightarrow a$ a derivada Ã© a reta tangente ao ponto $(a, f(a))$.
- EquaÃ§Ã£o da **reta tangente** ao ponto a: y - f(a) = fâ€²(a)(x - a).(coenficiente angular Ã© beta1 -> y = beta0 + beta1*x)

## Exemplo
Obtenha a derivada de $f(x) = -x^2$
$$
f'(x) = 
$$
fâ€²(x) = lim
â„â†’0
f(x + â„) - f(x)
â„
= lim
â„â†’0
-(x + â„)2 - (-x2)
â„
= lim
â„â†’0
-(x2 + 2xâ„ + â„2) + x2
â„
= lim
â„â†’0
-x2 - 2xâ„ - â„2 + x2
â„
=
-2xâ„ - â„2
â„
= lim
â„â†’0
-2x - â„ = -2x
fâ€²(x) = -2x. (1)



Obtenha a reta tangente a f(x) nos
pontos x = 2 e x = -2.
- Temos f(x = 2) = -4 e
fâ€²(x = 2) = -4, assim
y - f(x = 2) = fâ€²(x = 2)(x - 2)
y - (-4) = -4(x - 2)
y + 4 = = -4x + 8
y = 4 - 4x
- Computacionalmente
- f(x) e fâ€²(x).
```{r}
fx <- function(x) {
out <- - x^2
return(out)
}
f_prime <- function(x) {
out <- -2*x
return(out)
}
```


- EquaÃ§Ã£o da reta y = a + b âˆ— x.
```{r}
intercept = (fx(x = 2) - f_prime(x = 2)*2)
slope <- f_prime(x = 2)
c(intercept, slope)
## [1] 4 -4
```

```{r}
## Figura 14. Desenho de uma funÃ§Ã£o e retas tangentes.
```


## Regras de derivaÃ§Ã£o
- Seja ğ‘› {!=} 0 um natural. SÃ£o vÃ¡lidas as
fÃ³rmulas de derivaÃ§Ã£o:
1. Se f(x) = ğ‘ entÃ£o fâ€²(x) = 0.
2. Se f(x) = xğ‘› entÃ£o fâ€²(x) = ğ‘›xğ‘›-1.
3. Se f(x) = x-ğ‘› entÃ£o
fâ€²(x) = -ğ‘›x-ğ‘›-1.
4. Se f(x) = x1/ğ‘› entÃ£o fâ€²(x) = 1
ğ‘›
x 1
ğ‘›
-1.
- Derivada de funÃ§Ãµes especiais
5. Se f(x) = exp(x) entÃ£o
fâ€²(x) = exp(x).
6. Se f(x) = ln(x) entÃ£o
fâ€²(x) = 1
x
, x > 0.
- Sendo, f(x) e ğ‘”(x) derivÃ¡veis em x e ğ‘
uma constante.
7. (f + ğ‘”)â€² = fâ€²(x) + ğ‘”â€²(x).
8. (ğ‘f)â€²(x) = ğ‘fâ€²(x).
9. (f â‹… ğ‘”)â€²(x) = fâ€²(x)ğ‘”(x) + f(x)ğ‘”â€²(x).
10. ( f
ğ‘” )â€²(x) = fâ€²(x)ğ‘”(x)-f(x)ğ‘”â€²(x)
[ğ‘”(x)]2 .
- Exemplo: obtenha a derivada de
f(x) = 2 + 3x.
- SoluÃ§Ã£o: fâ€²(x) = 3.
- Computacionalmente
```{r}
D(expression(2 + 3*x), name = "x")
## [1] 3
```



## Regra da cadeia
- "Uma funÃ§Ã£o dentro da outra"
- Sejam y = f(x) e x = ğ‘”(ğ‘¡) duas funÃ§Ãµes derivÃ¡veis, com ğ¼ \in ğ·f . A funÃ§Ã£o composta
â„(ğ‘¡) = f(ğ‘”(ğ‘¡)) Ã© derivÃ¡vel, sendo
â„â€²(ğ‘¡) = fâ€²(ğ‘”(ğ‘¡))ğ‘”â€²(ğ‘¡), ğ‘¡ \in ğ·ğ‘”.
- Existe uma infinidade de fÃ³rmulas de derivaÃ§Ã£o.
- Na prÃ¡tica Ã© comum usar um software de matemÃ¡tica simbÃ³lica como o wxMaxima.
- Em R as funÃ§Ãµes deriv() e deriv3().


## Exemplo regra da cadeia
- Obtenha a derivada de sin(2x3 - 4x).
1. Note que temos uma funÃ§Ã£o composta (derivada de sen e cos)
sin(ğ‘”(x)), onde ğ‘”(x) = 2x3 - 4x.
2. Usando a regra da cadeia temos:
fâ€²(ğ‘”(x)) = cos(2x3 - 4x) and ğ‘”â€²(x) = 6x2 - 4.
3. Assim, a derivada fica dada por
cos(2x3 - 4x) â‹… (6x2 - 4).
4. Computacionalmente
```{r}
D(expression( sin(2*x^3 - 4*x)), name = "x")
## cos(2 * x^3 - 4 * x) * (2 * (3 * x^2) - 4)
## ou cos(2x^3 - 4x) * (6x^2) - 4)

D(D(expression( sin(2*x^3 - 4*x)), name = "x"), name = "x")
## cos(2 * x^3 - 4 * x) * (2 * (3 * (2 * x))) - sin(2 * x^3 - 4 * x) * (2 * (3 * x^2) - 4) * (2 * (3 * x^2) - 4)
```

## Derivadas de ordem superior
- A derivada fâ€²(x) Ã© tambÃ©m chamada de derivada de primeira ordem e mede a variaÃ§Ã£o da
funÃ§Ã£o original ou primitiva.
- A derivada de segunda ordem denotada por fâ€²â€²(x) mede a taxa de variaÃ§Ã£o da primeira
derivada.
- A derivada de terceira ordem fâ€²â€²â€²(x) mede a taxa de variaÃ§Ã£o da segunda derivada e assim
por diante atÃ© a ğ‘›-Ã©sima derivada.
- NotaÃ§Ã£o comum: ğ‘‘ğ‘›y
ğ‘‘xğ‘› que Ã© interpretada como a ğ‘›-Ã©sima derivada de y em relaÃ§Ã£o a x
- Exemplo: obtenha as derivadas atÃ© a ordem 5 da funÃ§Ã£o y = 2x4 + 5x3 + 2x2.
ğ‘‘y
ğ‘‘x = 8x3 + 15x2 + 4x, ğ‘‘2y
ğ‘‘x2 = 24x2 + 30x + 4, ğ‘‘3y
ğ‘‘x3 = 48x + 30, ğ‘‘4y
ğ‘‘x4 = 48 e ğ‘‘5y
ğ‘‘x5 = 0.
daqui em diante Ã© zero


## MÃ¡ximos e mÃ­nimos
- Dizemos que um ponto $c$ Ã© um valor mÃ¡ximo relativo de $f(x)$ se existir um intervalo aberto contendo $c$, no qual $f(x)$4 esteja definida, tal que $f(c) >= f(x)$ para todo $x$ neste intervalo.
- Dizemos que um ponto $c$ Ã© um valor mÃ­nimo relativo de $f(x)$ se existir um intervalo aberto contendo $c$, no qual f(x) esteja definida, tal que f(ğ‘) â‰¤ f(x) para todo x neste intervalo. (maximo e minimo dentro de um trecho de grafico)

```{r}
## Figura 15. IlustraÃ§Ã£o de mÃ¡ximo/mÃ­nimo relativos.
```

- Multiplicando a funÃ§Ã£o por -1 invertemos a sua concavidade.


## Pontos extremos (pico do morro ou fundo do vale)
- Se f(x) existe para todos os valores de x no intervalo aberto (ğ‘,ğ‘), e se f(x) tem um extremo relativo em ğ‘, em que ğ‘ < ğ‘ < ğ‘, entÃ£o fâ€²(ğ‘) existe e fâ€²(ğ‘) = 0.
- ImplicaÃ§Ã£o - Sendo f(x) diferenciÃ¡vel os pontos extremos de f(x) vÃ£o ocorrer quando fâ€²(x) = 0.
- $f'(x)$ pode ser igual a zero mesmo nÃ£o sendo um extremo relativo.
```{r}
## Figura 16. IlustraÃ§Ã£o de uma funÃ§Ã£o onde derivada zero nÃ£o Ã© ponto extremo.
```


## MÃ¡ximos e mÃ­nimos
Seja $c$ um ponto extremo de uma funÃ§Ã£o $f(x)$ no qual $f'(c) = 0$, e suponha que $f'(x)$ exista
para todos os valores de x em um intervalo aberto contendo ğ‘. Se fâ€²â€²(ğ‘) existe, entÃ£o
- Se fâ€²â€²(ğ‘) < 0, entÃ£o f(x) tem um mÃ¡ximo relativo em ğ‘.
- Se fâ€²â€²(ğ‘) > 0, entÃ£o f(x) tem um mÃ­nimo relativo em ğ‘.
## Concavidade
- Se fâ€²â€²(ğ‘) > 0 o grÃ¡fico de f(x) Ã© cÃ´ncavo para cima em (ğ‘, f(ğ‘));
- Se fâ€²â€²(ğ‘) < 0 o grÃ¡fico de f(x) Ã© cÃ´ncavo para baixo em (ğ‘, f(ğ‘)).



Por que derivadas sÃ£o importantes?
- ObtenÃ§Ã£o de mÃ¡ximo ou mÃ­nino (relativo).

ponto extremo tem inclinaÃ§Ã£o zero (a3 na figura)


```{r}
## Figura 17. IlustraÃ§Ã£o de uma funÃ§Ã£o com a reta tangente.
```

## ReduÃ§Ã£o de dados

VocÃª jÃ¡ trabalha com dados? Se sim,
- Por qual razÃ£o vocÃª usa a mÃ©dia ou a mediana como uma medida resumo?
- VocÃª acha que existe algum procedimento mais geral que leva a obtenÃ§Ã£o destas medidas resumo?
- Se sim, como este procedimento estÃ¡ relacionado com o que vimos em relaÃ§Ã£o a funÃ§Ãµes e seu comportamento?


- Suponha que temos um conjunto de observaÃ§Ãµes $y_{i}$ para $i = 1, â€¦ , n$.
- Objetivo: resumir a informaÃ§Ã£o contida em $y_{i}$ em um Ãºnico nÃºmero, digamos $\mu$.
- Problema: como encontrar $\mu$?
- SoluÃ§Ã£o: encontrar o valor $\mu$, tal que $f(\mu) = \sum_{i=1}^{n} (y_{i} - \mu)^2 $ (soma de quadrados da diferenÃ§a de cada valor para media, ou seja o quanto eu perdi ao trocar os $y$ por $\mu$), seja a menor possÃ­vel.
- Uma vez que temos os nÃºmeros observados $y_{i}$ a Ãºnica quantidade desconhecida Ã©$\mu$.
- Note que $\mu$ Ã© o parÃ¢metro da nossa funÃ§Ã£o.
- A funÃ§Ã£o $f(\mu)$ mede o quanto perdemos em representar $y_{i}$ apenas usando $\mu$.
- FunÃ§Ãµes perda muito populares sÃ£o a perda quadrÃ¡tica, perda absoluta, minmax e a cross entropia.
- dervar e igualar a 0.

FunÃ§Ãµes em R.
```{r}
y <- c(8,9,14,10,10,15,11,5,4,13)
fmu <- function(mu, y) {
out <- sum((y - mu)^2)
return(out)
}
fmu <- Vectorize(fmu, "mu")
fmu(mu = c(10, 12, 0, 8), y = y)
## [1] 117 161
f_prime <- function(mu, y) {
out <- -2*sum(y-mu)
return(out)
}
```

Graficamente
```{r}

```

- Note que o melhor resumo dos dados de um nÃºmero, corresponde ao ponto de mÃ­nimo da funÃ§Ã£o
$$
f(y) = \sum_{i=1}^{n} (y_{i} -\mu )^2
$$

- Como o mÃ­nimo estÃ¡ relacionado com a derivada de $f(\mu)$?


## Exemplo: reduÃ§Ã£o de dados
- No ponto de mÃ­nimo/mÃ¡ximo a inclinaÃ§Ã£o da reta tangente a $f(\mu)$ Ã© zero.
- Denote por ğœ‡Ì‚ o ponto de mÃ­nimo/mÃ¡ximo de ğ‘“(ğœ‡), entÃ£o ğ‘“â€²(ğœ‡)Ì‚ = 0.
- Assim, temos (regra da cadeia!!)

$$ f(y) = \sum_{i=1}^{n} (y_{i} -\mu )^2$$
$$\varepsilon_{i} = y_{i} -\mu$$
$$  f'(\mu) = \sum_{i=1}^{n} (\varepsilon_{i})^2 $$
$$  f'(\mu) = 2 \sum_{i=1}^{n} (y_{i} -\mu) \frac{d}{d \mu} (y_{i} -\mu) $$

$$ f'(\mu) = 2 \sum_{i=1}^{n} (y_{i} -\mu) (-1)$$

$$ f'(\mu) = -2 \sum_{i=1}^{n} (y_{i} -\mu)$$

Exemplo: reduÃ§Ã£o de dados
- Agora precisamos achar o ponto ğœ‡Ì‚ tal que ğ‘“â€²(ğœ‡)Ì‚ = 0.

$$ f'(\mu_{chapeu}) = 0$$

$$  -2 \sum_{i=1}^{n} (y_{i} -\mu_{chapeu}) = 0$$
$$  -\sum_{i=1}^{n} (y_{i} -n \mu_{chapeu}) = 0$$
$$ n\mu_{chapeu} = \sum_{i=1}^{n} y_{i}$$

$$ \mu_{chapeu} = \frac{\sum_{i=1}^{n} y_{i}}{n}$$
OU SEJA MÃ‰DIA!!!

ComentÃ¡rios
- Por qual razÃ£o vocÃª usa a mÃ©dia ou a mediana como uma medida resumo?
  - Minimiza a perda quadrÃ¡tica.
  - Medida Ã³tima no sentido de perda quadrÃ¡tica.
- VocÃª acha que existe algum procedimento mais geral que leva a obtenÃ§Ã£o destas medidas resumo?
  - EspecificaÃ§Ã£o do modelo.
  - Escolha da funÃ§Ã£o perda.
  - Treinamento (otimizaÃ§Ã£o).
- Se sim, como este procedimento estÃ¡ relacionado com o que vimos em relaÃ§Ã£o a funÃ§Ãµes e
seu comportamento?
  - Estudar o comportamento de funÃ§Ãµes.

## Derivadas parciais


- Uma funÃ§Ã£o pode ter mais do que uma variÃ¡vel independente.
- A derivada parcial mede a taxa de variaÃ§Ã£o instantÃ¢nea da variÃ¡vel dependente (ğ‘¦) com relaÃ§Ã£o a variÃ¡vel independente ğ‘¥1, quando a outra variÃ¡vel independente ğ‘¥2 Ã© mantida constante.
- Como obter a derivada parcial?
- A derivada parcial em relaÃ§Ã£o a ğ‘¥1 Ã© obtida derivando ğ‘“(ğ‘¥1, ğ‘¥2) â€œfingindoâ€ que ğ‘¥2 Ã© uma constante.
- A derivada parcial de ğ‘“(ğ‘¥1, ğ‘¥2) em relaÃ§Ã£o a ğ‘¥2 Ã© obtida derivando ğ‘“(ğ‘¥1, ğ‘¥2) mantendo ğ‘¥1
constante.
- A diferenciaÃ§Ã£o parcial segue as mesmas regras da diferenciaÃ§Ã£o ordinÃ¡ria.


Exemplo
Obtenha as derivadas parciais em relaÃ§Ã£o a $x_{1}$ e  $x_{2}$ de $y = 5 x_{1}^{3} + 3 x_{1} x_{2} + 4 x_{2}^{2}$

$$\displaystyle \frac{\partial y}{\partial x_{1}} = 15 x_{1}^{2} + 3 x_{2}$$
ou
```{r}
D(expression( 5 * x^3 + 3 * x * c + 4* c^2 ), name = "x")
```


$$\displaystyle \frac{\partial y}{\partial x_{2}} = 3 x_{1} + 8 x_{2}$$
```{r}
D(expression( 5 * x^3 + 3 * x * c + 4* c^2 ), name = "c")
```



Derivadas parciais de ordem superior
- Derivadas parciais de segunda ordem
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥21
e ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥22
indica que a funÃ§Ã£o foi diferenciada parcialmente em relaÃ§Ã£o a ğ‘¥1 ou ğ‘¥2 duas vezes.
- Derivada parcial cruzada (ou mista)
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥1ğœ•ğ‘¥2
indica que primeiro derivamos em ğ‘¥1 e depois em ğ‘¥2.
- A ordem da derivada cruzada nÃ£o importa (se ambas contÃ­nuas), ou seja
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥1ğœ•ğ‘¥2
=
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥2ğœ•ğ‘¥1
.


Exemplo: derivadas parciais de segunda ordem
- Obtenha as derivadas parciais de atÃ© segunda ordem em relaÃ§Ã£o a ğ‘¥1 e ğ‘¥2 de
ğ‘¦ = 7ğ‘¥31
+ 9ğ‘¥1ğ‘¥2 + 2ğ‘¥52
.
- Derivadas parciais de primeira ordem
ğœ•ğ‘¦
ğœ•ğ‘¥1
= 21ğ‘¥21
+ 9ğ‘¥2,
ğœ•ğ‘¦
ğœ•ğ‘¥2
= 9ğ‘¥1 + 10ğ‘¥42
.
- Derivadas parciais de segunda ordem (segunda derivadas direta)
ğœ•2ğ‘¦
ğœ•ğ‘¥21
= 42ğ‘¥1,
ğœ•2ğ‘¦
ğœ•ğ‘¥22
= 40ğ‘¥32
.
- Derivadas parciais de segunda ordem (termos cruzados)
ğœ•2ğ‘¦
ğœ•ğ‘¥1ğ‘¥2
=
ğœ•21ğ‘¥21
+ 9ğ‘¥2
ğœ•ğ‘¥2
= 9,
ğœ•2ğ‘¦
ğœ•ğ‘¥2ğ‘¥1
=
ğœ•9ğ‘¥1 + 10ğ‘¥42
ğœ•ğ‘¥1
= 9.

- As cruzadas dÃ£o sempre iguais.


## MÃ¡ximos e mÃ­nimos funÃ§Ãµes muldimensionais
- Pontos crÃ­ticos: as derivadas parciais de primeira ordem devem ser iguais a zero **simultaneamente**.
- Derivadas parciais **principais** de segunda ordem no ponto crÃ­tico forem ambas **positivas -> ponto de mÃ­nimo**.
- Derivadas parciais de segunda ordem no ponto crÃ­tico forem ambas **negativas -> ponto de mÃ¡ximo**.
- Outras situaÃ§Ãµes ver material suplementar.


## Exemplo
Considere a funÃ§Ã£o ğ‘¦ = 6ğ‘¥21
âˆ’ 9ğ‘¥1 âˆ’ 3ğ‘¥1ğ‘¥2 âˆ’ 7ğ‘¥2 + 5ğ‘¥22
. Encontre os pontos crÃ­ticos e
determine se sÃ£o de mÃ¡ximo ou minÃ­mo.
- Graficamente
```{r}

```

- Calcular as derivadas parciais de primeira ordem da funÃ§Ã£o
ğ‘¦ = 6ğ‘¥21
âˆ’ 9ğ‘¥1 âˆ’ 3ğ‘¥1ğ‘¥2 âˆ’ 7ğ‘¥2 + 5ğ‘¥22
.
- Derivando em ğ‘¥1, temos
ğœ•ğ‘¦
ğœ•ğ‘¥1
= 12ğ‘¥1 âˆ’ 9 âˆ’ 3ğ‘¥2.
- Derivando em ğ‘¥2, temos
ğœ•ğ‘¦
ğœ•ğ‘¥2
= âˆ’3ğ‘¥1 âˆ’ 7 + 10ğ‘¥2.

- Resolver o sistema de equaÃ§Ãµes
12ğ‘¥1 âˆ’ 9 âˆ’ 3ğ‘¥2 = 0
âˆ’3ğ‘¥1 âˆ’ 7 + 10ğ‘¥2 = 0.
- SoluÃ§Ã£o: ğ‘¥1 = 1 e ğ‘¥2 = 1. ## USA NA PROXIMA

- Verificar se o ponto encontrado Ã© de mÃ­nimo calculando a segunda derivada parcial principal e avaliando o seu sinal.



ğœ•2ğ‘¦
ğœ•ğ‘¥21
=
ğœ•
ğœ•ğ‘¥1
(12ğ‘¥1 âˆ’ 9 âˆ’ 3ğ‘¥2) = 12,
ğœ•2ğ‘¦
ğœ•ğ‘¥22
=
ğœ•
ğœ•ğ‘¥2
(3ğ‘¥1 âˆ’ 7 + 10ğ‘¥2) = 10.


- Calcular as derivadas cruzadas e verificar se o produto das derivadas principais Ã© maior que o produto das cruzadas

ğœ•2ğ‘¦
ğœ•ğ‘¥1ğ‘¥2
=
ğœ•12ğ‘¥1 âˆ’ 9 âˆ’ 3ğ‘¥2
ğœ•ğ‘¥2
= âˆ’3,
ğœ•2ğ‘¦
ğœ•ğ‘¥2ğ‘¥1
=
ğœ• âˆ’ 3ğ‘¥1 âˆ’ 7 + 10ğ‘¥2
ğœ•ğ‘¥2
= âˆ’3.

Assim, temos que
ğœ•2ğ‘¦
ğœ•ğ‘¥21
ğœ•2ğ‘¦
ğœ•ğ‘¥22
 (
ğœ•2ğ‘¦
ğœ•ğ‘¥1ğ‘¥2
)
2
12 â‹… 10 > (âˆ’3)2
120 > 9.

- A funÃ§Ã£o estÃ¡ em um ponto de mÃ­nimo quando examinada de todas as direÃ§Ãµes.

## Gradiente e Hessiano


## Gradiente

- Derivadas de primeira e segunda ordem aparecem com tanta frequÃªncia que receberam nomes especiais.
- O vetor gradiente de uma funÃ§Ã£o ğ‘“(ğ‘¥1,ğ‘¥2) Ã© o **vetor composto pelas derivadas primeira** de ğ‘“(ğ‘¥1,ğ‘¥2) em relaÃ§Ã£o a ğ‘¥1 e ğ‘¥2,
âˆ‡ğ‘“(ğ‘¥1,ğ‘¥2) = (
ğœ•ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥1
,
ğœ•ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥2
)
âŠ¤
.
- A definiÃ§Ã£o estende-se naturalmente para funÃ§Ãµes multidimensionais.
- Sendo, ğ‘“(ğ‘¥) onde ğ‘¥ Ã© um vetor ğ‘ Ã— 1 de variÃ¡veis independentes o vetor gradiente de ğ‘“(ğ‘¥) Ã© dado por
âˆ‡ğ‘“(ğ‘¥) = (
ğœ•ğ‘“(ğ‘¥)
ğœ•ğ‘¥1
, â€¦ ,
ğœ•ğ‘“(ğ‘¥)
ğœ•ğ‘¥ğ‘
)
âŠ¤
.


## Hessiano
- A matriz hessiana de uma funÃ§Ã£o ğ‘“(ğ‘¥1,ğ‘¥2) Ã© a matriz composta pelas **derivadas de segunda ordem** de ğ‘“(ğ‘¥1,ğ‘¥2), na seguinte estrutura
H = (
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥21
ğœ•ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥1ğœ•ğ‘¥2
ğœ•ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥2ğœ•ğ‘¥1
ğœ•2ğ‘“(ğ‘¥1,ğ‘¥2)
ğœ•ğ‘¥22
) .
- E para o caso multidimensional
H =
â›âœâœâœ
â
ğœ•2ğ‘“(ğ‘¥)
ğœ•ğ‘¥21
â‹¯ ğœ•ğ‘“(ğ‘¥)
ğœ•ğ‘¥1ğœ•ğ‘¥ğ‘
â‹® â‹± â‹®
ğœ•ğ‘“(ğ‘¥)
ğœ•ğ‘¥ğ‘ğœ•ğ‘¥1
â‹¯ ğœ•2ğ‘“(ğ‘¥)
ğœ•ğ‘¥2
ğ‘
ââŸâŸâŸ
â 


## SÃ©ries de Taylor

- Suponha que uma funÃ§Ã£o ğ‘“(ğ‘¥) Ã© derivÃ¡vel (ğ‘› + 1) vezes em um intervalo contendo
ğ‘¥ = ğ‘¥0.
- ExpansÃ£o em SÃ©rie de Taylor de ğ‘“(ğ‘¥) em torno de ğ‘¥ = ğ‘¥0 consiste em reescrever ğ‘“(ğ‘¥) da
seguinte forma:
ğ‘“(ğ‘¥) = ğ‘“(ğ‘¥0) + (ğ‘¥ âˆ’ ğ‘¥0)
ğ‘‘ğ‘“(ğ‘¥)
ğ‘‘ğ‘¥
|ğ‘¥=ğ‘¥0 +
(ğ‘¥ âˆ’ ğ‘¥0)2
2!
ğ‘‘2ğ‘“(ğ‘¥)
ğ‘‘ğ‘¥2 |ğ‘¥=ğ‘¥0+ (2)
(ğ‘¥ âˆ’ ğ‘¥0)3
3!
ğ‘‘3ğ‘“(ğ‘¥)
ğ‘‘ğ‘¥3 |ğ‘¥=ğ‘¥0 + â€¦ +
(ğ‘¥ âˆ’ ğ‘¥0)ğ‘›
ğ‘›!
ğ‘‘ğ‘›ğ‘“(ğ‘¥)
ğ‘‘ğ‘¥ğ‘› |ğ‘¥=ğ‘¥0 + ğ‘…ğ‘›(ğ‘¥) (3)
onde o termo ğ‘…ğ‘›(ğ‘¥) Ã© chamado de resÃ­duo ou erro, e dado por
ğ‘…ğ‘›(ğ‘¥) =
(ğ‘¥ âˆ’ ğ‘¥0)ğ‘›+1
(ğ‘› + 1)!
ğ‘‘ğ‘›+1ğ‘“(ğ‘¥)
ğ‘‘ğ‘¥ğ‘›+1 |ğ‘¥=ğœ–
sendo ğœ– um valor entre ğ‘¥ e ğ‘¥0.


## Exemplo
- Seja ğ‘“(ğ‘¥) = exp(ğ‘¥). Determine a expansÃ£o de Taylor de ordens 1 e 2, de ğ‘“(ğ‘¥) ao redor de
ğ‘¥0 = 0.
- AproximaÃ§Ã£o de primeira ordem
ğ‘ƒ1(ğ‘¥) = ğ‘“(ğ‘¥ = 0) + ğ‘“â€²(ğ‘¥ = 0)(ğ‘¥ âˆ’ 0)
= exp(0) + exp(0)(ğ‘¥ âˆ’ 0)
= 1 + ğ‘¥.
- AproximaÃ§Ã£o de segunda ordem
ğ‘ƒ2(ğ‘¥) = ğ‘“(ğ‘¥ = 0) + ğ‘“â€²(ğ‘¥ = 0)(ğ‘¥ âˆ’ 0) +
ğ‘“â€²â€²(ğ‘¥ = 0)
2
(ğ‘¥ âˆ’ 0)2
= exp(0) + exp(0)(ğ‘¥ âˆ’ 0) + exp(0)
2
(ğ‘¥ âˆ’ 0)2
= 1 + ğ‘¥ +
1
2
ğ‘¥2.

Graficos

- Quanto mais se afasta de zero pior fica a aproximaÃ§Ã£o.
- A Tailor em n+1 graus Ã© igual a original


## RegressÃ£o linear simples
- RegressÃ£o linear Ã© uma das tÃ©cnicas mais populares em ciÃªncia de dados.
- Objetivo: descrever o comportamento de uma variÃ¡vel dependente ğ‘¦ por meio do conhecimento de outra variÃ¡vel
independente ğ‘¥.
- Predizer ğ‘¦ dado um valor de ğ‘¥.
- Descrever a relaÃ§Ã£o entre ğ‘¦ e ğ‘¥.
- Exemplo
  - Como o tamanho (em metros quadrados) de um apartamento estÃ¡ associado ao seu preÃ§o (em reais)?
  - Suponha que um conjunto de 20 apartamentos foi medido e avaliado.

Grafico

RegressÃ£o linear simples
- Ideia simples! â†’ O preÃ§o deve ser uma funÃ§Ã£o do tamanho do apartamento.
- FormalizaÃ§Ã£o matemÃ¡tica:
- Denote por ğ‘¦ğ‘– para ğ‘– = 1, â€¦ ,ğ‘› o preÃ§o do apartamento ğ‘– e neste caso ğ‘› = 20.
- Denote por ğ‘¥ğ‘– o tamanho do apartamento ğ‘– em metros quadrados.
- FunÃ§Ã£o relacionando preÃ§o âˆ¼ tamanho
$$ PreÃ§o = f(metroquadrado) $$
$$ y_{i} = f^{*}(x_{i})$$

- Qual Ã© a funÃ§Ã£o ğ‘“âˆ—(ğ‘¥ğ‘–)?
- NÃ£o conhecemos e em geral nunca vamor conhecer ğ‘“âˆ—(ğ‘¥ğ‘–).
- Aproximar ğ‘“âˆ—(ğ‘¥ğ‘–) por outra funÃ§Ã£o ğ‘“(ğ‘¥ğ‘–) conhecida.
- Problema: qual ğ‘“(ğ‘¥ğ‘–) e como fazer a aproximaÃ§Ã£o!

- Uma opÃ§Ã£o Ã© usar a expansÃ£o em sÃ©rie de Taylor para obter uma aproximaÃ§Ã£o.

- AproximaÃ§Ã£o em sÃ©rie de Taylor de primeira ordem
$$ f^{*}(x) = f^{*}(x_0) + (x - x_0)f^{*'}(x) + R_n(x)$$

- Ignorando o termo residual ğ‘…ğ‘›(ğ‘¥)
ğ‘“âˆ—(ğ‘¥) â‰ˆ ğ‘“âˆ—(ğ‘¥0) + (ğ‘¥ âˆ’ ğ‘¥0)ğ‘“âˆ—â€²(ğ‘¥0).

- Rearranjando os termos obtemos
ğ‘“âˆ—(ğ‘¥) â‰ˆ âŸ{ğ‘“âŸâˆ—(âŸğ‘¥0âŸ)âŸâˆ’ ğ‘“âˆ—âŸâ€²(ğ‘¥âŸ0âŸ)ğ‘¥âŸ0}
ğ›½0
+ ğ‘“âŸâˆ—â€²(ğ‘¥0)
ğ›½1
ğ‘¥
ğ‘“âˆ—(ğ‘¥) â‰ˆ ğ›½0 + ğ›½1ğ‘¥.
- De forma equivalente, temos
ğ‘¦ğ‘– = ğ›½0 + ğ›½1ğ‘¥ğ‘– + ğ‘…ğ‘›(ğ‘¥ğ‘–),
em que o termo ğ‘…ğ‘›(ğ‘¥ğ‘–) Ã© o erro cometido em aproximar ğ‘¦ğ‘– por ğ›½0 + ğ›½1ğ‘¥ğ‘–.

- NotaÃ§Ã£o usual ğœ–ğ‘– = ğ‘¦ğ‘– âˆ’ (ğ›½0 + ğ›½1ğ‘¥ğ‘–).
- Note que o erro Ã© uma funÃ§Ã£o dos parÃ¢metros desconhecidos ğ›½0 e ğ›½1.
- Objetivo: minimizar a soma de quadrados dos erros ou resÃ­duos
$$ 
$$

ğ‘†ğ‘„(ğ›½0, ğ›½1) =
ğ‘›Î£
ğ‘–=1
ğœ–2(ğ›½0, ğ›½1)ğ‘–
ğ‘†ğ‘„(ğ›½0, ğ›½1) =
ğ‘›Î£
ğ‘–=1
(ğ‘¦ğ‘– âˆ’ (ğ›½0 + ğ›½1ğ‘¥ğ‘–))2.

- Obter o vetor gradiente
âˆ‡ğ‘†ğ‘„(ğ›½0,ğ›½1) = (
ğœ•ğ‘†ğ‘„(ğ›½0,ğ›½1)
ğœ•ğ›½0
,
ğœ•ğ‘†ğ‘„(ğ›½0, ğ›½1)
ğœ•ğ›½1
) .
- Encontrar ğ›½0Ì‚ e ğ›½1Ì‚ tal que
âˆ‡ğ‘†ğ‘„(ğ›½0Ì‚ ,ğ›½1Ì‚ ) = 0.



1. Chame ğ‘¦ğ‘– âˆ’ (ğ›½0 + ğ›½1ğ‘¥ğ‘–) = ğœ–ğ‘–.
2. Chame ğ›½0 + ğ›½1ğ‘¥ğ‘– = ğœ‡ğ‘–.
3. Assim,
âˆ‡ğ‘†ğ‘„(ğ›½0,ğ›½1) = (
ğœ•ğ‘†ğ‘„(ğ›½0,ğ›½1)
ğœ•ğœ–ğ‘–
ğœ•ğœ–ğ‘–
ğœ‡ğ‘–
ğœ•ğœ‡ğ‘–
ğœ•ğ›½0
,
ğœ•ğ‘†ğ‘„(ğ›½0,ğ›½1)
ğœ•ğœ–ğ‘–
ğœ•ğœ–ğ‘–
ğœ‡ğ‘–
ğœ•ğœ‡ğ‘–
ğœ•ğ›½1
) ,
em que
ğœ•ğ‘†ğ‘„(ğ›½0,ğ›½1)
ğœ•ğœ–ğ‘–
=
ğœ•
ğœ•ğœ–ğ‘–
ğ‘›Î£
ğ‘–=1
ğœ–2
ğ‘–
= 2
ğ‘›Î£
ğ‘–=1
ğœ–ğ‘–.
ğœ•ğœ–ğ‘–
ğœ•ğœ‡ğ‘–
=
ğœ•
ğœ•ğœ‡ğ‘–
(ğ‘¦ğ‘– âˆ’ ğœ‡ğ‘–) = âˆ’1,
ğœ•ğœ‡ğ‘–
ğœ•ğ›½0
=
ğœ•
ğœ•ğ›½0
ğ›½0 + ğ›½1ğ‘¥ğ‘– = 1,
ğœ•ğœ‡ğ‘–
ğœ•ğ›½1
=
ğœ•
ğœ•ğ›½1
ğ›½0 + ğ›½1ğ‘¥ğ‘– = ğ‘¥ğ‘–.


Vetor gradiente
- Portanto,
âˆ‡ğ‘†ğ‘„(ğ›½0,ğ›½1) = (âˆ’2
ğ‘›Î£
ğ‘–=1
ğœ–ğ‘–(1); âˆ’2
ğ‘›Î£
ğ‘–=1
ğœ–ğ‘–ğ‘¥ğ‘–)
= (âˆ’2
ğ‘›Î£
ğ‘–=1
(ğ‘¦ğ‘– âˆ’ ğ›½0 âˆ’ ğ›½1ğ‘¥ğ‘–); âˆ’2
ğ‘›Î£
ğ‘–=1
(ğ‘¦ğ‘– âˆ’ ğ›½0 âˆ’ ğ›½1ğ‘¥ğ‘–)ğ‘¥ğ‘–) .
- Resolver o sistema de equaÃ§Ãµes simultÃ¢neas (derivadas de beta 0 e beta 1)
âˆ’2
ğ‘›Î£
ğ‘–=1
(ğ‘¦ğ‘– âˆ’ ğ›½0Ì‚ âˆ’ ğ›½1Ì‚ ğ‘¥ğ‘–) = 0
âˆ’2
ğ‘›Î£
ğ‘–=1
(ğ‘¦ğ‘– âˆ’ ğ›½0Ì‚ âˆ’ ğ›½1Ì‚ ğ‘¥ğ‘–)ğ‘¥ğ‘– = 0.

- SoluÃ§Ã£o
ğ›½0Ì‚ = ğ‘¦Ì„âˆ’ ğ›½1Ì‚ ğ‘¥,Ì„
ğ›½1Ì‚ =
Î£ğ‘›
ğ‘–=1 ğ‘¦ğ‘–ğ‘¥ğ‘– âˆ’ ğ‘¦Ì„Î£ğ‘›
ğ‘–=1 ğ‘¥ğ‘–
Î£ğ‘›
ğ‘–=1 ğ‘¥2
ğ‘–
âˆ’ ğ‘¥Ì„Î£ğ‘›
ğ‘–=1 ğ‘¥ğ‘–




```{r}
## Carregando a base de dados
dados <- read.table("Wagner/reglinear.csv",
                    header = TRUE)
dados
```

```{r}
## Obtendo beta1
beta1 <- (sum(dados$y*dados$x) -
            mean(dados$y)*sum(dados$x))/
  (sum(dados$x^2) - mean(dados$x)*sum(dados$x))
# Obtendo beta0
beta0 <- mean(dados$y) - beta1*mean(dados$x)
c(beta0, beta1)
## [1] 2622.752 3608.499
## Verificando
```



```{r}
coef(lm(y ~ x, data = dados))
## (Intercept) x
## 2622.752 3608.499
```
Modelo:
ychapeu = 2622.752 + 3608.499* metrosquadrados


## DiscussÃ£o
- Derivadas sÃ£o essenciais em estatÃ­stica.
- Maximizar/minimizar funÃ§Ãµes perda/objetivo.
- O cÃ¡lculo Ã© por vezes difÃ­cil e tedioso.
- SoluÃ§Ã£o de sistemas lineares Ã© tedioso quando possÃ­vel.
- Ãlgebra linear ajuda a generalizar as soluÃ§Ãµes.
- Em situaÃ§Ãµes mais gerais expressÃµes analÃ­ticas nÃ£o serÃ£o possÃ­veis de obter.
- MÃ©todos numÃ©ricos para resoluÃ§Ã£o de sistemas lineares.
- MÃ©todos numÃ©ricos para resoluÃ§Ã£o de sistemas nÃ£o-lineares.
- MÃ©todos de otimizaÃ§Ã£o numÃ©rica.



