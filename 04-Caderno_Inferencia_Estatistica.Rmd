---
title: "Caderno_Inferencia_Estatistica"
output: pdf_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```
# Sumario

# Aula

## Subtitulo

### Silde

# Instrumenta√ß√£o Matem√°tica para Estat√≠stica ‚Äì Prof Wagner Hugo Bonat ‚Äì 09/03/2024

- Matem√°tica (5 partes)
-	Probabilidade (1 parte)
-	Infer√™ncia (3 partes)

### T√≥picos em matem√°tica customizados para DS:

-	Fornecer base matem√°tica para entender e criar t√©cnicas de an√°lise de dados
-	Vis√£o geral e intuitiva
-	Focar nos resultados e suas aplica√ß√µes 
-	N√£o ser exaustivo em cada t√≥pico ou matematicamente (muito) rigoroso
-	Suporte computacional para compreender conceitos matem√°ticos abstratos
-	Formar uma base s√≥lida para entender t√©cnicas avan√ßadas:
  -	Modelagem estat√≠stica
  -	Machine learnig

### O curso n√£o √© de receitas, √© de fundamentos

- Os objetivos desta abordagem s√£o:
  -	Desmestificar o processo peos quais os algoritmos resolvem problemas
  -	Mostrar que apesar de existir um conjunto enrme de t√©cnicas, muitas delas s√£o pequenas melhorias em t√©cnicas j√° existentes
-	Promover um uso qualificado das ferramentas j√° dispon√≠veis

## Referencias:

-	Deep Learning, Ian Goodfellow and Yoshua Bengio and Aaro Courville, MIT Press, 2016.
-	Mathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo Faisal and Cheng Soon Ong, Cambridge, 2019
-	Livro do prof: Matem√°tica para Ci√™ncias de Dados

## O que precisamos saber?

-	C√°lculo Diferencial e Integral
  -	Fun√ß√µes, limites e continuidade
  -	Derivadas
  -	Integrais
-	√Ålgebra Matricial
  -	Vetores e escalares
  -	Matrizes
  -	Sistemas de equa√ß√µes lineares
  -	Decomposi√ß√µes matriciais
-	M√©todos Num√©ricos
  -	Sistemas de equa√ß√µes n√£o-lineares
  -	Diferencia√ß√£o e integra√ß√£o num√©rica
  -	Otimiza√ß√£o

## Exemplos motivacionais:

### Classificador bin√°rio
Ferramenta popular em modelagem estat√≠stica e aprendizagem de maquina

Objetivo: classificar um individuo ou observa√ß√£o em uma entre duas categorias

Exemplos:

-	Classificar um paciente como sadio ou doente
-	Classificar um cliente como bom ou mal pagador etc
	
## Diversos algoritmos dispon√≠veis:

-	Arvores de classifica√ß√£o
-	M√°quinas de vetores de suporte
-	Redes neurais
-	Gradient boost
-	Regress√£o log√≠stica √© muito popular

## Descri√ß√£o matem√°tica:

- Suponha que temos um conjunto de dados $y_{i}$  para $i=1,‚Ä¶,n$ .
-	Cada $y_{i}  \in [0,1]$ (√© zero ou 1) -> sim ou n√£o, saud√°vel ou doente etc

Potenciais objetivos:

-	Descrever o relacionamento de $y_{i}$ com um conjunto de vari√°veis explanat√≥rios $x_{ij}$  com $j=1,‚Ä¶,p$
-	Classificar uma nova observa√ß√£o como 0 ou 1

Exemplo - Conjunto de dados com 3 colunas:

- Renda anual do usu√°rio
-	Anos de experiencia do usu√°rio
-	Se √© premium ou n√£o

Objetivos:

-	Identificar como as covari√°veis renda e anos influenciem a compra premium
-	Predizer se um novo usu√°rio ser√° ou n√£o premium
-	Orientar campanha de marketing


```{r}
dados_reg_log <- read.table("./Wagner/reg_log.txt", header = TRUE)

head(dados_reg_log,n =10)

```
```{r}
plot(dados_reg_log$Anos, dados_reg_log$Renda, main = "Anos de Exp vs Renda")
```
```{r}
library(ggplot2)
grafico <- ggplot(dados_reg_log,aes(x = Anos, y = Renda, colour = Premium)) + geom_point()

grafico
```




$i$	$y$	$=f($ 	$x_{i1} = renda$ $x_{i2} = anos)$

$y_{i} = f (x_{ij})$
$y_{i} = f(x_{ij})+erro$
$erro = y_{i}-f (x_{ij} )$


Constru√ß√£o do classificador:

-	Explicar o modelo que descreve a rela√ß√£o entre $y_{i}$ e $x_{ij}$ (i linha-usu√°rio, j coluna-covari√°vel)

$y=f(renda,xp)$, ou seja,  y √© fun√ß√£o dependente de renda e xp

-	 Especificar fun√ß√£o perda (medida de erro)

$erro=g( y_{i},f(x_{ij}))$ fun√ß√£o g

```{r}
f_logit <- function(par, y, renda, anos){
  mu <- 1/(1+exp(-(par[1] + par[2]*renda + par[3]*anos)))
  SQ_logit <- sum((y - mu)^2)
  return(SQ_logit)
}


#f_logit()
```


-	Caracter√≠sticas satisfa√ßa duas equa√ß√µes de dist√¢ncia: 
$d(y,\mu)>0 | y= \mu$     e     $d(y,\mu)=0 | \mu=f(x_{ij})$

Otimizar a fun√ß√£o perda:

-	Qual algoritmo escolher?
-	Como implement√°-la?
-	Analisar o modelo ajustando

## Kmeans

Clusteriza√ß√£o usando kmeans

- Agrupar indiv√≠duos semelhantes
-	Individuos no mesmo grupo sejam mais parecidos do que indiv√≠duos em grupos diferentes
-	Dist√¢ncia da media 



# Math part

## Linha reta

$$y_{i} = \beta_{0} + \beta_{1} * renda$$

## Sigmoide

$$y_{i} = \frac{1}{1 + exp^{ -(\beta_{0} + \beta_{1} * renda +  \beta_{2} * anos)}} $$

Combinando o modelo logistico com a fun√ß√£o perda


$$SQ_{logit}(\beta) = \sum_{i=1}^{n}(y_{1} - \frac{1}{1 + exp^{ -(\beta_{0} + \beta_{1} * renda +  \beta_{2} * anos)}})^2 $$

```{r}
# f_logit <- funcao(par, y, renda, anos) {
#   mu <- 1 / (1 + exp(-(par[1] + par[2] * renda + par[3] * anos)))
#   SQ_logit <- sum((y - mu) ^ 2)
#   return(SQ_logit)
# }
```


# C√°lculo Diferencial e Integral

## Problemas convencionais em ci√™ncia de dados

- Problemas convencionais em ci√™ncia de dados
- Previs√£o ou predi√ß√£o ‚Üí O que vai acontecer?
- Classifica√ß√£o ‚Üí Qual o tipo de um determinado objeto?
- Agrupamento ‚Üí Qual a melhor forma de agregar objetos?
- Prescri√ß√£o ‚Üí O que devo fazer?


- Como resolv√™-los?
- Em geral usamos algum tipo de modelo.
- O que √© um modelo?
- Representa√ß√£o simplificada da realidade.
- Qual o objetivo de um modelo?
- Representar como o cientista imagina ou sup√µe que a realidade est√° sendo gerada e refletida por meio dos dados.
- Caracter√≠sticas de um bom modelo
- Deve representar os principais aspectos do fen√¥meno sendo avaliado.
- Pode conter uma ou mais quantidades desconhecidas (par√¢metros).
- Deve permitir generaliza√ß√µes.
- Deve fornecer um resumo r√°pido e interpret√°vel do fen√¥meno em estudo.
- Deve ser matematicamente preciso e coerente.


## Fun√ß√µes

- Defini√ß√£o: uma fun√ß√£o escrita como $y = f(x)$ associa um n√∫mero $y$ a cada valor de $x$.
- $x$ √© chamada de vari√°vel independente.
- Dom√≠nio de $f(x)$ √© a faixa de valores que $x$ pode assumir.
- $y$ √© chamada de vari√°vel dependente.
- Imagem de $f(x)$ √© a faixa de valores que $y$ pode assumir.
- Resumindo temos,

$$ \frac{x \in Dominio}{Independente} \longrightarrow f(x) \longrightarrow \frac{x \in Imagem}{Dependente}$$


- O dom√≠nio e imagem de uma fun√ß√£o
s√£o intervalos.
- Tipos de intervalos:
  - Intervalo aberto n√£o cont√©m as extremidades: Nota√ß√£o (a,b).
  - Intervalo fechado cont√©m as extremidades: Nota√ß√£o [a,b].
- O que entra e o que sai de uma fun√ß√£o?
  - Naturais: $ {N} = \{0, 1, 2, 3...\} $ {N} = \{0,1,2,3, ‚Ä¶ \}$.
  - Inteiros: ${Z} = {‚Ä¶ , -3, -2, -1, 0, 1,2,3, ‚Ä¶}$
  - Racionais ${Q} = {ab |a, b \in {Z}, b {!=} 0}$
  - Irracionais: Conjunto de n√∫meros que n√£o s√£o racionais.
  - Reais: Uni√£o de todos os n√∫meros mencionados acima, nota√ß√£o {R}.
- Distin√ß√£o importante ${R}$ (double) e ${Z}$
(integer).


- Considere a fun√ß√£o y = x2.
- Em R temos
```{r}
minha_funcao <- function(x) {
  y <- x^2
  return(y)
}
```

- Avaliando a fun√ß√£o em alguns pontos.
```{r}
x_vec <- c(-5, -4, -3, -2, -1,
0, 1, 2, 3, 4, 5) #concatena√ß√£o
minha_funcao(x = x_vec) #automaticamente vetorizado
```


## Fun√ß√µes unidimensionais

- Uma fun√ß√£o y = f(x) √© dita ser de apenas uma vari√°vel (unidimensional). Ou seja, s√≥ uma entrada
- Pode ser desenhada em um espa√ßo bidimensional, o chamado {R}2. Gafico de x e y
- O espa√ßo {R}2 √© formado por todas as duplas ordenadas de valores reais.
- A vari√°vel dependente y √© representada no eixo vertical.
- A vari√°vel dependente x √© representada no eixo horizontal.

```{r}

## Avaliando a fun√ß√£o
y <- minha_funcao(x = x_vec)
## Gr√°fico da fun√ß√£o
plot(y ~ x_vec, xlab = "x", type = "l",
ylab = expression(y = f(x)))
points(x_vec,y)

## ou com GGPLOT

ggplot(mapping = aes(x_vec,y))

```

## Fun√ß√µes parametrizadas

- Defini√ß√£o - par√¢metro √© uma quantidade conhecida que indexa ou parametriza uma determinada fun√ß√£o.
- Os par√¢metros mudam o comportamento da fun√ß√£o e descrevem quantidades/caracter√≠sticas de interesse.
- Nota√ß√£o: $y = f(x - \theta)$, onde $\theta$ denota o par√¢metro.
- O conjunto de valores que $\theta$ (theta minusculo) pode assumir √© chamado de espa√ßo param√©trico (theta maiusculo).
- Nota√ß√£o $\theta \in \Theta $.
- Exemplo: $y = (x - \theta)^2$. Theta joga o grafico mais para direita ou esquerda
- Computacionalmente:

```{r}
fx <- function(x, theta) {
out <- (x - theta)^2
return(out)
}
```


```{r}
## Criar grafico
```

## Fun√ß√µes com v√°rios par√¢metros

- Em geral uma fun√ß√£o pode ter v√°rios par√¢metros.
- O ideal √© que cada par√¢metro controle um aspecto da fun√ß√£o.
- Exemplo: $y = f(x; \theta)$, onde $\theta$ √© um vetor de par√¢metros.
- Fun√ß√£o com dois par√¢metros:
$$ y = \frac{(x - \theta_{1})^2}{\theta_{2}}$$

```{r}
## Criar grafico
```



## Declividade

- A declividade mede a varia√ß√£o Œî no valor de y dividido pela varia√ß√£o no valor de x, ou seja, declividade √© $ \frac{\Delta y}{\Delta x}$ (quanto varia y quando mudamos x).
- A declividade do desenho de uma fun√ß√£o pode ser constante (A), positiva (B) ou negativa (C).


```{r}
## Criar grafico
```
Figura 4. Exemplos de declividade.

- O intercepto vertical √© o ponto no qual o gr√°fico cruza o eixo vertical e √© obtido quando
x = 0.
Prof




## Fun√ß√µes com duas ou mais vari√°veis independentes

Fun√ß√µes com duas ou mais vari√°veis independentes
- Defini√ß√£o - uma fun√ß√£o escrita como y = f(x) associa um n√∫mero y a cada vetor de entrada x. (x √© um vetor!)
- x = (x1, ‚Ä¶ , xùëù)‚ä§ denota um vetor linha transposto (vetor coluna).
- Exemplo: considere a fun√ß√£o de duas vari√°veis x1 e x2 definida por

$$ f(x1, x2) = ‚àö(25 - x21- x22)$$
,avalie a fun√ß√£o nos pontos x = (0, 0)trasp, x = (3, 0)transpo= e desenhe seu gr√°fico.
- Avaliando nos pontos
y =
‚àö
25 - 02 - 02 = 5 e y =
‚àö
25 - 32 - 02 = 4.

Computacionalmente
- Implementa√ß√£o computacional
```{r}
fx1x2 <- function(x) {
y = sqrt(25 - x[1]^2 - x[2]^2)
return(y)
}
entrada1 <- c(0, 0)
entrada2 <- c(3, 0)
fx1x2(x = entrada1)
## [1] 5
fx1x2(x = entrada2)
## [1] 4
```

- Avaliando uma fun√ß√£o bidimensional.
```{r}

entrada <- matrix(c(entrada1, entrada2),
                  ncol = 2, nrow = 2,
                  byrow = TRUE)
entrada
## [,1] [,2]
## [1,] 0 0
## [2,] 3 0

saida <- c()
for(i in 1:2) {
  saida[i] <- fx1x2(entrada[i,])
}
saida
## [1] 5 4
```



- O gr√°fico da fun√ß√£o √© o conjunto das triplas ordenadas (y, x1, x2) que satisfazem a fun√ß√£o.


## Passo-a-passo para desenhar fun√ß√µes bidimensionais

- Neste caso estamos no espa√ßo {R}3.
- (A) Montar uma grade de valores combinando valores para x1 com valores para x2.
- (B) Avaliar a fun√ß√£o em cada um dos pontos criados.
- (C) Representar o valor da fun√ß√£o no gr√°fico. Neste caso usando uma paleta de cores. (poderia ser uma topografia, seria uma hemi-esfera)

```{r}

```

Figura 5. Passo-a-passo para desenhar uma fun√ß√£o de duas vari√°veis independentes.

Gr√°ficos bidimensionais
- Em geral usamos uma grade mais precisa.

curva de nivel ou iso-linha

```{r}

```


Figura 6. Ilustra√ß√£o do gr√°fico de uma fun√ß√£o de duas vari√°veis de entrada.

## Fun√ß√µes multidimensionais

- Defini√ß√£o - uma fun√ß√£o escrita como y = f(x; \theta) associa um n√∫mero y a cada vetor de entrada x e \theta denota um vetor de par√¢metros conhecidos.
- Para fun√ß√µes com mais de duas vari√°veis de entrada n√£o temos uma forma simples de representa√ß√£o gr√°fica.
- Em termos pr√°ticos as fun√ß√µes v√£o representar ou modelar situa√ß√µes reais.
- Precisamos de fun√ß√µes flex√≠veis para representar fen√¥menos complexos.



Fun√ß√µes polin√¥miais
- Fun√ß√µes polin√¥miais s√£o fun√ß√µes do tipo $y = \beta_{0} + \beta_{1}x + \beta_{2} x^2 + ‚Ä¶ \beta_{p} x^p$.
- Exemplo: fun√ß√µes polin√¥miais de grau at√© tr√™s.  
  - Fun√ß√£o linear: y = ùõΩ0 + ùõΩ1x.
  - Fun√ß√£o quadr√°tica: y = ùõΩ0 + ùõΩ1x + ùõΩ2x2.
  - Fun√ß√£o c√∫bica:y = ùõΩ0 + ùõΩ1x + ùõΩ2x2 + ùõΩ3x3.
- O gr√°fico de uma fun√ß√£o quadr√°tica √© uma par√°bola aberta para cima se ùõΩ2 > 0 ou para baixo se ùõΩ2 < 0.
- Graficamente:
```{r}

```


Figura 8. Exemplos de gr√°ficos de fun√ß√µes polin√¥miais.

Fun√ß√µes do tipo pot√™ncia
- Fun√ß√µes do tipo pot√™ncia s√£o fun√ß√µes da forma
$$y = x^a$$
em que a √© um expoente constante.
- Por defini√ß√£o, $x^0 = 1 $ e note que um
n√∫mero sem expoente est√° elevado a 1.
- Propriedades importantes:
$$


$$
1. xa(xùëê) = xa+ùëê;
2. (xa)ùëê = xaùëê;
3. (xùëß)a = xa(ùëßa);
4. (xùëß
)ùëê = xùëê
ùëßùëê ;
5. 1
xa = x-a;
6. xa
xùëê = xa-ùëê;
7. ‚àö
x = x1/2;
8. a ‚àö
x = x1/a;
9. ùëê ‚àö
xa = xa/ùëê.


## Fun√ß√µes exponenciais

- Fun√ß√µes exponenciais s√£o fun√ß√µes do tipo y = ax onde a √© maior que zero e diferente
de 1 e x √© o expoente.
- Fun√ß√µes exponenciais naturais s√£o fun√ß√µes exponenciais que tem como base
ùëí = limùëõ‚Üí‚àû [1 + (1/ùëõ)]ùëõ = 2.718281828.
- Propriedades importantes:
$$
$$
1. ùëí0 = 1.
2. ùëí1 = ùëí = 2.71828.
3. ùëía(ùëíb) = ùëía+b.
4. (ùëía)b = ùëíab.
5. ùëía
ùëíb = ùëía-b.

## Fun√ß√µes logar√≠tmicas

- Fun√ß√µes logar√≠tmicas ou logaritmo √© a pot√™ncia √† qual uma dada base deve ser elevada
para se obter um particular n√∫mero.
- Logaritmos comuns utilizam a base 10 e s√£o escritos log10.
- Por exemplo, uma vez que 102 = 100, 2 √© o log de 100.
- Para qualquer fun√ß√£o exponencial y = ax, onde a √© a base e x o expoente, loga y = x x √©
a pot√™ncia √† qual a deve ser elevado, para obter-se y.


## Rela√ß√µes entre fun√ß√µes logar√≠tmicas e exponenciais.
- Se log10 y = 2x, ent√£o y = 102x.
- Se loga y = xùëß, ent√£o y = axùëß.
- Se ln y = 5ùë°, ent√£o y = ùëí5ùë°.
- Se y = a3x, ent√£o loga y = 3x.
- Se y = 106x, ent√£o log10 y = 6x.
- Se y = ùëíùë°+1, ent√£o ln y = ùë° + 1.


## Outras fun√ß√µes de interesse
- Sigm√≥ide ou log√≠stica: y = 1
1+ùëí-x .
- Tangente hiperb√≥lica: y = ùëíx-ùëí-x
ùëíx+ùëí-x .
- Linear retificada (ReLU): y = max{0,x}. (maximo entre 0 e x?. Vale 0 at√© o 0 e depois "sobe")
- Leaky ReLU: y = max{ùõºx, x}, onde ùõº √© uma par√¢metro conhecido.

##Desenho do gr√°fico das fun√ß√µes

```{r}

```

## Normal

$$ y= (x-0)^2/\theta$$

$$ exp{-(n - \theta_{1})^2/ \theta_{2}}$$
fazer grafico
 .....normal

## Limites e continuidade

Limite de uma fun√ß√£o
- Defini√ß√£o - se uma fun√ß√£o f(x) se aproxima de um n√∫mero ùêø conforme x tende a um
n√∫mero a vindo da direita ou da esquerda, dizemos que o limite de f(x) tende a ùêø
quando x tende a a.
- Nota√ß√£o
lim x‚Üía
f(x) = f(a) = ùêø.
- O limite pode n√£o existir.
- Se o limite de uma fun√ß√£o existe ele √© √∫nico.
- Considere o limite
lim
x‚Üí1
(x + 1) = 2.



Exemplo
- Considere o limite
lim
x‚Üí1
x2 - 1
x - 1
= ?

√© 2
- Computacionalmente
```{r}
fx <- function(x) {
out <- (x^2 - 1)/(x - 1)
return(out)
}
fx(x = 1)
## [1] NaN
```



```{r}
## Figura 11. Desenho do gr√°fico da fun√ß√£o
```

Exemplo
- Note que
$$
$$

- Defini√ß√£o intuitiva: o limite de uma fun√ß√£o √© o valor que achamos natural para ela em um determinado ponto.
- Essa fun√ß√£o n√£o √© continua (no ponto)



## Continuidade de uma fun√ß√£o
- Defini√ß√£o - dizemos que uma fun√ß√£o √© cont√≠nua em x = a se tr√™s condi√ß√µes forem satisfeitas:
  - $f(a)$ existe,
  - $\lim_{x \to a} f(x)$ existe e
  - $\lim_{x \to a} f(x) = f(a)$.
- Continuidade significa que pequenas varia√ß√µes na vari√°vel independente levam a pequenas varia√ß√µes na vari√°vel dependente.(mudan√ßas suaves, ou n√£o abruptas)
- Teorema do valor intermedi√°rio: se a fun√ß√£o f(x) √© cont√≠nua no intervalo fechado [a,b],
ent√£o existe pelo menos um n√∫mero ùëê em [a,b] tal que f(ùëê) = ùëÄ.
- Implica√ß√£o: se f(x) √© cont√≠nua seu gr√°fico n√£o cont√©m salto vertical.
- Em geral podemos pensar em fun√ß√µes cont√≠nuas como sendo fun√ß√µes suaves.

Fun√ß√£o n√£o cont√≠nua
- Considere a fun√ß√£o n√£o continua em 0.
$$
\lim_{x \to 0} \frac{|x|}{x} = \{-1   x < 0 e 1 x > 0
$$



```{r}
## Figura 12. Fun√ß√£o descontinua.
```

Propriedades de limites
Se limx‚Üíùëù f(x) = ùêø1 e limx‚Üíùëù ùëî(x) = ùêø2, ent√£o
- limx‚Üíùëù[f(x) + ùëî(x)] = limx‚Üíùëù f(x) + limx‚Üíùëù ùëî(x) = ùêø1 + ùêø2.
- limx‚Üíùëù ùëòf(x) = ùëò limx‚Üíùëù f(x) = ùëòùêø1.
- limx‚Üíùëù f(x)ùëî(x) = limx‚Üíùëù f(x) limx‚Üíùëù ùëî(x) = ùêø1ùêø2.
- limx‚Üíùëù
f(x)
ùëî(x) = ùêø1
ùêø2
, desde que ùêø2 {!=} 0.


## Derivadas

- Defini√ß√£o - derivada ordin√°ria, derivada primeira, ou simplesmente, derivada de uma fun√ß√£o y = f(x) em um ponto x = a no dom√≠nio de f √© representada por $ ùëëy/ùëëx , y‚Ä≤, ùëëf ùëëx$ ou $f‚Ä≤(a)$ √© o valor

$$
$$
ùëëy
ùëëx
|x=a = f‚Ä≤(a) = lim
‚Ñé‚Üí0
f(a + ‚Ñé) - f(a)
‚Ñé

$$
\lim_{h \to 0}  = \frac{f(a+h)-f(a)}h
$$

- Interpreta√ß√£o da derivada
- Taxa de mudan√ßa inst√¢ntanea.
- No limite quando $x \longrightarrow a$ a derivada √© a reta tangente ao ponto $(a, f(a))$.
- Equa√ß√£o da **reta tangente** ao ponto a: y - f(a) = f‚Ä≤(a)(x - a).(coenficiente angular √© beta1 -> y = beta0 + beta1*x)

## Exemplo
Obtenha a derivada de $f(x) = -x^2$
$$
f'(x) = 
$$
f‚Ä≤(x) = lim
‚Ñé‚Üí0
f(x + ‚Ñé) - f(x)
‚Ñé
= lim
‚Ñé‚Üí0
-(x + ‚Ñé)2 - (-x2)
‚Ñé
= lim
‚Ñé‚Üí0
-(x2 + 2x‚Ñé + ‚Ñé2) + x2
‚Ñé
= lim
‚Ñé‚Üí0
-x2 - 2x‚Ñé - ‚Ñé2 + x2
‚Ñé
=
-2x‚Ñé - ‚Ñé2
‚Ñé
= lim
‚Ñé‚Üí0
-2x - ‚Ñé = -2x
f‚Ä≤(x) = -2x. (1)



Obtenha a reta tangente a f(x) nos
pontos x = 2 e x = -2.
- Temos f(x = 2) = -4 e
f‚Ä≤(x = 2) = -4, assim
y - f(x = 2) = f‚Ä≤(x = 2)(x - 2)
y - (-4) = -4(x - 2)
y + 4 = = -4x + 8
y = 4 - 4x
- Computacionalmente
- f(x) e f‚Ä≤(x).
```{r}
fx <- function(x) {
out <- - x^2
return(out)
}
f_prime <- function(x) {
out <- -2*x
return(out)
}
```


- Equa√ß√£o da reta y = a + b ‚àó x.
```{r}
intercept = (fx(x = 2) - f_prime(x = 2)*2)
slope <- f_prime(x = 2)
c(intercept, slope)
## [1] 4 -4
```

```{r}
## Figura 14. Desenho de uma fun√ß√£o e retas tangentes.
```


## Regras de deriva√ß√£o
- Seja ùëõ {!=} 0 um natural. S√£o v√°lidas as
f√≥rmulas de deriva√ß√£o:
1. Se f(x) = ùëê ent√£o f‚Ä≤(x) = 0.
2. Se f(x) = xùëõ ent√£o f‚Ä≤(x) = ùëõxùëõ-1.
3. Se f(x) = x-ùëõ ent√£o
f‚Ä≤(x) = -ùëõx-ùëõ-1.
4. Se f(x) = x1/ùëõ ent√£o f‚Ä≤(x) = 1
ùëõ
x 1
ùëõ
-1.
- Derivada de fun√ß√µes especiais
5. Se f(x) = exp(x) ent√£o
f‚Ä≤(x) = exp(x).
6. Se f(x) = ln(x) ent√£o
f‚Ä≤(x) = 1
x
, x > 0.
- Sendo, f(x) e ùëî(x) deriv√°veis em x e ùëê
uma constante.
7. (f + ùëî)‚Ä≤ = f‚Ä≤(x) + ùëî‚Ä≤(x).
8. (ùëêf)‚Ä≤(x) = ùëêf‚Ä≤(x).
9. (f ‚ãÖ ùëî)‚Ä≤(x) = f‚Ä≤(x)ùëî(x) + f(x)ùëî‚Ä≤(x).
10. ( f
ùëî )‚Ä≤(x) = f‚Ä≤(x)ùëî(x)-f(x)ùëî‚Ä≤(x)
[ùëî(x)]2 .
- Exemplo: obtenha a derivada de
f(x) = 2 + 3x.
- Solu√ß√£o: f‚Ä≤(x) = 3.
- Computacionalmente
```{r}
D(expression(2 + 3*x), name = "x")
## [1] 3
```



## Regra da cadeia
- "Uma fun√ß√£o dentro da outra"
- Sejam y = f(x) e x = ùëî(ùë°) duas fun√ß√µes deriv√°veis, com ùêº \in ùê∑f . A fun√ß√£o composta
‚Ñé(ùë°) = f(ùëî(ùë°)) √© deriv√°vel, sendo
‚Ñé‚Ä≤(ùë°) = f‚Ä≤(ùëî(ùë°))ùëî‚Ä≤(ùë°), ùë° \in ùê∑ùëî.
- Existe uma infinidade de f√≥rmulas de deriva√ß√£o.
- Na pr√°tica √© comum usar um software de matem√°tica simb√≥lica como o wxMaxima.
- Em R as fun√ß√µes deriv() e deriv3().


## Exemplo regra da cadeia
- Obtenha a derivada de sin(2x3 - 4x).
1. Note que temos uma fun√ß√£o composta (derivada de sen e cos)
sin(ùëî(x)), onde ùëî(x) = 2x3 - 4x.
2. Usando a regra da cadeia temos:
f‚Ä≤(ùëî(x)) = cos(2x3 - 4x) and ùëî‚Ä≤(x) = 6x2 - 4.
3. Assim, a derivada fica dada por
cos(2x3 - 4x) ‚ãÖ (6x2 - 4).
4. Computacionalmente
```{r}
D(expression( sin(2*x^3 - 4*x)), name = "x")
## cos(2 * x^3 - 4 * x) * (2 * (3 * x^2) - 4)
## ou cos(2x^3 - 4x) * (6x^2) - 4)

D(D(expression( sin(2*x^3 - 4*x)), name = "x"), name = "x")
## cos(2 * x^3 - 4 * x) * (2 * (3 * (2 * x))) - sin(2 * x^3 - 4 * x) * (2 * (3 * x^2) - 4) * (2 * (3 * x^2) - 4)
```

## Derivadas de ordem superior
- A derivada f‚Ä≤(x) √© tamb√©m chamada de derivada de primeira ordem e mede a varia√ß√£o da
fun√ß√£o original ou primitiva.
- A derivada de segunda ordem denotada por f‚Ä≤‚Ä≤(x) mede a taxa de varia√ß√£o da primeira
derivada.
- A derivada de terceira ordem f‚Ä≤‚Ä≤‚Ä≤(x) mede a taxa de varia√ß√£o da segunda derivada e assim
por diante at√© a ùëõ-√©sima derivada.
- Nota√ß√£o comum: ùëëùëõy
ùëëxùëõ que √© interpretada como a ùëõ-√©sima derivada de y em rela√ß√£o a x
- Exemplo: obtenha as derivadas at√© a ordem 5 da fun√ß√£o y = 2x4 + 5x3 + 2x2.
ùëëy
ùëëx = 8x3 + 15x2 + 4x, ùëë2y
ùëëx2 = 24x2 + 30x + 4, ùëë3y
ùëëx3 = 48x + 30, ùëë4y
ùëëx4 = 48 e ùëë5y
ùëëx5 = 0.
daqui em diante √© zero


## M√°ximos e m√≠nimos
- Dizemos que um ponto $c$ √© um valor m√°ximo relativo de $f(x)$ se existir um intervalo aberto contendo $c$, no qual $f(x)$4 esteja definida, tal que $f(c) >= f(x)$ para todo $x$ neste intervalo.
- Dizemos que um ponto $c$ √© um valor m√≠nimo relativo de $f(x)$ se existir um intervalo aberto contendo $c$, no qual f(x) esteja definida, tal que f(ùëê) ‚â§ f(x) para todo x neste intervalo. (maximo e minimo dentro de um trecho de grafico)

```{r}
## Figura 15. Ilustra√ß√£o de m√°ximo/m√≠nimo relativos.
```

- Multiplicando a fun√ß√£o por -1 invertemos a sua concavidade.


## Pontos extremos (pico do morro ou fundo do vale)
- Se f(x) existe para todos os valores de x no intervalo aberto (ùëé,ùëè), e se f(x) tem um extremo relativo em ùëê, em que ùëé < ùëê < ùëè, ent√£o f‚Ä≤(ùëê) existe e f‚Ä≤(ùëê) = 0.
- Implica√ß√£o - Sendo f(x) diferenci√°vel os pontos extremos de f(x) v√£o ocorrer quando f‚Ä≤(x) = 0.
- $f'(x)$ pode ser igual a zero mesmo n√£o sendo um extremo relativo.
```{r}
## Figura 16. Ilustra√ß√£o de uma fun√ß√£o onde derivada zero n√£o √© ponto extremo.
```


## M√°ximos e m√≠nimos
Seja $c$ um ponto extremo de uma fun√ß√£o $f(x)$ no qual $f'(c) = 0$, e suponha que $f'(x)$ exista
para todos os valores de x em um intervalo aberto contendo ùëê. Se f‚Ä≤‚Ä≤(ùëê) existe, ent√£o
- Se f‚Ä≤‚Ä≤(ùëê) < 0, ent√£o f(x) tem um m√°ximo relativo em ùëê.
- Se f‚Ä≤‚Ä≤(ùëê) > 0, ent√£o f(x) tem um m√≠nimo relativo em ùëê.
## Concavidade
- Se f‚Ä≤‚Ä≤(ùëê) > 0 o gr√°fico de f(x) √© c√¥ncavo para cima em (ùëê, f(ùëê));
- Se f‚Ä≤‚Ä≤(ùëê) < 0 o gr√°fico de f(x) √© c√¥ncavo para baixo em (ùëê, f(ùëê)).



Por que derivadas s√£o importantes?
- Obten√ß√£o de m√°ximo ou m√≠nino (relativo).

ponto extremo tem inclina√ß√£o zero (a3 na figura)


```{r}
## Figura 17. Ilustra√ß√£o de uma fun√ß√£o com a reta tangente.
```

## Redu√ß√£o de dados

Voc√™ j√° trabalha com dados? Se sim,
- Por qual raz√£o voc√™ usa a m√©dia ou a mediana como uma medida resumo?
- Voc√™ acha que existe algum procedimento mais geral que leva a obten√ß√£o destas medidas resumo?
- Se sim, como este procedimento est√° relacionado com o que vimos em rela√ß√£o a fun√ß√µes e seu comportamento?


- Suponha que temos um conjunto de observa√ß√µes $y_{i}$ para $i = 1, ‚Ä¶ , n$.
- Objetivo: resumir a informa√ß√£o contida em $y_{i}$ em um √∫nico n√∫mero, digamos $\mu$.
- Problema: como encontrar $\mu$?
- Solu√ß√£o: encontrar o valor $\mu$, tal que $f(\mu) = \sum_{i=1}^{n} (y_{i} - \mu)^2 $ (soma de quadrados da diferen√ßa de cada valor para media, ou seja o quanto eu perdi ao trocar os $y$ por $\mu$), seja a menor poss√≠vel.
- Uma vez que temos os n√∫meros observados $y_{i}$ a √∫nica quantidade desconhecida √©$\mu$.
- Note que $\mu$ √© o par√¢metro da nossa fun√ß√£o.
- A fun√ß√£o $f(\mu)$ mede o quanto perdemos em representar $y_{i}$ apenas usando $\mu$.
- Fun√ß√µes perda muito populares s√£o a perda quadr√°tica, perda absoluta, minmax e a cross entropia.
- dervar e igualar a 0.

Fun√ß√µes em R.
```{r}
y <- c(8,9,14,10,10,15,11,5,4,13)
fmu <- function(mu, y) {
out <- sum((y - mu)^2)
return(out)
}
fmu <- Vectorize(fmu, "mu")
fmu(mu = c(10, 12, 0, 8), y = y)
## [1] 117 161
f_prime <- function(mu, y) {
out <- -2*sum(y-mu)
return(out)
}
```

Graficamente
```{r}

```

- Note que o melhor resumo dos dados de um n√∫mero, corresponde ao ponto de m√≠nimo da fun√ß√£o
$$
f(y) = \sum_{i=1}^{n} (y_{i} -\mu )^2
$$

- Como o m√≠nimo est√° relacionado com a derivada de $f(\mu)$?


## Exemplo: redu√ß√£o de dados
- No ponto de m√≠nimo/m√°ximo a inclina√ß√£o da reta tangente a $f(\mu)$ √© zero.
- Denote por ùúáÃÇ o ponto de m√≠nimo/m√°ximo de ùëì(ùúá), ent√£o ùëì‚Ä≤(ùúá)ÃÇ = 0.
- Assim, temos (regra da cadeia!!)

$$ f(y) = \sum_{i=1}^{n} (y_{i} -\mu )^2$$
$$\varepsilon_{i} = y_{i} -\mu$$
$$  f'(\mu) = \sum_{i=1}^{n} (\varepsilon_{i})^2 $$
$$  f'(\mu) = 2 \sum_{i=1}^{n} (y_{i} -\mu) \frac{d}{d \mu} (y_{i} -\mu) $$

$$ f'(\mu) = 2 \sum_{i=1}^{n} (y_{i} -\mu) (-1)$$

$$ f'(\mu) = -2 \sum_{i=1}^{n} (y_{i} -\mu)$$

Exemplo: redu√ß√£o de dados
- Agora precisamos achar o ponto ùúáÃÇ tal que ùëì‚Ä≤(ùúá)ÃÇ = 0.

$$ f'(\mu_{chapeu}) = 0$$

$$  -2 \sum_{i=1}^{n} (y_{i} -\mu_{chapeu}) = 0$$
$$  -\sum_{i=1}^{n} (y_{i} -n \mu_{chapeu}) = 0$$
$$ n\mu_{chapeu} = \sum_{i=1}^{n} y_{i}$$

$$ \mu_{chapeu} = \frac{\sum_{i=1}^{n} y_{i}}{n}$$
OU SEJA M√âDIA!!!

Coment√°rios
- Por qual raz√£o voc√™ usa a m√©dia ou a mediana como uma medida resumo?
  - Minimiza a perda quadr√°tica.
  - Medida √≥tima no sentido de perda quadr√°tica.
- Voc√™ acha que existe algum procedimento mais geral que leva a obten√ß√£o destas medidas resumo?
  - Especifica√ß√£o do modelo.
  - Escolha da fun√ß√£o perda.
  - Treinamento (otimiza√ß√£o).
- Se sim, como este procedimento est√° relacionado com o que vimos em rela√ß√£o a fun√ß√µes e
seu comportamento?
  - Estudar o comportamento de fun√ß√µes.

## Derivadas parciais


- Uma fun√ß√£o pode ter mais do que uma vari√°vel independente.
- A derivada parcial mede a taxa de varia√ß√£o instant√¢nea da vari√°vel dependente (ùë¶) com rela√ß√£o a vari√°vel independente ùë•1, quando a outra vari√°vel independente ùë•2 √© mantida constante.
- Como obter a derivada parcial?
- A derivada parcial em rela√ß√£o a ùë•1 √© obtida derivando ùëì(ùë•1, ùë•2) ‚Äúfingindo‚Äù que ùë•2 √© uma constante.
- A derivada parcial de ùëì(ùë•1, ùë•2) em rela√ß√£o a ùë•2 √© obtida derivando ùëì(ùë•1, ùë•2) mantendo ùë•1
constante.
- A diferencia√ß√£o parcial segue as mesmas regras da diferencia√ß√£o ordin√°ria.


Exemplo
Obtenha as derivadas parciais em rela√ß√£o a $x_{1}$ e  $x_{2}$ de $y = 5 x_{1}^{3} + 3 x_{1} x_{2} + 4 x_{2}^{2}$

$$\displaystyle \frac{\partial y}{\partial x_{1}} = 15 x_{1}^{2} + 3 x_{2}$$
ou
```{r}
D(expression( 5 * x^3 + 3 * x * c + 4* c^2 ), name = "x")
```


$$\displaystyle \frac{\partial y}{\partial x_{2}} = 3 x_{1} + 8 x_{2}$$
```{r}
D(expression( 5 * x^3 + 3 * x * c + 4* c^2 ), name = "c")
```



Derivadas parciais de ordem superior
- Derivadas parciais de segunda ordem
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•21
e ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•22
indica que a fun√ß√£o foi diferenciada parcialmente em rela√ß√£o a ùë•1 ou ùë•2 duas vezes.
- Derivada parcial cruzada (ou mista)
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•1ùúïùë•2
indica que primeiro derivamos em ùë•1 e depois em ùë•2.
- A ordem da derivada cruzada n√£o importa (se ambas cont√≠nuas), ou seja
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•1ùúïùë•2
=
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•2ùúïùë•1
.


Exemplo: derivadas parciais de segunda ordem
- Obtenha as derivadas parciais de at√© segunda ordem em rela√ß√£o a ùë•1 e ùë•2 de
ùë¶ = 7ùë•31
+ 9ùë•1ùë•2 + 2ùë•52
.
- Derivadas parciais de primeira ordem
ùúïùë¶
ùúïùë•1
= 21ùë•21
+ 9ùë•2,
ùúïùë¶
ùúïùë•2
= 9ùë•1 + 10ùë•42
.
- Derivadas parciais de segunda ordem (segunda derivadas direta)
ùúï2ùë¶
ùúïùë•21
= 42ùë•1,
ùúï2ùë¶
ùúïùë•22
= 40ùë•32
.
- Derivadas parciais de segunda ordem (termos cruzados)
ùúï2ùë¶
ùúïùë•1ùë•2
=
ùúï21ùë•21
+ 9ùë•2
ùúïùë•2
= 9,
ùúï2ùë¶
ùúïùë•2ùë•1
=
ùúï9ùë•1 + 10ùë•42
ùúïùë•1
= 9.

- As cruzadas d√£o sempre iguais.


## M√°ximos e m√≠nimos fun√ß√µes muldimensionais
- Pontos cr√≠ticos: as derivadas parciais de primeira ordem devem ser iguais a zero **simultaneamente**.
- Derivadas parciais **principais** de segunda ordem no ponto cr√≠tico forem ambas **positivas -> ponto de m√≠nimo**.
- Derivadas parciais de segunda ordem no ponto cr√≠tico forem ambas **negativas -> ponto de m√°ximo**.
- Outras situa√ß√µes ver material suplementar.


## Exemplo
Considere a fun√ß√£o ùë¶ = 6ùë•21
‚àí 9ùë•1 ‚àí 3ùë•1ùë•2 ‚àí 7ùë•2 + 5ùë•22
. Encontre os pontos cr√≠ticos e
determine se s√£o de m√°ximo ou min√≠mo.
- Graficamente
```{r}

```

- Calcular as derivadas parciais de primeira ordem da fun√ß√£o
ùë¶ = 6ùë•21
‚àí 9ùë•1 ‚àí 3ùë•1ùë•2 ‚àí 7ùë•2 + 5ùë•22
.
- Derivando em ùë•1, temos
ùúïùë¶
ùúïùë•1
= 12ùë•1 ‚àí 9 ‚àí 3ùë•2.
- Derivando em ùë•2, temos
ùúïùë¶
ùúïùë•2
= ‚àí3ùë•1 ‚àí 7 + 10ùë•2.

- Resolver o sistema de equa√ß√µes
12ùë•1 ‚àí 9 ‚àí 3ùë•2 = 0
‚àí3ùë•1 ‚àí 7 + 10ùë•2 = 0.
- Solu√ß√£o: ùë•1 = 1 e ùë•2 = 1. ## USA NA PROXIMA

- Verificar se o ponto encontrado √© de m√≠nimo calculando a segunda derivada parcial principal e avaliando o seu sinal.



ùúï2ùë¶
ùúïùë•21
=
ùúï
ùúïùë•1
(12ùë•1 ‚àí 9 ‚àí 3ùë•2) = 12,
ùúï2ùë¶
ùúïùë•22
=
ùúï
ùúïùë•2
(3ùë•1 ‚àí 7 + 10ùë•2) = 10.


- Calcular as derivadas cruzadas e verificar se o produto das derivadas principais √© maior que o produto das cruzadas

ùúï2ùë¶
ùúïùë•1ùë•2
=
ùúï12ùë•1 ‚àí 9 ‚àí 3ùë•2
ùúïùë•2
= ‚àí3,
ùúï2ùë¶
ùúïùë•2ùë•1
=
ùúï ‚àí 3ùë•1 ‚àí 7 + 10ùë•2
ùúïùë•2
= ‚àí3.

Assim, temos que
ùúï2ùë¶
ùúïùë•21
ùúï2ùë¶
ùúïùë•22
 (
ùúï2ùë¶
ùúïùë•1ùë•2
)
2
12 ‚ãÖ 10 > (‚àí3)2
120 > 9.

- A fun√ß√£o est√° em um ponto de m√≠nimo quando examinada de todas as dire√ß√µes.

## Gradiente e Hessiano


## Gradiente

- Derivadas de primeira e segunda ordem aparecem com tanta frequ√™ncia que receberam nomes especiais.
- O vetor gradiente de uma fun√ß√£o ùëì(ùë•1,ùë•2) √© o **vetor composto pelas derivadas primeira** de ùëì(ùë•1,ùë•2) em rela√ß√£o a ùë•1 e ùë•2,
‚àáùëì(ùë•1,ùë•2) = (
ùúïùëì(ùë•1,ùë•2)
ùúïùë•1
,
ùúïùëì(ùë•1,ùë•2)
ùúïùë•2
)
‚ä§
.
- A defini√ß√£o estende-se naturalmente para fun√ß√µes multidimensionais.
- Sendo, ùëì(ùë•) onde ùë• √© um vetor ùëù √ó 1 de vari√°veis independentes o vetor gradiente de ùëì(ùë•) √© dado por
‚àáùëì(ùë•) = (
ùúïùëì(ùë•)
ùúïùë•1
, ‚Ä¶ ,
ùúïùëì(ùë•)
ùúïùë•ùëù
)
‚ä§
.


## Hessiano
- A matriz hessiana de uma fun√ß√£o ùëì(ùë•1,ùë•2) √© a matriz composta pelas **derivadas de segunda ordem** de ùëì(ùë•1,ùë•2), na seguinte estrutura
H = (
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•21
ùúïùëì(ùë•1,ùë•2)
ùúïùë•1ùúïùë•2
ùúïùëì(ùë•1,ùë•2)
ùúïùë•2ùúïùë•1
ùúï2ùëì(ùë•1,ùë•2)
ùúïùë•22
) .
- E para o caso multidimensional
H =
‚éõ‚éú‚éú‚éú
‚éù
ùúï2ùëì(ùë•)
ùúïùë•21
‚ãØ ùúïùëì(ùë•)
ùúïùë•1ùúïùë•ùëù
‚ãÆ ‚ã± ‚ãÆ
ùúïùëì(ùë•)
ùúïùë•ùëùùúïùë•1
‚ãØ ùúï2ùëì(ùë•)
ùúïùë•2
ùëù
‚éû‚éü‚éü‚éü
‚é†


## S√©ries de Taylor

- Suponha que uma fun√ß√£o ùëì(ùë•) √© deriv√°vel (ùëõ + 1) vezes em um intervalo contendo
ùë• = ùë•0.
- Expans√£o em S√©rie de Taylor de ùëì(ùë•) em torno de ùë• = ùë•0 consiste em reescrever ùëì(ùë•) da
seguinte forma:
ùëì(ùë•) = ùëì(ùë•0) + (ùë• ‚àí ùë•0)
ùëëùëì(ùë•)
ùëëùë•
|ùë•=ùë•0 +
(ùë• ‚àí ùë•0)2
2!
ùëë2ùëì(ùë•)
ùëëùë•2 |ùë•=ùë•0+ (2)
(ùë• ‚àí ùë•0)3
3!
ùëë3ùëì(ùë•)
ùëëùë•3 |ùë•=ùë•0 + ‚Ä¶ +
(ùë• ‚àí ùë•0)ùëõ
ùëõ!
ùëëùëõùëì(ùë•)
ùëëùë•ùëõ |ùë•=ùë•0 + ùëÖùëõ(ùë•) (3)
onde o termo ùëÖùëõ(ùë•) √© chamado de res√≠duo ou erro, e dado por
ùëÖùëõ(ùë•) =
(ùë• ‚àí ùë•0)ùëõ+1
(ùëõ + 1)!
ùëëùëõ+1ùëì(ùë•)
ùëëùë•ùëõ+1 |ùë•=ùúñ
sendo ùúñ um valor entre ùë• e ùë•0.


## Exemplo
- Seja ùëì(ùë•) = exp(ùë•). Determine a expans√£o de Taylor de ordens 1 e 2, de ùëì(ùë•) ao redor de
ùë•0 = 0.
- Aproxima√ß√£o de primeira ordem
ùëÉ1(ùë•) = ùëì(ùë• = 0) + ùëì‚Ä≤(ùë• = 0)(ùë• ‚àí 0)
= exp(0) + exp(0)(ùë• ‚àí 0)
= 1 + ùë•.
- Aproxima√ß√£o de segunda ordem
ùëÉ2(ùë•) = ùëì(ùë• = 0) + ùëì‚Ä≤(ùë• = 0)(ùë• ‚àí 0) +
ùëì‚Ä≤‚Ä≤(ùë• = 0)
2
(ùë• ‚àí 0)2
= exp(0) + exp(0)(ùë• ‚àí 0) + exp(0)
2
(ùë• ‚àí 0)2
= 1 + ùë• +
1
2
ùë•2.

Graficos

- Quanto mais se afasta de zero pior fica a aproxima√ß√£o.
- A Tailor em n+1 graus √© igual a original


## Regress√£o linear simples
- Regress√£o linear √© uma das t√©cnicas mais populares em ci√™ncia de dados.
- Objetivo: descrever o comportamento de uma vari√°vel dependente ùë¶ por meio do conhecimento de outra vari√°vel
independente ùë•.
- Predizer ùë¶ dado um valor de ùë•.
- Descrever a rela√ß√£o entre ùë¶ e ùë•.
- Exemplo
  - Como o tamanho (em metros quadrados) de um apartamento est√° associado ao seu pre√ßo (em reais)?
  - Suponha que um conjunto de 20 apartamentos foi medido e avaliado.

Grafico

Regress√£o linear simples
- Ideia simples! ‚Üí O pre√ßo deve ser uma fun√ß√£o do tamanho do apartamento.
- Formaliza√ß√£o matem√°tica:
- Denote por ùë¶ùëñ para ùëñ = 1, ‚Ä¶ ,ùëõ o pre√ßo do apartamento ùëñ e neste caso ùëõ = 20.
- Denote por ùë•ùëñ o tamanho do apartamento ùëñ em metros quadrados.
- Fun√ß√£o relacionando pre√ßo ‚àº tamanho
$$ Pre√ßo = f(metroquadrado) $$
$$ y_{i} = f^{*}(x_{i})$$

- Qual √© a fun√ß√£o ùëì‚àó(ùë•ùëñ)?
- N√£o conhecemos e em geral nunca vamor conhecer ùëì‚àó(ùë•ùëñ).
- Aproximar ùëì‚àó(ùë•ùëñ) por outra fun√ß√£o ùëì(ùë•ùëñ) conhecida.
- Problema: qual ùëì(ùë•ùëñ) e como fazer a aproxima√ß√£o!

- Uma op√ß√£o √© usar a expans√£o em s√©rie de Taylor para obter uma aproxima√ß√£o.

- Aproxima√ß√£o em s√©rie de Taylor de primeira ordem
$$ f^{*}(x) = f^{*}(x_0) + (x - x_0)f^{*'}(x) + R_n(x)$$

- Ignorando o termo residual ùëÖùëõ(ùë•)
ùëì‚àó(ùë•) ‚âà ùëì‚àó(ùë•0) + (ùë• ‚àí ùë•0)ùëì‚àó‚Ä≤(ùë•0).

- Rearranjando os termos obtemos
ùëì‚àó(ùë•) ‚âà ‚èü{ùëì‚èü‚àó(‚èüùë•0‚èü)‚èü‚àí ùëì‚àó‚èü‚Ä≤(ùë•‚èü0‚èü)ùë•‚èü0}
ùõΩ0
+ ùëì‚èü‚àó‚Ä≤(ùë•0)
ùõΩ1
ùë•
ùëì‚àó(ùë•) ‚âà ùõΩ0 + ùõΩ1ùë•.
- De forma equivalente, temos
ùë¶ùëñ = ùõΩ0 + ùõΩ1ùë•ùëñ + ùëÖùëõ(ùë•ùëñ),
em que o termo ùëÖùëõ(ùë•ùëñ) √© o erro cometido em aproximar ùë¶ùëñ por ùõΩ0 + ùõΩ1ùë•ùëñ.

- Nota√ß√£o usual ùúñùëñ = ùë¶ùëñ ‚àí (ùõΩ0 + ùõΩ1ùë•ùëñ).
- Note que o erro √© uma fun√ß√£o dos par√¢metros desconhecidos ùõΩ0 e ùõΩ1.
- Objetivo: minimizar a soma de quadrados dos erros ou res√≠duos
$$ 
$$

ùëÜùëÑ(ùõΩ0, ùõΩ1) =
ùëõŒ£
ùëñ=1
ùúñ2(ùõΩ0, ùõΩ1)ùëñ
ùëÜùëÑ(ùõΩ0, ùõΩ1) =
ùëõŒ£
ùëñ=1
(ùë¶ùëñ ‚àí (ùõΩ0 + ùõΩ1ùë•ùëñ))2.

- Obter o vetor gradiente
‚àáùëÜùëÑ(ùõΩ0,ùõΩ1) = (
ùúïùëÜùëÑ(ùõΩ0,ùõΩ1)
ùúïùõΩ0
,
ùúïùëÜùëÑ(ùõΩ0, ùõΩ1)
ùúïùõΩ1
) .
- Encontrar ùõΩ0ÃÇ e ùõΩ1ÃÇ tal que
‚àáùëÜùëÑ(ùõΩ0ÃÇ ,ùõΩ1ÃÇ ) = 0.



1. Chame ùë¶ùëñ ‚àí (ùõΩ0 + ùõΩ1ùë•ùëñ) = ùúñùëñ.
2. Chame ùõΩ0 + ùõΩ1ùë•ùëñ = ùúáùëñ.
3. Assim,
‚àáùëÜùëÑ(ùõΩ0,ùõΩ1) = (
ùúïùëÜùëÑ(ùõΩ0,ùõΩ1)
ùúïùúñùëñ
ùúïùúñùëñ
ùúáùëñ
ùúïùúáùëñ
ùúïùõΩ0
,
ùúïùëÜùëÑ(ùõΩ0,ùõΩ1)
ùúïùúñùëñ
ùúïùúñùëñ
ùúáùëñ
ùúïùúáùëñ
ùúïùõΩ1
) ,
em que
ùúïùëÜùëÑ(ùõΩ0,ùõΩ1)
ùúïùúñùëñ
=
ùúï
ùúïùúñùëñ
ùëõŒ£
ùëñ=1
ùúñ2
ùëñ
= 2
ùëõŒ£
ùëñ=1
ùúñùëñ.
ùúïùúñùëñ
ùúïùúáùëñ
=
ùúï
ùúïùúáùëñ
(ùë¶ùëñ ‚àí ùúáùëñ) = ‚àí1,
ùúïùúáùëñ
ùúïùõΩ0
=
ùúï
ùúïùõΩ0
ùõΩ0 + ùõΩ1ùë•ùëñ = 1,
ùúïùúáùëñ
ùúïùõΩ1
=
ùúï
ùúïùõΩ1
ùõΩ0 + ùõΩ1ùë•ùëñ = ùë•ùëñ.


Vetor gradiente
- Portanto,
‚àáùëÜùëÑ(ùõΩ0,ùõΩ1) = (‚àí2
ùëõŒ£
ùëñ=1
ùúñùëñ(1); ‚àí2
ùëõŒ£
ùëñ=1
ùúñùëñùë•ùëñ)
= (‚àí2
ùëõŒ£
ùëñ=1
(ùë¶ùëñ ‚àí ùõΩ0 ‚àí ùõΩ1ùë•ùëñ); ‚àí2
ùëõŒ£
ùëñ=1
(ùë¶ùëñ ‚àí ùõΩ0 ‚àí ùõΩ1ùë•ùëñ)ùë•ùëñ) .
- Resolver o sistema de equa√ß√µes simult√¢neas (derivadas de beta 0 e beta 1)
‚àí2
ùëõŒ£
ùëñ=1
(ùë¶ùëñ ‚àí ùõΩ0ÃÇ ‚àí ùõΩ1ÃÇ ùë•ùëñ) = 0
‚àí2
ùëõŒ£
ùëñ=1
(ùë¶ùëñ ‚àí ùõΩ0ÃÇ ‚àí ùõΩ1ÃÇ ùë•ùëñ)ùë•ùëñ = 0.

- Solu√ß√£o
ùõΩ0ÃÇ = ùë¶ÃÑ‚àí ùõΩ1ÃÇ ùë•,ÃÑ
ùõΩ1ÃÇ =
Œ£ùëõ
ùëñ=1 ùë¶ùëñùë•ùëñ ‚àí ùë¶ÃÑŒ£ùëõ
ùëñ=1 ùë•ùëñ
Œ£ùëõ
ùëñ=1 ùë•2
ùëñ
‚àí ùë•ÃÑŒ£ùëõ
ùëñ=1 ùë•ùëñ




```{r}
## Carregando a base de dados
dados <- read.table("Wagner/reglinear.csv",
                    header = TRUE)
dados
```

```{r}
## Obtendo beta1
beta1 <- (sum(dados$y*dados$x) -
            mean(dados$y)*sum(dados$x))/
  (sum(dados$x^2) - mean(dados$x)*sum(dados$x))
# Obtendo beta0
beta0 <- mean(dados$y) - beta1*mean(dados$x)
c(beta0, beta1)
## [1] 2622.752 3608.499
## Verificando
```



```{r}
coef(lm(y ~ x, data = dados))
## (Intercept) x
## 2622.752 3608.499
```
Modelo:
ychapeu = 2622.752 + 3608.499* metrosquadrados


## Discuss√£o
- Derivadas s√£o essenciais em estat√≠stica.
- Maximizar/minimizar fun√ß√µes perda/objetivo.
- O c√°lculo √© por vezes dif√≠cil e tedioso.
- Solu√ß√£o de sistemas lineares √© tedioso quando poss√≠vel.
- √Ålgebra linear ajuda a generalizar as solu√ß√µes.
- Em situa√ß√µes mais gerais express√µes anal√≠ticas n√£o ser√£o poss√≠veis de obter.
- M√©todos num√©ricos para resolu√ß√£o de sistemas lineares.
- M√©todos num√©ricos para resolu√ß√£o de sistemas n√£o-lineares.
- M√©todos de otimiza√ß√£o num√©rica.



