require(pracma)
require(ds4psy)
require(FRACTION)
A <- matrix(
c(08, -2, -6, 09, 03, 06, 10, -3, 0),
byrow = TRUE,
nrow = 3,
ncol = 3
)
A
i <- 1
j <- 1
for (i in 1:3) {
print(paste("i = ", i))
for (j in 1:3) {
print(paste("j = ", j))
numtransf = 0
print(paste("num = ", A[i,j]))
if (A[i,j] < 0)    {
numtemporario = abs(A[i,j])
#print(paste("absoluto = ", numtemporario))
numtransf = nthroot(x = numtemporario, n = 3)
} else if (is_prime(A[i,j]))    {
numtransf = A[i,j] * 9
} else if (is.wholenumber(sqrt(A[i,j])))
{
numtransf = A[i,j] - 4
if (numtransf < 0)
{
numtransf = numtransf ** 3
}
} else{
numtransf = A[i,j]
}
print(paste("pos = ", numtransf))
A[i,j] = numtransf
}
}
A
B <- matrix(c(20, 0, -3, 15,
16, 19, 8, 12,
3, 6, 5, 11,
-8, 18, -5, 10),
byrow = TRUE,
nrow = 4,
ncol = 4
)
B
i <- 1
j <- 1
for (i in 1:4) {
print(paste("i = ", i))
for (j in 1:4) {
print(paste("j = ", j))
numtransf = 0
print(paste("num = ", B[i,j]))
if (B[i,j] < 0)    {
numtemporario = abs(B[i,j])
#print(paste("absoluto = ", numtemporario))
numtransf = nthroot(x = numtemporario, n = 3)
} else if (is_prime(B[i,j]))    {
numtransf = B[i,j] * 9
} else if (is.wholenumber(sqrt(B[i,j])))
{
numtransf = B[i,j] - 4
if (numtransf < 0)
{
numtransf = numtransf ** 3
}
} else{
numtransf = B[i,j]
}
print(paste("pos = ", numtransf))
B[i,j] = numtransf
}
}
B
C <- matrix(c(-1, 30, 20, 7, 17,
29, -5, 18, 8, 22,
-10, -9, 2, 16, 27,
-7, -4, 1, 6, 12,
15, 26, 9, 19, -2),
byrow = TRUE,
nrow = 5,
ncol = 5
)
C
i <- 1
j <- 1
for (i in 1:5) {
print(paste("i = ", i))
for (j in 1:5) {
print(paste("j = ", j))
numtransf = 0
print(paste("num = ", C[i,j]))
if (C[i,j] < 0)    {
numtemporario = abs(C[i,j])
#print(paste("absoluto = ", numtemporario))
numtransf = nthroot(x = numtemporario, n = 3)
} else if (is_prime(C[i,j]))    {
numtransf = C[i,j] * 9
} else if (is.wholenumber(sqrt(C[i,j])))
{
numtransf = C[i,j] - 4
if (numtransf < 0)
{
numtransf = numtransf ** 3
}
} else{
numtransf = C[i,j]
}
print(paste("pos = ", numtransf))
C[i,j] = numtransf
}
}
C
sum(diag(A))
A
C
sum(C[,2])
B
contador = 0
for (i in 1:4) {
print(paste("i = ", i))
for (j in 1:4) {
if(is_prime(B[i,j])){
contador = contador +1
}
}
}
B
contador = 0
for (i in 1:4) {
for (j in 1:4) {
if(is_prime(B[i,j])){
contador = contador +1
}
}
}
contador
B
contador = 0
for (i in 1:4) {
for (j in 1:4) {
if(is_prime(B[i,j])){
print(paste("o numero ", B[i,j], "eh primo"))
contador = contador +1
}
}
}
contador
contador = 0
contador = 0
i <- 1
j <- 1
for (i in 1:3) {
for (j in 1:3) {
if (is.wholenumber(sqrt(A[i,j]))){
print(paste("o numero ", A[i,j], "eh primo"))
contador = contador +1
}
}
}
contador = 0
i <- 1
j <- 1
for (i in 1:3) {
for (j in 1:3) {
print(paste("num = ", A[i,j]))
if (is.wholenumber(sqrt(A[i,j]))){
print(paste("o numero ", A[i,j], "eh primo"))
contador = contador +1
}
}
}
install.packages("ggplot2")
require(ggplot2)
diamonds
diamantes2 <- filter(diamonds, diamonds$cut == "Fair")
diamantes2
count(diamantes2)
diamantes3 <- filter(diamonds, diamonds$color == "J", diamonds$clarity == SI2)
diamonds$clarity
diamantes3 <- filter(diamonds, diamonds$color == "J", diamonds$clarity == "SI2")
diamantes3
mean(diamantes3$price)
diamantes4 <- filter(diamonds, diamonds$carat > 1.4)
diamantes4
mean(diamantes4$price)
diamantes5 <- filter(diamonds, diamonds$color == "J", diamonds$clarity == "VS2", diamonds$carat > 2.9)
diamantes5
median(diamantes5)
median(diamantes5$price)
- Variância ("standartization")
knitr::opts_chunk$set(echo = TRUE)
### Modelos estatísticos - Aula de modelos lineares
### Pacotes usados na aula.
require("ISLR")
require("ggplot2")
require("GGally")
require("leaps")
require("car")
options(device = X11)
summary(Auto)
ggplot(Auto, aes(x = year)) + geom_histogram()
ggplot(Auto, aes(x = year, y = mpg)) + geom_point() +
stat_smooth(method = "lm") +
theme_bw(base_size = 14)
plot1 <- ggplot(Auto, aes(x = horsepower, y = mpg)) + geom_point() + theme_bw(base_size = 14)
plot1
plot1 + coord_trans(x="log2", y="log2")
### Carregamento e visualização inicial da base
data("College") ### Carregando a base
#help("College") ### Acessando a documentação
head(College,10) ### Visualizando as dez primeiras linhas
dim(College) ### Acessando a dimensão da base
summary(College) ### Resumo das variáveis
### Vamos considerar Grad.Rate (taxa de formados) como a variável resposta na nossa análise. Começamos a análise com alguns gráficos.
ggplot(College, aes(x = Grad.Rate)) + geom_histogram() +
theme_bw(base_size = 14)
### Distribuição das taxas de formados
ggplot(College, aes(x = Top10perc, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus percentual de alunos entre os 10% melhores
### no ensino médio.
ggplot(College, aes(x = Outstate, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus investimentos externos.
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus porcentagens de ex-alunos contribuintes.
### Parte 1 - Ajuste dos modelos lineares. Comecemos com o caso de apenas uma
### variável explicativa (no caso, perc.alumni)
### Para ajustar modelos lineares no R usamos a função lm. Vamos consultar
### a documentação da função.
#help('lm')
### Ajuste da regressão linear simples (assumindo relação linear entre a taxa de formados e o percentual de ex-alunos contribuintes)
ajuste1 <- lm(Grad.Rate ~ perc.alumni, data = College) ###(resposta ~ var.explicativas)
ajuste1
summary(ajuste1)
### O percentual de ex-alunos contribuintes tem efeito positivo, e
### estatisticamente significativo na taxa de formados.
### Vamos visualizar o ajuste do modelo
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
stat_smooth(method = "lm") +
theme_bw(base_size = 14)
### Vamos investigar possível efeito quadrático do percentual de contribuíntes na taxa de formados. Para isso, adicionamos ao preditor o termo quadrático da variável explicativa, da seguinte forma:
ajuste2 <- lm(Grad.Rate ~ perc.alumni + I(perc.alumni^2), data = College)
summary(ajuste2)
### O termo quadrático é estatisticamente significativo, indicando que a
### relação entre as variáveis não é linear. Vamos dar um passo além, e
### incluir o termo de terceira ordem para o percentual de contribuintes
### (modelo cúbico).
ajuste3 <- lm(Grad.Rate ~ perc.alumni + I(perc.alumni^2) + I(perc.alumni^3), data = College)
summary(ajuste3)
### O termo de ordem cúbica não tem significância estatística. Vamos seguir
### a análise com o modelo quadrático.
### Vamos extrair alguns elementos do modelo ajustado
ajuste2$coefficients ### Estimativas dos parâmetros
ajuste2$residuals ### Resíduos ordeinários
ajuste2$fitted.values ### Valores ajustados pelo modelo
model.matrix(ajuste2) ### Matriz do modelo (matriz X)
vcov(ajuste2) ### Matriz de variâncias e covariâncias dos estimadores.
### Vamos visualizar o ajuste do modelo
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
stat_smooth(method = "lm", formula = y ~ x + I(x^2)) +
theme_bw(base_size = 14)
### Extraindo os intervalos de confiança (95%) para os parâmetros
confint(ajuste2)
### vamos realizar algumas predições. Considere faculdades com os seguintes
### percentuais de ex-alunos contribuintes: 13, 28 e 45
new_data <- data.frame(perc.alumni = c(13,28,45))
predict(ajuste2, newdata = new_data, se.fit = TRUE)
### Estimativas pontuais e erros padrões (nota: erros padrões para a resposta
### média)
predict(ajuste2, newdata = new_data, interval = 'confidence')
### Estimativas pontiais e intervalos de confiança (95%) para a resposta média.
predict(ajuste2, newdata = new_data, interval = 'prediction')
### Estimativas pontiais e intervalos de confiança (95%) para a predição
### de uma nova observação.
### Parte 2 - Regressão linear múltipla, incluindo todas as variáveis da base como explicativas (exceto a taxa de formação, que é a resposta)
ajuste_p2 <- lm(Grad.Rate ~., data = College)
### Ajuste da regressão linear múltipla. A especificação "~." indica que
### todas as demais variáveis da base devem ser incluídas como explicativas.
### A título de ilustração, se quiséssemos ajustar um modelo apenas com as
### variáveis "Private", "Apps" e "Accept":
summary(ajuste_p2)
ajuste_p2 <- lm(Grad.Rate ~.-Top25perc, data = College)
## Todas menos a top 25. pq o top 10 e top 25 "se sobrepoe"
## "ajustado os efeitos das outras variaveis"
summary(ajuste_p2)
ajuste_p2 <- lm(Grad.Rate ~ Expend, data = College)
## Todas menos a top 25. pq o top 10 e top 25 "se sobrepoe"
## "ajustado os efeitos das outras variaveis"
summary(ajuste_p2)
ajuste_p2_ilustrativo <- lm(Grad.Rate ~ Private + Apps + Accept, data = College)
summary(ajuste_p2_ilustrativo)
### Resumo do ajuste. Observe as variáveis com efeito significativo e os respectivos sinais.
### Variáveis com p-valor (Pr(>|t|)) < 0.05 podem ser consideradas com efeito
### significativo na taxa de formados. Desta forma, as variáveis com efeito
### significativo na taxa de formados são Private (Yes), Apps, Top25perc, Outstate,
### Room.Board, 0.2793343; Já as variáveis com efeito negativo na taxa de formados
### são P.Undergrad, Personal e Expend.
lm(formula = Grad.Rate ~ ., data = College)
ajuste22< - lm(formula = Grad.Rate ~ ., data = College)
ajuste22 <- lm(formula = Grad.Rate ~ ., data = College)
summary(ajuste22)
head(ajuste2$residuals) ### Resíduos ordeinários
tail(ajuste2$residuals)
ajuste23 <- lm(formula = Grad.Rate ~ PrivateYes , data = College)
ajuste23 <- lm(formula = Grad.Rate ~ Private , data = College)
summary(ajuste23)
summary(ajuste22)
### Vamos extrair alguns elementos do modelo ajustado
ajuste2$coefficients ### Estimativas dos parâmetros
ajuste22$coefficients ### Estimativas dos parâmetros
ajuste22$coefficients ### Estimativas dos parâmetros
coef(ajuste22) ### Estimativas dos parâmetros
conf(ajuste22) ### Estimativas dos parâmetros
confint(ajuste22) ### Estimativas dos parâmetros
predict(ajuste2, newdata = new_data, se.fit = TRUE)
summary(ajuste22)
AIC(ajuste22)
resumo22 <- summary(ajuste22)
resumo22$r.squared
AIC(ajuste22)
### Modelos estatísticos - Aula de modelos lineares
### Pacotes usados na aula.
require("ISLR")
require("ggplot2")
require("GGally")
require("leaps") ## seleção de variaveis
require("car")
require(tidyverse)
require(caret)
require(MASS)
options(device = X11)
aj_full <- ajuste22
### Método backward
step_back_AIC <- step(aj_full, direction = "backward", data = College, k = 2)
data.frame(compareCoefs(step_back_AIC, step_for_AIC, step_both_AIC, step_back_BIC, step_for_BIC, step_both_BIC))
knitr::opts_chunk$set(echo = TRUE)
### Modelos estatísticos - Aula de modelos lineares
### Pacotes usados na aula.
require("ISLR")
require("ggplot2")
require("GGally")
require("leaps") ## seleção de variaveis
require("car")
require(tidyverse)
require(caret)
require(MASS)
options(device = X11)
summary(Auto)
ggplot(Auto, aes(x = year)) + geom_histogram()
ggplot(Auto, aes(x = year, y = mpg)) + geom_point() +
stat_smooth(method = "lm") +
theme_bw(base_size = 14)
plot1 <- ggplot(Auto, aes(x = horsepower, y = mpg)) + geom_point() + theme_bw(base_size = 14)
plot1
plot1 + coord_trans(x="log2", y="log2")
### Carregamento e visualização inicial da base
data("College") ### Carregando a base
#help("College") ### Acessando a documentação
head(College,10) ### Visualizando as dez primeiras linhas
dim(College) ### Acessando a dimensão da base
summary(College) ### Resumo das variáveis
### Vamos considerar Grad.Rate (taxa de formados) como a variável resposta na nossa análise. Começamos a análise com alguns gráficos.
ggplot(College, aes(x = Grad.Rate)) + geom_histogram() +
theme_bw(base_size = 14)
### Distribuição das taxas de formados
ggplot(College, aes(x = Top10perc, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus percentual de alunos entre os 10% melhores
### no ensino médio.
ggplot(College, aes(x = Outstate, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus investimentos externos.
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
geom_smooth(method = "loess") +
theme_bw(base_size = 14)
### Taxas de formados versus porcentagens de ex-alunos contribuintes.
### Parte 1 - Ajuste dos modelos lineares. Comecemos com o caso de apenas uma
### variável explicativa (no caso, perc.alumni)
### Para ajustar modelos lineares no R usamos a função lm. Vamos consultar
### a documentação da função.
#help('lm')
### Ajuste da regressão linear simples (assumindo relação linear entre a taxa de formados e o percentual de ex-alunos contribuintes)
ajuste1 <- lm(Grad.Rate ~ perc.alumni, data = College) ###(resposta ~ var.explicativas)
ajuste1
summary(ajuste1)
### O percentual de ex-alunos contribuintes tem efeito positivo, e
### estatisticamente significativo na taxa de formados.
### Vamos visualizar o ajuste do modelo
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
stat_smooth(method = "lm") +
theme_bw(base_size = 14)
### Vamos investigar possível efeito quadrático do percentual de contribuíntes na taxa de formados. Para isso, adicionamos ao preditor o termo quadrático da variável explicativa, da seguinte forma:
ajuste2 <- lm(Grad.Rate ~ perc.alumni + I(perc.alumni^2), data = College)
summary(ajuste2)
### O termo quadrático é estatisticamente significativo, indicando que a
### relação entre as variáveis não é linear. Vamos dar um passo além, e
### incluir o termo de terceira ordem para o percentual de contribuintes
### (modelo cúbico).
ajuste22 <- lm(formula = Grad.Rate ~ ., data = College)
summary(ajuste22)
## PrivateYes -> 1 se privada (YES); 0 se publica(No)
## Nesse modelo (ajustado com todas as outras variaveis) as escolas privadas tem p<0.05, portanto ser privada tem um impacto  no (maior) número de formados (3.3 pontos percentuais)
ajuste23 <- lm(formula = Grad.Rate ~ Private , data = College)
summary(ajuste23)
## Num modelo só com a privada ela (por "acaso") tambem teve p<0.05 mas com um impacto diferente (12.9 pontos percentuais)
confint(ajuste22) ### Intervalo de confiaça
ajuste3 <- lm(Grad.Rate ~ perc.alumni + I(perc.alumni^2) + I(perc.alumni^3), data = College)
summary(ajuste3)
### O termo de ordem cúbica não tem significância estatística. Vamos seguir
### a análise com o modelo quadrático.
### Vamos extrair alguns elementos do modelo ajustado
ajuste2$coefficients ### Estimativas dos parâmetros
head(ajuste2$residuals)
tail(ajuste2$residuals)
head(ajuste2$fitted.values)
tail(ajuste2$fitted.values)
model.matrix(ajuste2) ### Matriz do modelo (matriz X)
vcov(ajuste2) ### Matriz de variâncias e covariâncias dos estimadores.
### Vamos visualizar o ajuste do modelo
ggplot(College, aes(x = perc.alumni, y = Grad.Rate)) + geom_point() +
stat_smooth(method = "lm", formula = y ~ x + I(x^2)) +
theme_bw(base_size = 14)
### Extraindo os intervalos de confiança (95%) para os parâmetros
confint(ajuste2)
### vamos realizar algumas predições. Considere faculdades com os seguintes percentuais de ex-alunos contribuintes: 13, 28 e 45
new_data <- data.frame(perc.alumni = c(13,28,45))
predict(ajuste2, newdata = new_data, se.fit = TRUE)
### Estimativas pontuais e erros padrões (nota: erros padrões para a resposta média)
predict(ajuste2, newdata = new_data, interval = 'confidence') # para grupo com essa média
### fit = estimando os formados a partir de um número de doadores (13,28,45). lwr e upr = limites do 95% de confiaça.
### Estimativas pontiais e intervalos de confiança (95%) para a resposta **média**.
predict(ajuste2, newdata = new_data, interval = 'prediction') ## Para caso isolado (observação única)
### fit = estimando os formados a partir de um número de doadores (13,28,45). lwr e upr = limites do 95% de confiaça
### Estimativas pontiais e intervalos de confiança (95%) para a predição de **uma nova observação**.
### Parte 2 - Regressão linear múltipla, incluindo todas as variáveis da base como explicativas (exceto a taxa de formação, que é a resposta)
ajuste_p2 <- lm(Grad.Rate ~., data = College)
### Ajuste da regressão linear múltipla. A especificação "~." indica que
### todas as demais variáveis da base devem ser incluídas como explicativas.
### A título de ilustração, se quiséssemos ajustar um modelo apenas com as
### variáveis "Private", "Apps" e "Accept":
summary(ajuste_p2)
ajuste_p2 <- lm(Grad.Rate ~.-Top25perc, data = College)
## Todas menos a top 25. pq o top 10 e top 25 "se sobrepoe"
## "ajustado os efeitos das outras variaveis"
summary(ajuste_p2)
ajuste_p2 <- lm(Grad.Rate ~ Expend, data = College)
## Todas menos a top 25. pq o top 10 e top 25 "se sobrepoe"
## "ajustado os efeitos das outras variaveis"
summary(ajuste_p2)
ajuste_p2_ilustrativo <- lm(Grad.Rate ~ Private + Apps + Accept, data = College)
summary(ajuste_p2_ilustrativo)
### Resumo do ajuste. Observe as variáveis com efeito significativo e os respectivos sinais.
### Variáveis com p-valor (Pr(>|t|)) < 0.05 podem ser consideradas com efeito
### significativo na taxa de formados. Desta forma, as variáveis com efeito
### significativo na taxa de formados são Private (Yes), Apps, Top25perc, Outstate,
### Room.Board, 0.2793343; Já as variáveis com efeito negativo na taxa de formados
### são P.Undergrad, Personal e Expend.
resumo22 <- summary(ajuste22)
resumo22$r.squared
AIC(ajuste22)
BIC(ajuste22)
### Para finalizar, vamos aplicar os algoritmos de seleção do tipo
### stepwise. Primeiramente fixando k = 2, estamos definindo o AIC como critério de
### seleção, temos:
aj_full <- ajuste22
### Método backward (obj: reduzir AIC)
step_back_AIC <- step(aj_full, direction = "backward", data = College, k = 2)
summary(step_back_AIC)
### Método forward. Para o método forward devemos definir o escopo da seleção (menor e maior modelo). O menor seria o modelo nulo (apenas com o intercepto), enquanto o maior seria o modelo com todas as covariáveis.
aj_lower <- lm(Grad.Rate~1, data = College)
aj_upper <- lm(Grad.Rate~., data = College)
formula(aj_upper)
step_for_AIC <- step(aj_lower, direction = "forward", scope=formula(aj_upper),
data = College, k = 2)
summary(step_for_AIC)
### Finalmente, o algoritmo que considera tanto exclusão quanto inclusão de
### covariáveis a cada passo
step_both_AIC <- step(aj_full, direction = "both", data = College, k = 2)
summary(step_both_AIC)
### Vamos comparar os ajustes.
data.frame(compareCoefs(step_back_AIC, step_for_AIC, step_both_AIC))
### Agora fixando k = log(n) (critério BIC):
### Método backward
step_back_BIC <- step(aj_full, direction = "backward", data = College, k = log(nrow(College)))
summary(step_back_BIC)
### Método forward. Para o método forward devemos definir o escopo da seleção
### (menor e maior modelo). O menor seria o modelo nulo (apenas com o intercepto),
### enquanto o maior seria o modelo com todas as covariáveis.
aj_lower <- lm(Grad.Rate~1, data = College)
aj_upper <- lm(Grad.Rate~., data = College)
formula(aj_upper)
step_for_BIC <- step(aj_lower, direction = "forward", scope=formula(aj_upper),
data = College, k = log(nrow(College)))
summary(step_for_BIC)
### Finalmente, o algoritmo que considera tanto exclusão quanto inclusão de
### covariáveis a cada passo
step_both_BIC <- step(aj_full, direction = "both", data = College, k = log(nrow(College)))
summary(step_both_BIC)
### Vamos comparar os ajustes.
data.frame(compareCoefs(step_back_BIC, step_for_BIC, step_both_BIC))
data.frame(compareCoefs(step_back_AIC, step_for_AIC, step_both_AIC, step_back_BIC, step_for_BIC, step_both_BIC))
